{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Configs"
      ],
      "metadata": {
        "id": "jhdlPrEg2Yk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_checked = False\n",
        "\n",
        "if not config_checked:\n",
        "  raise RuntimeError(\"Configuration check failed! Please check the config and set config_checked to True before proceeding.\")\n",
        "\n",
        "RETRAIN = False\n",
        "number_of_run = 5\n",
        "DATA_DIRECTORY = 'ptbxl_data'\n",
        "MODEL_SAVE_DIRECTORY = 'saved_models'\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 30\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_WORKERS = 2 # Adjust based on your system\n",
        "PIN_MEMORY = True\n",
        "DA = False\n",
        "if RETRAIN:\n",
        "  assert number_of_run < 6\n",
        "\n"
      ],
      "metadata": {
        "id": "TFLRfHSZ2Yz_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download prerequisite libabaries"
      ],
      "metadata": {
        "id": "FN5SI3EYydaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/thisistayeb/ECG-PTB-XL/blob/main/requirments.txt\n",
        "!pip install -r ./requirments.txt -q"
      ],
      "metadata": {
        "id": "6hgj4u2-yjoL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Pre-trained wights"
      ],
      "metadata": {
        "id": "UNWMN0mcKwbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf saved_models\n",
        "!wget https://github.com/thisistayeb/ECG-PTB-XL/blob/main/saved_models.zip\n",
        "!unzip -q saved_models.zip -d .\n",
        "!rm saved_models.zip"
      ],
      "metadata": {
        "id": "NLDYGS-5JaNS"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import os\n",
        "import requests\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import wfdb\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import f1_score, hamming_loss, classification_report, precision_recall_fscore_support, multilabel_confusion_matrix\n",
        "import wfdb\n",
        "import glob\n",
        "import pickle\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm.notebook import tqdm\n",
        "from scipy import signal as sp_signal\n"
      ],
      "metadata": {
        "id": "fejdAY4Qyr0u"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download PTB-XL"
      ],
      "metadata": {
        "id": "bdtAnglvyteM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdrive_url = 'https://drive.google.com/file/d/1Rmjr43WqzOYv0EsWduHIJipLh61iQLPa/view?usp=drive_link'\n",
        "fallback_url = 'https://physionet.org/static/published-projects/ptb-xl/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3.zip'\n",
        "output_filename = 'ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3.zip' # Using specific name\n",
        "\n",
        "if os.path.exists(output_filename):\n",
        "    print(f\"File '{output_filename}' already exists. Skipping download.\")\n",
        "else:\n",
        "    try:\n",
        "        print(f\"Attempting download using gdown from: {gdrive_url}\")\n",
        "        gdown.download(url=gdrive_url, output=output_filename, quiet=False, fuzzy=True)\n",
        "        print(f\"\\nFile downloaded successfully via gdown and saved as: {output_filename}\")\n",
        "\n",
        "    except Exception as gdown_exception:\n",
        "        print(f\"\\nGoogle Drive download failed (link might be broken or inaccessible):\")\n",
        "        # --- Fallback to Direct Link Download ---\n",
        "        print(\"\\nAttempting fallback download from PhysioNet Server:\")\n",
        "        print(f\"Direct link: {fallback_url}\")\n",
        "\n",
        "        try:\n",
        "            response = requests.get(fallback_url, stream=True, timeout=60) # timeout in seconds\n",
        "            response.raise_for_status() # Raises HTTPError for bad responses (4xx or 5xx)\n",
        "\n",
        "            # Get total file size from headers for progress bar\n",
        "            total_size = int(response.headers.get('content-length', 0))\n",
        "\n",
        "            print(f\"Saving to: {output_filename}\")\n",
        "            # Write content to file in chunks with progress bar\n",
        "            with open(output_filename, 'wb') as f, tqdm(\n",
        "                desc=output_filename,\n",
        "                total=total_size,\n",
        "                unit='B',\n",
        "                unit_scale=True,\n",
        "                unit_divisor=1024,\n",
        "            ) as bar:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "                    bar.update(len(chunk))\n",
        "\n",
        "            print(f\"\\nFile '{output_filename}' downloaded successfully via fallback link.\")\n",
        "\n",
        "        except requests.exceptions.RequestException as fallback_request_exception:\n",
        "            # This block runs if the requests download (fallback) fails\n",
        "            print(f\"\\nFallback download using direct link also failed:\")\n",
        "            print(fallback_request_exception)\n",
        "            print(\"\\nPlease check the fallback URL and your internet connection.\")\n",
        "            # Clean up potentially partially downloaded file from the failed fallback attempt\n",
        "            if os.path.exists(output_filename):\n",
        "                 try:\n",
        "                     os.remove(output_filename)\n",
        "                     print(f\"Removed potentially partially downloaded file: {output_filename}\")\n",
        "                 except OSError as remove_err:\n",
        "                     print(f\"Error removing partial file {output_filename}: {remove_err}\")\n",
        "        except Exception as general_exception:\n",
        "            # Catch any other unexpected errors during fallback\n",
        "            print(f\"\\nAn unexpected error occurred during fallback download: {general_exception}\")\n",
        "            # Clean up\n",
        "            if os.path.exists(output_filename):\n",
        "                 try:\n",
        "                     os.remove(output_filename)\n",
        "                     print(f\"Removed potentially partially downloaded file: {output_filename}\")\n",
        "                 except OSError as remove_err:\n",
        "                     print(f\"Error removing partial file {output_filename}: {remove_err}\")\n",
        "\n",
        "\n",
        "# Final check to confirm if the file exists after all attempts\n",
        "if os.path.exists(output_filename):\n",
        "    print(f\"\\nFinal Status: File '{output_filename}' is available.\")\n",
        "else:\n",
        "    print(f\"\\nFinal Status: Failed to download '{output_filename}' from either source.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjhMIT-UzReH",
        "outputId": "79577e9a-765b-49c9-a03a-df1b2ba633fc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting download using gdown from: https://drive.google.com/file/d/1Rmjr43WqzOYv0EsWduHIJipLh61iQLPa/view?usp=drive_link\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Rmjr43WqzOYv0EsWduHIJipLh61iQLPa\n",
            "From (redirected): https://drive.google.com/uc?id=1Rmjr43WqzOYv0EsWduHIJipLh61iQLPa&confirm=t&uuid=f77ac624-183c-49a2-bd4c-d3a5155dffb9\n",
            "To: /content/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3.zip\n",
            "100%|██████████| 1.84G/1.84G [00:42<00:00, 42.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "File downloaded successfully via gdown and saved as: ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3.zip\n",
            "\n",
            "Final Status: File 'ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3.zip' is available.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3.zip -d .\n",
        "!mv  ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3 ptbxl_data\n",
        "!rm ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3.zip"
      ],
      "metadata": {
        "id": "uvxbuRSz0OVg"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Seeds"
      ],
      "metadata": {
        "id": "btcpFjAX16Ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "\n",
        "    \"\"\"\n",
        "    Function that controls randomness. NumPy and random modules must be imported.\n",
        "\n",
        "    Args:\n",
        "    seed : Integer\n",
        "    A non-negative integer that defines the random state. Default is `None`.\n",
        "    seed_torch : Boolean\n",
        "    If `True` sets the random seed for pytorch tensors, so pytorch module\n",
        "    must be imported. Default is `True`.\n",
        "\n",
        "    Returns:\n",
        "    Nothing.\n",
        "    \"\"\"\n",
        "    if seed is None:\n",
        "\n",
        "        seed = np.random.choice(2 ** 32)\n",
        "        random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    if seed_torch:\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    print(f'Random seed {seed} has been set.')\n",
        "\n",
        "\n",
        "def generate_sub_seeds(initial_seed, num_seeds=5):\n",
        "    \"\"\"\n",
        "    Generates a specified number of distinct pseudo-random integers\n",
        "    based on an initial seed, suitable for use as further seeds.\n",
        "\n",
        "    Using NumPy's default_rng ensures that the generation is isolated\n",
        "    and repeatable given the same initial_seed.\n",
        "\n",
        "    Args:\n",
        "        initial_seed (int): The non-negative integer seed to initialize\n",
        "                            the random number generator.\n",
        "        num_seeds (int): The number of sub-seeds to generate. Default is 5.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: An array containing 'num_seeds' integers derived\n",
        "                       from the initial seed. These are typically within\n",
        "                       the range [0, 2**32 - 1]. Collisions (non-unique\n",
        "                       numbers) are extremely unlikely with this range\n",
        "                       and small num_seeds.\n",
        "    \"\"\"\n",
        "\n",
        "    rng = np.random.default_rng(initial_seed)\n",
        "    max_val = 2**10\n",
        "    sub_seeds = rng.integers(low=0, high=max_val, size=num_seeds, dtype=np.uint32)\n",
        "    assert len(sub_seeds) == num_seeds\n",
        "    return sub_seeds\n",
        "\n",
        "# Define your main starting seed\n",
        "master_seed = 2025\n",
        "\n",
        "# Generate 5 sub-seeds based on the master seed\n",
        "all_seeds = generate_sub_seeds(master_seed, num_seeds=number_of_run)\n",
        "print(f\"Initial Master Seed: {master_seed}\")\n",
        "print(f\"Generated 5 Sub-Seeds: {all_seeds}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCuy6ToK19-1",
        "outputId": "ebf461e6-6b3f-4d18-8461-494b08cacd88"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Master Seed: 2025\n",
            "Generated 5 Sub-Seeds: [ 458 1018 1016  391  976]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#loading Data and Define the model"
      ],
      "metadata": {
        "id": "H4X7Iy7N6hgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_diagnostic_classes(scp_codes_dict_str, scp_map, valid_classes):\n",
        "    \"\"\" Safely parses SCP codes string and maps them to diagnostic classes. \"\"\"\n",
        "    try:\n",
        "        scp_codes_dict = eval(scp_codes_dict_str)\n",
        "        present_classes = set()\n",
        "        for code, _ in scp_codes_dict.items():\n",
        "            diag_class = scp_map.get(code) # Use the map derived from scp_statements\n",
        "            if diag_class is not None and diag_class in valid_classes:\n",
        "                present_classes.add(diag_class)\n",
        "        return list(present_classes)\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Error processing scp_codes '{scp_codes_dict_str}': {e}\")\n",
        "        return []\n",
        "\n",
        "class ECGMultiLabelDataset(Dataset):\n",
        "    def __init__(self, df, data_dir, mlb_instance, signal_length=1000,\n",
        "                 filter_lowcut=0.5, filter_highcut=45.0, filter_order=4):\n",
        "        self.df = df.copy()\n",
        "        self.data_dir = data_dir\n",
        "        self.mlb = mlb_instance\n",
        "        self.signal_length = signal_length\n",
        "\n",
        "        # --- Filter Parameters ---\n",
        "        self.filter_lowcut = filter_lowcut\n",
        "        self.filter_highcut = filter_highcut\n",
        "        self.filter_order = filter_order\n",
        "        self.filter_coeffs = {}\n",
        "\n",
        "        # Ensure 'label_vector' exists and extract labels\n",
        "        if 'label_vector' not in self.df.columns:\n",
        "             raise ValueError(\"'label_vector' column not found in DataFrame for Dataset.\")\n",
        "        self.labels = np.array(self.df['label_vector'].tolist(), dtype=np.float32)\n",
        "\n",
        "        # Ensure 'filename_lr' or 'filename_hr' exists\n",
        "        if 'filename_lr' in self.df.columns:\n",
        "            self.filepaths = self.df['filename_lr'].values\n",
        "        elif 'filename_hr' in self.df.columns:\n",
        "             print(\"Using high-resolution filenames ('filename_hr')\")\n",
        "             self.filepaths = self.df['filename_hr'].values\n",
        "        else:\n",
        "             raise ValueError(\"Filename column ('filename_lr' or 'filename_hr') not found.\")\n",
        "\n",
        "        # Verify number of labels matches number of samples\n",
        "        if len(self.labels) != len(self.filepaths):\n",
        "             raise ValueError(f\"Mismatch between number of labels ({len(self.labels)}) and filepaths ({len(self.filepaths)}).\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def _get_filter_coeffs(self, fs):\n",
        "        \"\"\" Get or compute Butterworth filter coefficients for a given sampling frequency. \"\"\"\n",
        "        fs = int(fs)\n",
        "        if fs not in self.filter_coeffs:\n",
        "            nyquist = 0.5 * fs\n",
        "            low = self.filter_lowcut / nyquist\n",
        "            high = self.filter_highcut / nyquist\n",
        "            # Ensure frequency bounds are valid\n",
        "            low = max(low, 1e-6) # Avoid zero frequency\n",
        "            high = min(high, 1.0 - 1e-6) # Avoid Nyquist exactly\n",
        "            if low >= high:\n",
        "                 print(f\"Warning: Filter lowcut ({self.filter_lowcut} Hz) >= highcut ({self.filter_highcut} Hz) for fs={fs}. Skipping filter.\")\n",
        "                 self.filter_coeffs[fs] = (None, None) # Store None to indicate skipping\n",
        "            else:\n",
        "                try:\n",
        "                    b, a = sp_signal.butter(self.filter_order, [low, high], btype='bandpass')\n",
        "                    self.filter_coeffs[fs] = (b, a)\n",
        "                except ValueError as e:\n",
        "                    print(f\"Error creating Butterworth filter for fs={fs}, Wn=[{low}, {high}]: {e}. Skipping filter.\")\n",
        "                    self.filter_coeffs[fs] = (None, None)\n",
        "        return self.filter_coeffs[fs]\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        record_filename = self.filepaths[idx]\n",
        "        record_path = os.path.join(self.data_dir, record_filename)\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        try:\n",
        "            record = wfdb.rdrecord(os.path.splitext(record_path)[0])\n",
        "            signal = record.p_signal.T\n",
        "            fs = record.fs\n",
        "            # --- Preprocessing Step 1: Butterworth Bandpass Filter ---\n",
        "            b, a = self._get_filter_coeffs(fs)\n",
        "            if b is not None and a is not None:\n",
        "                # Apply zero-phase filter (filtfilt) to each lead (axis=1)\n",
        "                # Handle potential issues with constant signals if necessary\n",
        "                try:\n",
        "                    signal_filtered = sp_signal.filtfilt(b, a, signal, axis=1)\n",
        "                except ValueError as e:\n",
        "                    print(f\"Warning: filtfilt error on {record_filename} (perhaps constant lead?): {e}. Using unfiltered signal.\")\n",
        "                    signal_filtered = signal # Fallback to original signal\n",
        "            else:\n",
        "                # Filter coefficients couldn't be generated (e.g., invalid range)\n",
        "                signal_filtered = signal # Use original signal if filter failed\n",
        "\n",
        "            # --- Preprocessing Step 2: Z-score Normalization (per lead) ---\n",
        "            # Apply to the filtered signal (or original if filtering failed)\n",
        "            mean = np.mean(signal_filtered, axis=1, keepdims=True)\n",
        "            std = np.std(signal_filtered, axis=1, keepdims=True)\n",
        "            # Add epsilon to std to prevent division by zero for flat signals\n",
        "            signal_normalized = (signal_filtered - mean) / (std + 1e-8)\n",
        "\n",
        "            # --- Preprocessing Step 3: Ensure Correct Length (Pad or Truncate) ---\n",
        "            # Apply padding/truncating AFTER filtering and normalization\n",
        "            current_length = signal_normalized.shape[1]\n",
        "            if current_length < self.signal_length:\n",
        "                padding = self.signal_length - current_length\n",
        "                # Pad with zeros (or another value like mean/edge if preferred)\n",
        "                signal_final = np.pad(signal_normalized, ((0, 0), (0, padding)), 'constant', constant_values=0)\n",
        "            elif current_length > self.signal_length:\n",
        "                # Truncate from the end\n",
        "                signal_final = signal_normalized[:, :self.signal_length]\n",
        "            else:\n",
        "                signal_final = signal_normalized\n",
        "\n",
        "            signal_tensor = torch.tensor(signal_final, dtype=torch.float32)\n",
        "\n",
        "        except FileNotFoundError:\n",
        "             print(f\"Error: Record file not found at {record_path}. Returning zeros.\")\n",
        "             # Assuming 12 leads\n",
        "             signal_tensor = torch.zeros((12, self.signal_length), dtype=torch.float32)\n",
        "             # label remains as loaded, or could be set to zeros if preferred for errors\n",
        "        except Exception as e:\n",
        "             print(f\"Error loading or processing record: {record_path} - {e}\")\n",
        "             signal_tensor = torch.zeros((12, self.signal_length), dtype=torch.float32)\n",
        "             # label remains as loaded\n",
        "\n",
        "        label_tensor = torch.tensor(label, dtype=torch.float32) # Ensure label is tensor too\n",
        "\n",
        "        return signal_tensor, label_tensor\n",
        "\n",
        "\n",
        "class ECGCNN(nn.Module):\n",
        "    def __init__(self, num_classes, input_channels=12):\n",
        "        super(ECGCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
        "        self.bn1 = nn.BatchNorm1d(32)\n",
        "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
        "        self.bn3 = nn.BatchNorm1d(128)\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc = nn.Linear(128, num_classes) #\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.pool(x).squeeze(-1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "EQInhCHA6lLe"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_prepare_data(data_dir, batch_size=32, num_workers=2, pin_memory=True):\n",
        "    \"\"\"\n",
        "    Loads PTB-XL metadata, performs preprocessing (age bins, multi-label encoding),\n",
        "    splits data, and creates PyTorch DataLoaders.\n",
        "\n",
        "    Args:\n",
        "        data_dir (str): Path to the directory containing PTB-XL files\n",
        "                        (ptbxl_database.csv, scp_statements.csv, and record data).\n",
        "        batch_size (int): Batch size for DataLoaders.\n",
        "        num_workers (int): Number of subprocesses for data loading.\n",
        "        pin_memory (bool): If True, copies Tensors into CUDA pinned memory.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Contains (train_loader, val_loader, test_loader, mlb, num_classes, target_classes)\n",
        "               Returns None for loaders if data loading fails at any stage.\n",
        "    \"\"\"\n",
        "    # --- Load Metadata ---\n",
        "    database_path = os.path.join(data_dir, 'ptbxl_database.csv')\n",
        "    scp_path = os.path.join(data_dir, 'scp_statements.csv')\n",
        "\n",
        "    if not os.path.exists(database_path):\n",
        "        print(f\"Error: Database file not found at {database_path}\")\n",
        "        return None, None, None, None, None, None\n",
        "    if not os.path.exists(scp_path):\n",
        "        print(f\"Error: SCP statements file not found at {scp_path}\")\n",
        "        return None, None, None, None, None, None\n",
        "\n",
        "    try:\n",
        "        ptbxl_df = pd.read_csv(database_path, index_col='ecg_id')\n",
        "        # Load scp_statements, ensure the index is the SCP code string (important!)\n",
        "        # If index is integer, convert it or handle mapping carefully. Assume it's the code string.\n",
        "        scp_df = pd.read_csv(scp_path, index_col=0) # Assuming first col is SCP code string\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading CSV files: {e}\")\n",
        "        return None, None, None, None, None, None\n",
        "\n",
        "    print(\"Metadata loaded.\")\n",
        "\n",
        "    # --- Add Age Bin ---\n",
        "    bins = [0, 10, 20, 30, 40, 50, 60, 70, 80,90, np.inf]\n",
        "    labels = ['0s', '10s', '20s', '30s', '40s', '50s', '60s', '70s', '80s', '90']\n",
        "    if 'age' in ptbxl_df.columns:\n",
        "        ptbxl_df['age'] = pd.to_numeric(ptbxl_df['age'], errors='coerce')\n",
        "        ptbxl_df['age_bin'] = pd.cut(ptbxl_df['age'], bins=bins, labels=labels, right=False)\n",
        "        print(\"Added 'age_bin' column.\")\n",
        "    else:\n",
        "        print(\"Warning: 'age' column not found. Could not create 'age_bin'.\")\n",
        "\n",
        "    # --- Multi-Label Preprocessing ---\n",
        "    # Check if 'scp_codes' column exists\n",
        "    if 'scp_codes' not in ptbxl_df.columns:\n",
        "        print(\"Error: 'scp_codes' column is required in ptbxl_database.csv for label processing.\")\n",
        "        return None, None, None, None, None, None\n",
        "\n",
        "    # Determine target classes and mapping from SCP statements\n",
        "    if 'diagnostic_class' in scp_df.columns:\n",
        "        scp_df_filtered = scp_df.dropna(subset=['diagnostic_class'])\n",
        "        # Ensure index is treated as string if needed for matching eval output\n",
        "        scp_df_filtered.index = scp_df_filtered.index.astype(str)\n",
        "        scp_to_class_map = scp_df_filtered['diagnostic_class'].to_dict()\n",
        "        target_classes = sorted(scp_df_filtered['diagnostic_class'].unique().tolist())\n",
        "        print(f\"Using diagnostic superclasses: {target_classes}\")\n",
        "    else:\n",
        "        # Fallback or error if 'diagnostic_class' is missing\n",
        "        print(\"Warning: 'diagnostic_class' column not found in scp_statements.csv.\")\n",
        "        # Implement alternative logic if needed, e.g., using 'diagnostic' column\n",
        "        # For now, raise an error if the primary column is missing.\n",
        "        print(\"Error: Cannot determine target classes without 'diagnostic_class' column.\")\n",
        "        return None, None, None, None, None, None\n",
        "\n",
        "    # Apply function to get labels for each ECG\n",
        "    ptbxl_df['diagnostic_classes_list'] = ptbxl_df['scp_codes'].apply(\n",
        "        lambda x: get_diagnostic_classes(x, scp_to_class_map, target_classes)\n",
        "    )\n",
        "\n",
        "    # Use MultiLabelBinarizer\n",
        "    mlb = MultiLabelBinarizer(classes=target_classes)\n",
        "    multi_hot_labels = mlb.fit_transform(ptbxl_df['diagnostic_classes_list'])\n",
        "    num_classes = len(mlb.classes_)\n",
        "\n",
        "    # Store multi-hot vector efficiently\n",
        "    ptbxl_df['label_vector'] = [row for row in multi_hot_labels]\n",
        "    print(f\"Processed multi-label vectors for {num_classes} classes.\")\n",
        "\n",
        "    # --- Split dataset ---\n",
        "    if 'strat_fold' not in ptbxl_df.columns:\n",
        "        print(\"Error: 'strat_fold' column required for splitting.\")\n",
        "        return None, None, None, None, None, None\n",
        "\n",
        "    train_df = ptbxl_df[ptbxl_df.strat_fold <= 8].copy()\n",
        "    val_df = ptbxl_df[ptbxl_df.strat_fold == 9].copy()\n",
        "    test_df = ptbxl_df[ptbxl_df.strat_fold == 10].copy()\n",
        "\n",
        "    if len(train_df) == 0 or len(val_df) == 0 or len(test_df) == 0:\n",
        "        print(\"Error: Data split resulted in empty training, validation, or test set.\")\n",
        "        return None, None, None, None, None, None\n",
        "\n",
        "    print(f\"Data split: Train={len(train_df)}, Val={len(val_df)}, Test={len(test_df)}\")\n",
        "\n",
        "    # --- Create Datasets and DataLoaders ---\n",
        "    # Pass the fitted MultiLabelBinarizer instance to the dataset\n",
        "    train_dataset = ECGMultiLabelDataset(train_df, data_dir, mlb)\n",
        "    val_dataset = ECGMultiLabelDataset(val_df, data_dir, mlb)\n",
        "    test_dataset = ECGMultiLabelDataset(test_df, data_dir, mlb)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
        "\n",
        "    print(\"--- DataLoaders created successfully ---\")\n",
        "\n",
        "    return train_loader, val_loader, test_loader, val_df, test_df, mlb, num_classes, target_classes\n"
      ],
      "metadata": {
        "id": "xckKEiVs7iSu"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_ecg_model(train_loader, val_loader, num_classes, seed, device,\n",
        "                    num_epochs=30, learning_rate=0.001, DA=False,\n",
        "                    model_save_dir='saved_models'):\n",
        "    \"\"\"\n",
        "    Trains the ECG CNN model, saves the BEST model based on validation loss\n",
        "    (overwriting previous best for this run), and saves the FINAL model state.\n",
        "\n",
        "    Args:\n",
        "        train_loader (DataLoader): DataLoader for the training set.\n",
        "        val_loader (DataLoader): DataLoader for the validation set.\n",
        "        num_classes (int): Number of output classes for the model.\n",
        "        seed (int): Random seed for reproducibility.\n",
        "        device (torch.device): Device to train on ('cuda' or 'cpu').\n",
        "        num_epochs (int): Number of training epochs.\n",
        "        learning_rate (float): Learning rate for the optimizer.\n",
        "        DA (bool): If True, data augmentation logic is placeholder-active\n",
        "                     and '_DA' is included in saved model filenames.\n",
        "        model_save_dir (str): Directory to save the trained model weights.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (best_model_path, final_model_path)\n",
        "               Paths to the saved best and final model weights for this run.\n",
        "               Returns (None, None) if training failed or no epochs were run.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Starting Training ---\")\n",
        "    print(f\"Seed: {seed}, Data Augmentation (DA) Flag: {DA}, Epochs: {num_epochs}, LR: {learning_rate}\")\n",
        "    print(f\"Models will be saved in: {model_save_dir}\")\n",
        "\n",
        "    # --- Setup ---\n",
        "    try:\n",
        "        set_seed(seed)\n",
        "    except NameError:\n",
        "        print(\"Warning: 'set_seed' function not found. Reproducibility may not be guaranteed.\")\n",
        "\n",
        "    os.makedirs(model_save_dir, exist_ok=True) # Ensure save directory exists\n",
        "\n",
        "    try:\n",
        "        model = ECGCNN(num_classes).to(device) # Ensure ECGCNN is defined\n",
        "    except NameError:\n",
        "        print(\"ERROR: 'ECGCNN' class not found. Cannot initialize model.\")\n",
        "        return None, None # Cannot proceed\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss() # Suitable for multi-label\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_path = None # Path to the best model *for this specific run*\n",
        "    final_model_path = None # Path for the model after the last epoch\n",
        "\n",
        "    # --- Define Consistent Base Name ---\n",
        "    # This base name identifies the specific run (seed + DA status)\n",
        "    base_name_prefix = f\"model_seed_{seed}{'_DA' if DA else ''}\"\n",
        "\n",
        "    # --- Training Loop ---\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for i, (signals, labels) in enumerate(train_loader):\n",
        "            signals, labels = signals.to(device), labels.to(device)\n",
        "\n",
        "            # --- Data Augmentation Placeholder ---\n",
        "            if DA:\n",
        "                # signals = apply_my_augmentations(signals) # Your augmentation here\n",
        "                pass # No augmentation implemented in this example\n",
        "\n",
        "            # Forward pass, loss calculation, backward pass, optimize\n",
        "            outputs = model(signals)\n",
        "            loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        # --- Validation Loop ---\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_preds_list, val_labels_list = [], []\n",
        "        with torch.no_grad():\n",
        "            for signals, labels in val_loader:\n",
        "                signals, labels = signals.to(device), labels.to(device)\n",
        "                outputs = model(signals)\n",
        "                v_loss = criterion(outputs, labels)\n",
        "                val_loss += v_loss.item()\n",
        "                preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "                val_preds_list.append(preds.cpu().numpy())\n",
        "                val_labels_list.append(labels.cpu().numpy())\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        val_preds = np.concatenate(val_preds_list, axis=0)\n",
        "        val_labels = np.concatenate(val_labels_list, axis=0)\n",
        "        val_hamming = hamming_loss(val_labels, val_preds)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Hamming: {val_hamming:.4f}\")\n",
        "\n",
        "        # --- Save Best Model (based on validation loss) ---\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            # Define the specific filename for the BEST model of this run\n",
        "            best_model_filename = f\"best_{base_name_prefix}.pth\"\n",
        "            current_best_path = os.path.join(model_save_dir, best_model_filename)\n",
        "\n",
        "            # Remove the previous best model *for this run* if it exists\n",
        "            # This check prevents accidentally deleting the current best if filenames somehow clash\n",
        "            # and avoids errors if it's the first time saving.\n",
        "            if best_model_path and os.path.exists(best_model_path) and best_model_path != current_best_path:\n",
        "                try:\n",
        "                    os.remove(best_model_path)\n",
        "                    # print(f\"  Removed previous best model: {os.path.basename(best_model_path)}\")\n",
        "                except OSError as e:\n",
        "                    print(f\"  Warning: Error removing previous best model {best_model_path}: {e}\")\n",
        "\n",
        "            # Save the new best model\n",
        "            torch.save(model.state_dict(), current_best_path)\n",
        "            best_model_path = current_best_path # Update the path variable\n",
        "            print(f\"  * New best val loss. Saved best model to: {os.path.basename(best_model_path)}\")\n",
        "\n",
        "    # --- End of Training Loop ---\n",
        "\n",
        "    # --- Save Final Model ---\n",
        "    if num_epochs > 0: # Ensure training actually ran\n",
        "        # Define the specific filename for the FINAL model of this run\n",
        "        final_model_filename = f\"final_{base_name_prefix}_epoch_{num_epochs}.pth\"\n",
        "        final_model_path = os.path.join(model_save_dir, final_model_filename)\n",
        "        torch.save(model.state_dict(), final_model_path)\n",
        "\n",
        "        print(f\"\\n--- Training Complete for Seed {seed} ---\")\n",
        "        if best_model_path:\n",
        "            print(f\"Best model saved to : {os.path.basename(best_model_path)} (Val Loss: {best_val_loss:.4f})\")\n",
        "        else:\n",
        "            print(\"Warning: No improvement in validation loss observed during training. 'Best' model not saved.\")\n",
        "        print(f\"Final model saved to: {os.path.basename(final_model_path)}\")\n",
        "        return best_model_path, final_model_path # Return paths to both\n",
        "    else:\n",
        "        print(\"--- Training Warning ---\")\n",
        "        print(\"num_epochs was 0. No training performed, no models saved.\")\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "ud00ZCgT7vV6"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Loop"
      ],
      "metadata": {
        "id": "aTmvJmc-9Ho_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_class_factory = ECGCNN\n",
        "actual_num_classes = 5\n",
        "\n",
        "# 3. Create the model config dictionary\n",
        "model_config = {\n",
        "    'num_classes': actual_num_classes\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- Step 1: Load and Prepare Data ---\n",
        "print(\"--- Loading and Preparing Data ---\")\n",
        "train_loader, val_loader, test_loader, val_df, test_df, mlb, num_classes, target_classes = \\\n",
        "    load_and_prepare_data(\n",
        "        data_dir=DATA_DIRECTORY,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=PIN_MEMORY\n",
        "    )\n",
        "\n",
        "# Check if data loading was successful (including val_df now)\n",
        "if train_loader is None or val_loader is None or test_loader is None or val_df is None or test_df is None or mlb is None:\n",
        "    print(\"Failed to load data completely (check loaders, val_df, test_df, mlb). Exiting.\")\n",
        "    exit()\n",
        "\n",
        "print(f\"Number of classes detected: {num_classes}\")\n",
        "print(f\"Class names: {mlb.classes_}\") # Access classes via mlb\n",
        "\n",
        "if RETRAIN:\n",
        "  # --- Step 2: Training Loop ---\n",
        "  # Dictionary to store paths of the FINAL models after training\n",
        "  final_model_paths = {} # Renamed for clarity\n",
        "\n",
        "  print(\"\\n--- Starting Training Phase ---\")\n",
        "  for current_seed in all_seeds:\n",
        "      # Determine device for this training run\n",
        "      DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "      print(f\"\\n-- Training SEED={current_seed} on device={DEVICE} | DA={DA} --\")\n",
        "      if not torch.cuda.is_available():\n",
        "          print(f\"Warning: CUDA not available, using CPU.\")\n",
        "\n",
        "      # Call the modified train_ecg_model function\n",
        "      # MODIFICATION 2: Unpack BOTH returned paths\n",
        "      best_path, final_path = train_ecg_model(\n",
        "          train_loader=train_loader,\n",
        "          val_loader=val_loader,\n",
        "          num_classes=num_classes,\n",
        "          seed=current_seed,\n",
        "          device=DEVICE,\n",
        "          num_epochs=NUM_EPOCHS,\n",
        "          learning_rate=LEARNING_RATE,\n",
        "          DA=DA,\n",
        "          model_save_dir=MODEL_SAVE_DIRECTORY\n",
        "      )\n",
        "\n",
        "      # Store the path to the FINAL model (or BEST, or both, depending on needs)\n",
        "      # We'll store the final path here for the summary printout.\n",
        "      run_key = f'seed_{current_seed}_DA_{DA}' # Include DA status in key\n",
        "      if final_path:\n",
        "          final_model_paths[run_key] = final_path\n",
        "          print(f\"Stored final model path for {run_key}\")\n",
        "      else:\n",
        "          print(f\"Training might have failed for {run_key}, no final path returned.\")\n",
        "\n",
        "  # Use the correct dictionary name `final_model_paths`\n",
        "  print(f\"\\n--- All DA={DA} Training Runs Complete ---\")\n",
        "  print(\"Summary of FINAL model paths saved:\")\n",
        "  if final_model_paths:\n",
        "      for key, path in final_model_paths.items():\n",
        "          # Use os.path.basename for cleaner output if path is not None\n",
        "          print(f\"- {key}: {os.path.basename(path) if path else 'Path not saved/returned'}\")\n",
        "  else:\n",
        "      print(\"No final model paths were recorded.\")\n",
        "\n",
        "  print(\"\\nTraining script finished.\")\n",
        "else:\n",
        "  print(\"\\nLoad pre-trained weights\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzlta27A9JXl",
        "outputId": "c48f5c4e-a9db-4b1c-a700-826c6ca81612"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Loading and Preparing Data ---\n",
            "Metadata loaded.\n",
            "Added 'age_bin' column.\n",
            "Using diagnostic superclasses: ['CD', 'HYP', 'MI', 'NORM', 'STTC']\n",
            "Processed multi-label vectors for 5 classes.\n",
            "Data split: Train=17418, Val=2183, Test=2198\n",
            "--- DataLoaders created successfully ---\n",
            "Number of classes detected: 5\n",
            "Class names: ['CD' 'HYP' 'MI' 'NORM' 'STTC']\n",
            "\n",
            "Load pre-trained weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global optimal threshold for each class to maximize the F1 on Validation"
      ],
      "metadata": {
        "id": "NPMmyZM298OW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import f1_score\n",
        "import os\n",
        "\n",
        "def find_optimal_thresholds_val(model_path, val_loader, num_classes, device, target_classes=None):\n",
        "    \"\"\"\n",
        "    Finds the optimal probability threshold for each class independently\n",
        "    by maximizing the F1-score on the validation set.\n",
        "\n",
        "    Args:\n",
        "        model_path (str): Path to the trained model state dictionary (.pth file).\n",
        "        val_loader (DataLoader): DataLoader for the validation set.\n",
        "        num_classes (int): Number of classes.\n",
        "        device (torch.device): Device to run inference on ('cuda' or 'cpu').\n",
        "        target_classes (list, optional): List of class names for printing. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: An array of shape (num_classes,) containing the optimal\n",
        "                    threshold for each class. Returns array of 0.5 if error occurs.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Finding Optimal Thresholds using Validation Set ---\")\n",
        "    print(f\"Loading model: {os.path.basename(model_path)}\")\n",
        "\n",
        "    # --- Load Model ---\n",
        "    try:\n",
        "        model = ECGCNN(num_classes=num_classes) # Ensure ECGCNN class is accessible\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "        model.to(device)\n",
        "        model.eval() # Set model to evaluation mode\n",
        "        print(\"Model loaded successfully.\")\n",
        "    except NameError:\n",
        "        print(\"ERROR: 'ECGCNN' class not defined. Cannot load model.\")\n",
        "        return np.full(num_classes, 0.5) # Return default thresholds\n",
        "    except FileNotFoundError:\n",
        "         print(f\"ERROR: Model file not found at {model_path}\")\n",
        "         return np.full(num_classes, 0.5)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model state_dict: {e}\")\n",
        "        return np.full(num_classes, 0.5)\n",
        "\n",
        "    # --- Get Probabilities and Labels from Validation Set ---\n",
        "    all_val_probs_list = []\n",
        "    all_val_labels_list = []\n",
        "    print(\"Running inference on validation set to get probabilities...\")\n",
        "    with torch.no_grad(): # Disable gradient calculations\n",
        "        for i, (signals, labels) in enumerate(val_loader):\n",
        "            signals = signals.to(device)\n",
        "            outputs = model(signals)\n",
        "            # Apply sigmoid to get probabilities\n",
        "            probs = torch.sigmoid(outputs)\n",
        "            all_val_probs_list.append(probs.cpu().numpy())\n",
        "            all_val_labels_list.append(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "\n",
        "    # Concatenate results from all batches\n",
        "    try:\n",
        "        y_true_val = np.concatenate(all_val_labels_list, axis=0)\n",
        "        y_prob_val = np.concatenate(all_val_probs_list, axis=0)\n",
        "        print(f\"Inference complete. Found {y_true_val.shape[0]} validation samples.\")\n",
        "    except ValueError:\n",
        "        print(\"Error: Validation loader might be empty or data format issue.\")\n",
        "        return np.full(num_classes, 0.5)\n",
        "\n",
        "    # --- Find Best Threshold per Class ---\n",
        "    optimal_thresholds = np.zeros(num_classes)\n",
        "    print(f\"Optimizing thresholds for {num_classes} classes...\")\n",
        "\n",
        "    for i in range(num_classes):\n",
        "        best_threshold_class = 0.5 # Default threshold\n",
        "        best_f1_class = -1.0       # Initialize with a value lower than any possible F1\n",
        "\n",
        "        # Define the range of thresholds to test\n",
        "        threshold_candidates = np.linspace(0.01, 0.99, 99) # Test 99 thresholds from 0.01 to 0.99\n",
        "\n",
        "        # Get true labels and predicted probabilities for the current class\n",
        "        true_labels_class = y_true_val[:, i]\n",
        "        probs_class = y_prob_val[:, i]\n",
        "\n",
        "        for thr in threshold_candidates:\n",
        "            # Apply the candidate threshold\n",
        "            pred_labels_class = (probs_class >= thr).astype(int)\n",
        "\n",
        "            # Calculate F1 score for this class using this threshold\n",
        "            # zero_division=0 handles cases where precision and recall are both 0\n",
        "            f1 = f1_score(true_labels_class, pred_labels_class, zero_division=0)\n",
        "\n",
        "            # Update if this threshold gives a better F1 score\n",
        "            if f1 > best_f1_class:\n",
        "                best_f1_class = f1\n",
        "                best_threshold_class = thr\n",
        "\n",
        "        # Store the best threshold found for this class\n",
        "        optimal_thresholds[i] = best_threshold_class\n",
        "\n",
        "        class_name = target_classes[i] if target_classes and i < len(target_classes) else f\"Class {i}\"\n",
        "        if best_f1_class >= 0: # Check if F1 score was calculable\n",
        "            print(f\"  {class_name:<10}: Best Threshold = {best_threshold_class:.3f} (Validation F1 = {best_f1_class:.4f})\")\n",
        "        else:\n",
        "             # This can happen if a class has no positive examples in validation set\n",
        "             print(f\"  {class_name:<10}: Could not optimize (F1 score remained {best_f1_class:.1f}). Using default threshold {optimal_thresholds[i]:.1f}\")\n",
        "\n",
        "\n",
        "    print(\"--- Optimal Threshold finding complete ---\")\n",
        "    return optimal_thresholds"
      ],
      "metadata": {
        "id": "T1z8Do1w995M"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimize threshold for each seed"
      ],
      "metadata": {
        "id": "Qi2RhXKg-S9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_thresholds_per_seed = {}\n",
        "OPTIMIZATION_RESULTS_DIR = 'optimization_results'\n",
        "os.makedirs(OPTIMIZATION_RESULTS_DIR, exist_ok=True)\n",
        "optimized_thresholds_filename = os.path.join(OPTIMIZATION_RESULTS_DIR, 'optimized_global_thresholds_per_seed.pkl')\n",
        "DEVICE_OPT = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device for threshold optimization: {DEVICE_OPT}\")\n",
        "\n",
        "# Check if validation loader exists\n",
        "if 'val_loader' not in locals() or val_loader is None:\n",
        "     print(\"ERROR: 'val_loader' not found or is None. Cannot optimize thresholds.\")\n",
        "     # Decide how to handle: exit() or use default 0.5? Using default for now.\n",
        "     for seed in all_seeds:\n",
        "         optimized_thresholds_per_seed[seed] = np.full(num_classes, 0.5)\n",
        "     print(\"WARNING: Using default threshold 0.5 for all seeds due to missing val_loader.\")\n",
        "else:\n",
        "    # Iterate through seeds to find or compute thresholds\n",
        "    seeds_to_compute = []\n",
        "    for current_seed in all_seeds:\n",
        "         if current_seed not in optimized_thresholds_per_seed:\n",
        "             seeds_to_compute.append(current_seed)\n",
        "         # Check model existence for seeds needing computation (important!)\n",
        "         base_name_prefix = f\"model_seed_{current_seed}{'_DA' if DA else ''}\" # Assuming DA=False for this path\n",
        "         final_model_filename = f\"final_{base_name_prefix}_epoch_{NUM_EPOCHS}.pth\"\n",
        "         model_path = os.path.join(MODEL_SAVE_DIRECTORY, final_model_filename)\n",
        "         if not os.path.exists(model_path) and current_seed in seeds_to_compute:\n",
        "              print(f\"WARNING: Model file not found for seed {current_seed}: {model_path}. Cannot optimize. Using default 0.5.\")\n",
        "              optimized_thresholds_per_seed[current_seed] = np.full(num_classes, 0.5)\n",
        "              seeds_to_compute.remove(current_seed) # Remove from computation list\n",
        "\n",
        "    if seeds_to_compute:\n",
        "        print(f\"Computing optimal thresholds for seeds: {seeds_to_compute}\")\n",
        "        for current_seed in seeds_to_compute:\n",
        "            print(f\"\\n-- Optimizing for SEED={current_seed} --\")\n",
        "            # Construct model path (assuming DA=False for this example)\n",
        "            current_da_flag_opt = False # Explicitly set DA flag assumption here\n",
        "            base_name_prefix = f\"model_seed_{current_seed}{'_DA' if current_da_flag_opt else ''}\"\n",
        "            final_model_filename = f\"final_{base_name_prefix}_epoch_{NUM_EPOCHS}.pth\"\n",
        "            model_path = os.path.join(MODEL_SAVE_DIRECTORY, final_model_filename)\n",
        "\n",
        "            # Call the optimization function\n",
        "            optimal_thresholds = find_optimal_thresholds_val(\n",
        "                model_path=model_path,\n",
        "                val_loader=val_loader,\n",
        "                num_classes=num_classes,\n",
        "                device=DEVICE_OPT,\n",
        "                target_classes=target_classes # Pass class names for printout\n",
        "            )\n",
        "            optimized_thresholds_per_seed[current_seed] = optimal_thresholds\n",
        "            print(f\"Optimization complete for seed {current_seed}.\")\n",
        "    else:\n",
        "         print(\"All required thresholds were loaded or previously computed.\")\n",
        "\n",
        "\n",
        "# Optional: Save the computed thresholds\n",
        "if seeds_to_compute: # Save only if new values were computed\n",
        "     print(f\"Saving computed thresholds to: {optimized_thresholds_filename}\")\n",
        "     try:\n",
        "         with open(optimized_thresholds_filename, 'wb') as f:\n",
        "             pickle.dump(optimized_thresholds_per_seed, f)\n",
        "         print(\"Optimized thresholds saved.\")\n",
        "     except Exception as e:\n",
        "         print(f\"Error saving optimized thresholds: {e}\")\n",
        "\n",
        "# --- Verify thresholds are available for all seeds needed for evaluation ---\n",
        "missing_thresholds = False\n",
        "for seed in all_seeds:\n",
        "    if seed not in optimized_thresholds_per_seed:\n",
        "        print(f\"ERROR: Thresholds for seed {seed} are missing after optimization/loading phase.\")\n",
        "        missing_thresholds = True\n",
        "if missing_thresholds:\n",
        "    print(\"Exiting due to missing optimized thresholds.\")\n",
        "    exit()\n",
        "\n",
        "print(f\"\\n{'='*20} Threshold Optimization Phase Complete {'='*20}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39jZyKBP-K_-",
        "outputId": "34a0e367-72ca-40c6-e585-160551ba0a6c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device for threshold optimization: cuda\n",
            "Computing optimal thresholds for seeds: [np.uint32(458), np.uint32(1018), np.uint32(1016), np.uint32(391), np.uint32(976)]\n",
            "\n",
            "-- Optimizing for SEED=458 --\n",
            "\n",
            "--- Finding Optimal Thresholds using Validation Set ---\n",
            "Loading model: final_model_seed_458_epoch_30.pth\n",
            "Model loaded successfully.\n",
            "Running inference on validation set to get probabilities...\n",
            "Inference complete. Found 2183 validation samples.\n",
            "Optimizing thresholds for 5 classes...\n",
            "  CD        : Best Threshold = 0.430 (Validation F1 = 0.7441)\n",
            "  HYP       : Best Threshold = 0.200 (Validation F1 = 0.4665)\n",
            "  MI        : Best Threshold = 0.540 (Validation F1 = 0.7452)\n",
            "  NORM      : Best Threshold = 0.360 (Validation F1 = 0.8556)\n",
            "  STTC      : Best Threshold = 0.340 (Validation F1 = 0.7609)\n",
            "--- Optimal Threshold finding complete ---\n",
            "Optimization complete for seed 458.\n",
            "\n",
            "-- Optimizing for SEED=1018 --\n",
            "\n",
            "--- Finding Optimal Thresholds using Validation Set ---\n",
            "Loading model: final_model_seed_1018_epoch_30.pth\n",
            "Model loaded successfully.\n",
            "Running inference on validation set to get probabilities...\n",
            "Inference complete. Found 2183 validation samples.\n",
            "Optimizing thresholds for 5 classes...\n",
            "  CD        : Best Threshold = 0.240 (Validation F1 = 0.7514)\n",
            "  HYP       : Best Threshold = 0.190 (Validation F1 = 0.4841)\n",
            "  MI        : Best Threshold = 0.210 (Validation F1 = 0.7439)\n",
            "  NORM      : Best Threshold = 0.540 (Validation F1 = 0.8535)\n",
            "  STTC      : Best Threshold = 0.430 (Validation F1 = 0.7502)\n",
            "--- Optimal Threshold finding complete ---\n",
            "Optimization complete for seed 1018.\n",
            "\n",
            "-- Optimizing for SEED=1016 --\n",
            "\n",
            "--- Finding Optimal Thresholds using Validation Set ---\n",
            "Loading model: final_model_seed_1016_epoch_30.pth\n",
            "Model loaded successfully.\n",
            "Running inference on validation set to get probabilities...\n",
            "Inference complete. Found 2183 validation samples.\n",
            "Optimizing thresholds for 5 classes...\n",
            "  CD        : Best Threshold = 0.250 (Validation F1 = 0.7564)\n",
            "  HYP       : Best Threshold = 0.290 (Validation F1 = 0.4908)\n",
            "  MI        : Best Threshold = 0.450 (Validation F1 = 0.7488)\n",
            "  NORM      : Best Threshold = 0.450 (Validation F1 = 0.8604)\n",
            "  STTC      : Best Threshold = 0.440 (Validation F1 = 0.7406)\n",
            "--- Optimal Threshold finding complete ---\n",
            "Optimization complete for seed 1016.\n",
            "\n",
            "-- Optimizing for SEED=391 --\n",
            "\n",
            "--- Finding Optimal Thresholds using Validation Set ---\n",
            "Loading model: final_model_seed_391_epoch_30.pth\n",
            "Model loaded successfully.\n",
            "Running inference on validation set to get probabilities...\n",
            "Inference complete. Found 2183 validation samples.\n",
            "Optimizing thresholds for 5 classes...\n",
            "  CD        : Best Threshold = 0.420 (Validation F1 = 0.7516)\n",
            "  HYP       : Best Threshold = 0.200 (Validation F1 = 0.4743)\n",
            "  MI        : Best Threshold = 0.360 (Validation F1 = 0.7391)\n",
            "  NORM      : Best Threshold = 0.470 (Validation F1 = 0.8597)\n",
            "  STTC      : Best Threshold = 0.400 (Validation F1 = 0.7485)\n",
            "--- Optimal Threshold finding complete ---\n",
            "Optimization complete for seed 391.\n",
            "\n",
            "-- Optimizing for SEED=976 --\n",
            "\n",
            "--- Finding Optimal Thresholds using Validation Set ---\n",
            "Loading model: final_model_seed_976_epoch_30.pth\n",
            "Model loaded successfully.\n",
            "Running inference on validation set to get probabilities...\n",
            "Inference complete. Found 2183 validation samples.\n",
            "Optimizing thresholds for 5 classes...\n",
            "  CD        : Best Threshold = 0.530 (Validation F1 = 0.7558)\n",
            "  HYP       : Best Threshold = 0.260 (Validation F1 = 0.4883)\n",
            "  MI        : Best Threshold = 0.440 (Validation F1 = 0.7417)\n",
            "  NORM      : Best Threshold = 0.430 (Validation F1 = 0.8559)\n",
            "  STTC      : Best Threshold = 0.340 (Validation F1 = 0.7619)\n",
            "--- Optimal Threshold finding complete ---\n",
            "Optimization complete for seed 976.\n",
            "Saving computed thresholds to: optimization_results/optimized_global_thresholds_per_seed.pkl\n",
            "Optimized thresholds saved.\n",
            "\n",
            "==================== Threshold Optimization Phase Complete ====================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement Subgroup Optimization"
      ],
      "metadata": {
        "id": "WTmCrPXQ-xTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Helper Function: Calculate Subgroup Metrics\n",
        "def calculate_subgroup_metrics(group_labels, group_preds, target_classes):\n",
        "    num_samples = len(group_labels)\n",
        "    metrics = {}\n",
        "    num_classes_calc = len(target_classes)\n",
        "\n",
        "    if num_samples == 0:\n",
        "        metrics['num_samples'] = 0; metrics['exact_match_ratio'] = np.nan; metrics['mean_true_labels'] = np.nan\n",
        "        metrics['precision_macro'] = np.nan; metrics['recall_macro'] = np.nan; metrics['f1_macro'] = np.nan\n",
        "        metrics['precision_micro'] = np.nan; metrics['recall_micro'] = np.nan; metrics['f1_micro'] = np.nan\n",
        "        metrics['precision_weighted'] = np.nan; metrics['recall_weighted'] = np.nan; metrics['f1_weighted'] = np.nan\n",
        "        metrics['precision_per_class'] = {cls: np.nan for cls in target_classes}; metrics['recall_per_class'] = {cls: np.nan for cls in target_classes}\n",
        "        metrics['f1_per_class'] = {cls: np.nan for cls in target_classes}; metrics['support_per_class'] = {cls: 0 for cls in target_classes}\n",
        "        return metrics\n",
        "\n",
        "    metrics['num_samples'] = num_samples\n",
        "    if num_samples == 1: group_labels = group_labels.reshape(1, -1); group_preds = group_preds.reshape(1, -1)\n",
        "\n",
        "    metrics['exact_match_ratio'] = np.sum(np.all(group_labels == group_preds, axis=1)) / num_samples\n",
        "    metrics['mean_true_labels'] = np.mean(np.sum(group_labels, axis=1))\n",
        "\n",
        "    precision_mac, recall_mac, f1_mac, _ = precision_recall_fscore_support(group_labels, group_preds, average='macro', zero_division=0)\n",
        "    precision_mic, recall_mic, f1_mic, _ = precision_recall_fscore_support(group_labels, group_preds, average='micro', zero_division=0)\n",
        "    precision_wei, recall_wei, f1_wei, _ = precision_recall_fscore_support(group_labels, group_preds, average='weighted', zero_division=0)\n",
        "    precision_pc, recall_pc, f1_pc, support_pc = precision_recall_fscore_support(group_labels, group_preds, average=None, zero_division=0, labels=list(range(num_classes_calc)))\n",
        "\n",
        "    metrics.update({'precision_macro': precision_mac, 'recall_macro': recall_mac, 'f1_macro': f1_mac, 'precision_micro': precision_mic, 'recall_micro': recall_mic, 'f1_micro': f1_mic,'precision_weighted': precision_wei, 'recall_weighted': recall_wei, 'f1_weighted': f1_wei,'precision_per_class': dict(zip(target_classes, precision_pc)),'recall_per_class': dict(zip(target_classes, recall_pc)),'f1_per_class': dict(zip(target_classes, f1_pc)),'support_per_class': dict(zip(target_classes, support_pc))})\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def find_optimal_thresholds_subgroup(\n",
        "    model_path,\n",
        "    model_class_factory, # Factory function for your model (e.g., ECGCNN or xresnet)\n",
        "    model_config,        # Dictionary with model config, MUST include 'num_classes'\n",
        "    val_loader,          # DataLoader for the validation set (MUST NOT SHUFFLE)\n",
        "    val_df,              # DataFrame with metadata, ordered consistently with val_loader\n",
        "    subgroup_col,        # Column name in val_df (e.g., 'sex', 'age_bin', 'device')\n",
        "    global_optimal_thresholds, # Numpy array (shape: num_classes) of pre-calculated global thresholds\n",
        "    device,              # Torch device ('cuda' or 'cpu')\n",
        "    target_classes=None, # Optional: List of class names for printing\n",
        "    threshold_step=0.01,  # Granularity for threshold search\n",
        "    log=False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Finds optimal probability thresholds for each class, optimized *within* each\n",
        "    subgroup defined by the unique values in `subgroup_col` of `val_df`.\n",
        "    Uses pre-calculated global thresholds as fallback when a class has no positive\n",
        "    samples within a subgroup.\n",
        "\n",
        "    Args:\n",
        "        model_path (str): Path to the trained model state dictionary (.pth file).\n",
        "        model_class_factory (function): Factory function to create the model instance.\n",
        "        model_config (dict): Configuration dictionary for the model factory,\n",
        "                               must include 'num_classes'.\n",
        "        val_loader (DataLoader): DataLoader for the validation set (MUST NOT SHUFFLE).\n",
        "        val_df (pd.DataFrame): DataFrame containing metadata for the validation set,\n",
        "                               ordered consistently with val_loader.\n",
        "        subgroup_col (str): The column name in val_df to group by (e.g., 'sex').\n",
        "        global_optimal_thresholds (np.ndarray): Array (shape: num_classes) with\n",
        "                                                pre-computed optimal thresholds\n",
        "                                                from the entire validation set.\n",
        "        device (torch.device): Device to run inference on ('cuda' or 'cpu').\n",
        "        target_classes (list, optional): List of class names for printing.\n",
        "        threshold_step (float): Step size for searching thresholds (e.g., 0.01).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are the unique subgroup values (as strings),\n",
        "              and values are numpy arrays (shape: num_classes) containing the\n",
        "              optimal thresholds for that specific subgroup. Returns None on critical error.\n",
        "              Example: {'male': array([0.45, 0.33,...]), 'female': array([0.51, 0.29,...])}\n",
        "    \"\"\"\n",
        "    if log:\n",
        "      print(f\"\\n--- Finding Optimal Thresholds per Subgroup: '{subgroup_col}' ---\")\n",
        "      print(f\"Using Model Factory: {model_class_factory.__name__}\")\n",
        "      print(f\"Loading model state: {os.path.basename(model_path)}\")\n",
        "\n",
        "    # --- Validate Inputs ---\n",
        "    if subgroup_col not in val_df.columns:\n",
        "        print(f\"ERROR: Subgroup column '{subgroup_col}' not found in val_df.\")\n",
        "        return None\n",
        "    if len(val_loader.dataset) != len(val_df):\n",
        "        print(f\"ERROR: Mismatch between val_loader dataset size ({len(val_loader.dataset)}) \"\n",
        "              f\"and val_df length ({len(val_df)}). Ensure order consistency.\")\n",
        "        return None\n",
        "    if not isinstance(global_optimal_thresholds, np.ndarray):\n",
        "         print(f\"ERROR: global_optimal_thresholds must be a NumPy array.\")\n",
        "         return None\n",
        "\n",
        "    # --- Extract num_classes from config ---\n",
        "    try:\n",
        "        num_classes = model_config['num_classes']\n",
        "        if global_optimal_thresholds.shape != (num_classes,):\n",
        "             print(f\"ERROR: Shape mismatch. global_optimal_thresholds shape {global_optimal_thresholds.shape} \"\n",
        "                   f\"does not match num_classes ({num_classes}) from model_config.\")\n",
        "             return None\n",
        "    except KeyError:\n",
        "        print(\"ERROR: 'num_classes' not found in model_config.\")\n",
        "        return None\n",
        "    except TypeError:\n",
        "         print(\"ERROR: model_config is not a dictionary or is None.\")\n",
        "         return None\n",
        "\n",
        "    # --- Ensure subgroup column is string type for consistent keys ---\n",
        "    try:\n",
        "        val_df_internal = val_df.copy()\n",
        "        val_df_internal[subgroup_col] = val_df_internal[subgroup_col].astype(str)\n",
        "        subgroup_values_array = val_df_internal[subgroup_col].values\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not convert column '{subgroup_col}' to string: {e}\")\n",
        "        subgroup_values_array = val_df[subgroup_col].values\n",
        "\n",
        "    # --- Load Model ---\n",
        "    try:\n",
        "        model = model_class_factory(**model_config)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "        if log:\n",
        "          print(\"Model loaded successfully.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ERROR: Model file not found at {model_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model or state_dict for {model_class_factory.__name__}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "    # --- Get ALL Probabilities and Labels from Validation Set (ONCE) ---\n",
        "    all_val_probs_list = []\n",
        "    all_val_labels_list = []\n",
        "    if log:\n",
        "      print(\"Running inference on entire validation set...\")\n",
        "    with torch.no_grad():\n",
        "        for signals, labels in val_loader:\n",
        "            signals = signals.to(device)\n",
        "            outputs = model(signals)\n",
        "            probs = torch.sigmoid(outputs)\n",
        "            all_val_probs_list.append(probs.cpu().numpy())\n",
        "            all_val_labels_list.append(labels.cpu().numpy())\n",
        "\n",
        "    # Concatenate results\n",
        "    try:\n",
        "        if not all_val_labels_list or not all_val_probs_list:\n",
        "             print(\"Error: No data collected from validation loader. Is it empty?\")\n",
        "             return None\n",
        "        all_y_true_val = np.concatenate(all_val_labels_list, axis=0).astype(int)\n",
        "        all_y_prob_val = np.concatenate(all_val_probs_list, axis=0)\n",
        "        if all_y_true_val.shape[0] == 0:\n",
        "             print(\"Error: Concatenated arrays are empty.\")\n",
        "             return None\n",
        "        if all_y_true_val.shape[1] != num_classes or all_y_prob_val.shape[1] != num_classes:\n",
        "             print(f\"Error: Shape mismatch after concatenation. Expected {num_classes} classes.\")\n",
        "             return None\n",
        "        print(f\"Inference complete. Found {all_y_true_val.shape[0]} validation samples.\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Error during concatenation: {e}. Check data shapes in validation loader.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during result processing: {e}\")\n",
        "        return None\n",
        "\n",
        "    # --- Optimize Thresholds per Subgroup Value ---\n",
        "    optimal_thresholds_per_subgroup = {}\n",
        "    unique_subgroup_values = np.unique(subgroup_values_array)\n",
        "    print(f\"Found unique subgroup values in '{subgroup_col}': {list(unique_subgroup_values)}\")\n",
        "\n",
        "    threshold_candidates = np.arange(threshold_step, 1.0, threshold_step)\n",
        "    if len(threshold_candidates) == 0:\n",
        "        print(f\"ERROR: threshold_step ({threshold_step}) is too large, resulted in zero candidates.\")\n",
        "        return None\n",
        "    print(f\"Optimizing thresholds using {len(threshold_candidates)} steps (step={threshold_step:.3f})...\")\n",
        "\n",
        "    for value_str in unique_subgroup_values:\n",
        "        print(f\"\\n-- Optimizing for Subgroup: {subgroup_col} = {value_str} --\")\n",
        "        mask = (subgroup_values_array == value_str)\n",
        "        num_samples_subgroup = np.sum(mask)\n",
        "\n",
        "        if num_samples_subgroup == 0:\n",
        "            print(\"  No samples found for this subgroup. Using global thresholds as fallback.\")\n",
        "            optimal_thresholds_per_subgroup[value_str] = global_optimal_thresholds.copy()\n",
        "            continue\n",
        "\n",
        "        y_true_subgroup = all_y_true_val[mask]\n",
        "        y_prob_subgroup = all_y_prob_val[mask]\n",
        "        print(f\"  Optimizing using {num_samples_subgroup} samples.\")\n",
        "\n",
        "        optimal_thresholds_subgroup = np.zeros(num_classes)\n",
        "        for i in range(num_classes): # Loop through classes\n",
        "            true_labels_class = y_true_subgroup[:, i]\n",
        "            probs_class = y_prob_subgroup[:, i]\n",
        "\n",
        "            # Check if positive samples exist for this class in this subgroup\n",
        "            if np.sum(true_labels_class) == 0:\n",
        "                # Path 1: No positive samples exist\n",
        "                class_name = target_classes[i] if target_classes and i < len(target_classes) else f\"Class {i}\"\n",
        "                # Define fallback_threshold locally just for this path's logic/printout\n",
        "                fallback_threshold = global_optimal_thresholds[i]\n",
        "                print(f\"  {class_name:<15}: No positive samples in subgroup. Using global threshold {fallback_threshold:.3f}\")\n",
        "                optimal_thresholds_subgroup[i] = fallback_threshold # Assign the fallback\n",
        "                continue # Skip optimization for this class\n",
        "\n",
        "            # Path 2: Positive samples DO exist\n",
        "            # Initialize best_threshold with the global one before searching\n",
        "            best_threshold_class = global_optimal_thresholds[i] # <<< THE FIX IS HERE\n",
        "            best_f1_class = -1.0\n",
        "\n",
        "            # Search for a better threshold within the subgroup\n",
        "            for thr in threshold_candidates:\n",
        "                pred_labels_class = (probs_class >= thr).astype(int)\n",
        "                f1 = f1_score(true_labels_class, pred_labels_class, zero_division=0)\n",
        "                if f1 > best_f1_class:\n",
        "                    best_f1_class = f1\n",
        "                    best_threshold_class = thr\n",
        "\n",
        "            # Store the best threshold found (or the initialized global one if F1 never improved)\n",
        "            optimal_thresholds_subgroup[i] = best_threshold_class\n",
        "            class_name = target_classes[i] if target_classes and i < len(target_classes) else f\"Class {i}\"\n",
        "            if best_f1_class >= 0:\n",
        "                 print(f\"  {class_name:<15}: Best Threshold = {best_threshold_class:.3f} (Subgroup Val F1 = {best_f1_class:.4f})\")\n",
        "            else:\n",
        "                 print(f\"  {class_name:<15}: Optimization found no improvement? Using initial fallback {optimal_thresholds_subgroup[i]:.3f}\")\n",
        "\n",
        "        # Store the thresholds found for this specific subgroup value\n",
        "        optimal_thresholds_per_subgroup[value_str] = optimal_thresholds_subgroup\n",
        "\n",
        "    print(f\"\\n--- Subgroup Threshold Optimization for '{subgroup_col}' Complete ---\")\n",
        "    return optimal_thresholds_per_subgroup\n"
      ],
      "metadata": {
        "id": "Kbtx_sUs-yGW"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPTIMIZATION_RESULTS_DIR = 'optimization_results'\n",
        "os.makedirs(OPTIMIZATION_RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "optimized_subgroup_thresholds_per_seed_result = {}\n",
        "\n",
        "# --- Loop through seeds ---\n",
        "for current_seed in all_seeds:\n",
        "    print(f\"\\n{'='*20} Optimizing Subgroup Thresholds for SEED={current_seed} {'='*20}\")\n",
        "    optimized_subgroup_thresholds_per_seed_result[current_seed] = {}\n",
        "\n",
        "    current_global_thresholds = optimized_thresholds_per_seed.get(current_seed)\n",
        "    if current_global_thresholds is None:\n",
        "        print(f\"WARNING: Global thresholds for seed {current_seed} not found. Skipping subgroup optimization.\")\n",
        "        # Assign None placeholders\n",
        "        optimized_subgroup_thresholds_per_seed_result[current_seed]['sex'] = None\n",
        "        optimized_subgroup_thresholds_per_seed_result[current_seed]['age_bin'] = None\n",
        "        optimized_subgroup_thresholds_per_seed_result[current_seed]['device'] = None\n",
        "        continue\n",
        "\n",
        "    base_name_prefix = f\"model_seed_{current_seed}{'_DA' if DA else ''}\"\n",
        "    final_model_filename = f\"final_{base_name_prefix}_epoch_{NUM_EPOCHS}.pth\"\n",
        "    model_path = os.path.join(MODEL_SAVE_DIRECTORY, final_model_filename)\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"WARNING: Model file not found for seed {current_seed}: {model_path}. Skipping.\")\n",
        "        optimized_subgroup_thresholds_per_seed_result[current_seed]['sex'] = None\n",
        "        optimized_subgroup_thresholds_per_seed_result[current_seed]['age_bin'] = None\n",
        "        optimized_subgroup_thresholds_per_seed_result[current_seed]['device'] = None\n",
        "        continue\n",
        "\n",
        "    # --- Call find_optimal_thresholds_subgroup (calls now work correctly) ---\n",
        "\n",
        "    # Optimize for 'sex'\n",
        "    thresholds_sex = find_optimal_thresholds_subgroup(\n",
        "        model_path=model_path,\n",
        "        model_class_factory=model_class_factory,\n",
        "        model_config=model_config,\n",
        "        val_loader=val_loader,\n",
        "        val_df=val_df,\n",
        "        subgroup_col='sex',\n",
        "        global_optimal_thresholds=current_global_thresholds,\n",
        "        device=DEVICE_OPT,\n",
        "        target_classes=target_classes\n",
        "    )\n",
        "    optimized_subgroup_thresholds_per_seed_result[current_seed]['sex'] = thresholds_sex\n",
        "\n",
        "    # Optimize for 'age_bin'\n",
        "    thresholds_age = find_optimal_thresholds_subgroup(\n",
        "        model_path=model_path,\n",
        "        model_class_factory=model_class_factory,\n",
        "        model_config=model_config,\n",
        "        val_loader=val_loader,\n",
        "        val_df=val_df,\n",
        "        subgroup_col='age_bin',\n",
        "        global_optimal_thresholds=current_global_thresholds,\n",
        "        device=DEVICE_OPT,\n",
        "        target_classes=target_classes\n",
        "    )\n",
        "    optimized_subgroup_thresholds_per_seed_result[current_seed]['age_bin'] = thresholds_age\n",
        "\n",
        "    # Optimize for 'device'\n",
        "    thresholds_device = find_optimal_thresholds_subgroup(\n",
        "        model_path=model_path,\n",
        "        model_class_factory=model_class_factory,\n",
        "        model_config=model_config,\n",
        "        val_loader=val_loader,\n",
        "        val_df=val_df,\n",
        "        subgroup_col='device',\n",
        "        global_optimal_thresholds=current_global_thresholds,\n",
        "        device=DEVICE_OPT,\n",
        "        target_classes=target_classes\n",
        "    )\n",
        "    optimized_subgroup_thresholds_per_seed_result[current_seed]['device'] = thresholds_device\n",
        "\n",
        "# --- Save the results ---\n",
        "subgroup_thresholds_filename = os.path.join(OPTIMIZATION_RESULTS_DIR, f'optimized_subgroup_thresholds_per_seed_DA_{DA}.pkl')\n",
        "print(f\"\\nSaving computed subgroup thresholds per seed to: {subgroup_thresholds_filename}\")\n",
        "try:\n",
        "    with open(subgroup_thresholds_filename, 'wb') as f:\n",
        "        pickle.dump(optimized_subgroup_thresholds_per_seed_result, f)\n",
        "    print(\"Optimized subgroup thresholds per seed saved.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving optimized subgroup thresholds per seed: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwiX-cGc-55W",
        "outputId": "f9033b22-6ed2-4de3-d700-59676a4814b6"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== Optimizing Subgroup Thresholds for SEED=458 ====================\n",
            "Inference complete. Found 2183 validation samples.\n",
            "Found unique subgroup values in 'sex': ['0', '1']\n",
            "Optimizing thresholds using 99 steps (step=0.010)...\n",
            "\n",
            "-- Optimizing for Subgroup: sex = 0 --\n",
            "  Optimizing using 1133 samples.\n",
            "  CD             : Best Threshold = 0.430 (Subgroup Val F1 = 0.7559)\n",
            "  HYP            : Best Threshold = 0.160 (Subgroup Val F1 = 0.5116)\n",
            "  MI             : Best Threshold = 0.540 (Subgroup Val F1 = 0.7700)\n",
            "  NORM           : Best Threshold = 0.450 (Subgroup Val F1 = 0.8496)\n",
            "  STTC           : Best Threshold = 0.340 (Subgroup Val F1 = 0.7361)\n",
            "\n",
            "-- Optimizing for Subgroup: sex = 1 --\n",
            "  Optimizing using 1050 samples.\n",
            "  CD             : Best Threshold = 0.450 (Subgroup Val F1 = 0.7320)\n",
            "  HYP            : Best Threshold = 0.340 (Subgroup Val F1 = 0.4490)\n",
            "  MI             : Best Threshold = 0.540 (Subgroup Val F1 = 0.7112)\n",
            "  NORM           : Best Threshold = 0.330 (Subgroup Val F1 = 0.8661)\n",
            "  STTC           : Best Threshold = 0.340 (Subgroup Val F1 = 0.7836)\n",
            "\n",
            "--- Subgroup Threshold Optimization for 'sex' Complete ---\n",
            "Inference complete. Found 2183 validation samples.\n",
            "Found unique subgroup values in 'age_bin': ['0s', '10s', '20s', '30s', '40s', '50s', '60s', '70s', '80s', '90']\n",
            "Optimizing thresholds using 99 steps (step=0.010)...\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 0s --\n",
            "  Optimizing using 1 samples.\n",
            "  CD             : No positive samples in subgroup. Using global threshold 0.430\n",
            "  HYP            : No positive samples in subgroup. Using global threshold 0.200\n",
            "  MI             : No positive samples in subgroup. Using global threshold 0.540\n",
            "  NORM           : Best Threshold = 0.010 (Subgroup Val F1 = 1.0000)\n",
            "  STTC           : No positive samples in subgroup. Using global threshold 0.340\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 10s --\n",
            "  Optimizing using 47 samples.\n",
            "  CD             : Best Threshold = 0.410 (Subgroup Val F1 = 0.5714)\n",
            "  HYP            : Best Threshold = 0.020 (Subgroup Val F1 = 0.1667)\n",
            "  MI             : No positive samples in subgroup. Using global threshold 0.540\n",
            "  NORM           : Best Threshold = 0.010 (Subgroup Val F1 = 0.9425)\n",
            "  STTC           : Best Threshold = 0.220 (Subgroup Val F1 = 0.8000)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 20s --\n",
            "  Optimizing using 101 samples.\n",
            "  CD             : Best Threshold = 0.300 (Subgroup Val F1 = 0.7200)\n",
            "  HYP            : Best Threshold = 0.080 (Subgroup Val F1 = 0.3333)\n",
            "  MI             : Best Threshold = 0.370 (Subgroup Val F1 = 0.4444)\n",
            "  NORM           : Best Threshold = 0.370 (Subgroup Val F1 = 0.9325)\n",
            "  STTC           : Best Threshold = 0.270 (Subgroup Val F1 = 0.7778)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 30s --\n",
            "  Optimizing using 135 samples.\n",
            "  CD             : Best Threshold = 0.340 (Subgroup Val F1 = 0.8333)\n",
            "  HYP            : Best Threshold = 0.110 (Subgroup Val F1 = 0.5714)\n",
            "  MI             : Best Threshold = 0.640 (Subgroup Val F1 = 0.7143)\n",
            "  NORM           : Best Threshold = 0.150 (Subgroup Val F1 = 0.9258)\n",
            "  STTC           : Best Threshold = 0.300 (Subgroup Val F1 = 0.8182)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 40s --\n",
            "  Optimizing using 254 samples.\n",
            "  CD             : Best Threshold = 0.340 (Subgroup Val F1 = 0.7119)\n",
            "  HYP            : Best Threshold = 0.090 (Subgroup Val F1 = 0.4186)\n",
            "  MI             : Best Threshold = 0.420 (Subgroup Val F1 = 0.6753)\n",
            "  NORM           : Best Threshold = 0.550 (Subgroup Val F1 = 0.9045)\n",
            "  STTC           : Best Threshold = 0.320 (Subgroup Val F1 = 0.7797)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 50s --\n",
            "  Optimizing using 415 samples.\n",
            "  CD             : Best Threshold = 0.460 (Subgroup Val F1 = 0.6723)\n",
            "  HYP            : Best Threshold = 0.270 (Subgroup Val F1 = 0.4286)\n",
            "  MI             : Best Threshold = 0.620 (Subgroup Val F1 = 0.7130)\n",
            "  NORM           : Best Threshold = 0.360 (Subgroup Val F1 = 0.8694)\n",
            "  STTC           : Best Threshold = 0.340 (Subgroup Val F1 = 0.7719)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 60s --\n",
            "  Optimizing using 481 samples.\n",
            "  CD             : Best Threshold = 0.500 (Subgroup Val F1 = 0.7415)\n",
            "  HYP            : Best Threshold = 0.230 (Subgroup Val F1 = 0.5714)\n",
            "  MI             : Best Threshold = 0.540 (Subgroup Val F1 = 0.7808)\n",
            "  NORM           : Best Threshold = 0.230 (Subgroup Val F1 = 0.8052)\n",
            "  STTC           : Best Threshold = 0.440 (Subgroup Val F1 = 0.7730)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 70s --\n",
            "  Optimizing using 451 samples.\n",
            "  CD             : Best Threshold = 0.350 (Subgroup Val F1 = 0.7837)\n",
            "  HYP            : Best Threshold = 0.160 (Subgroup Val F1 = 0.4607)\n",
            "  MI             : Best Threshold = 0.540 (Subgroup Val F1 = 0.7607)\n",
            "  NORM           : Best Threshold = 0.130 (Subgroup Val F1 = 0.7704)\n",
            "  STTC           : Best Threshold = 0.410 (Subgroup Val F1 = 0.7319)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 80s --\n",
            "  Optimizing using 256 samples.\n",
            "  CD             : Best Threshold = 0.570 (Subgroup Val F1 = 0.7565)\n",
            "  HYP            : Best Threshold = 0.330 (Subgroup Val F1 = 0.5283)\n",
            "  MI             : Best Threshold = 0.690 (Subgroup Val F1 = 0.8098)\n",
            "  NORM           : Best Threshold = 0.360 (Subgroup Val F1 = 0.7059)\n",
            "  STTC           : Best Threshold = 0.320 (Subgroup Val F1 = 0.7931)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 90 --\n",
            "  Optimizing using 42 samples.\n",
            "  CD             : Best Threshold = 0.510 (Subgroup Val F1 = 0.9200)\n",
            "  HYP            : Best Threshold = 0.170 (Subgroup Val F1 = 0.4167)\n",
            "  MI             : Best Threshold = 0.660 (Subgroup Val F1 = 0.8500)\n",
            "  NORM           : Best Threshold = 0.290 (Subgroup Val F1 = 1.0000)\n",
            "  STTC           : Best Threshold = 0.320 (Subgroup Val F1 = 0.8235)\n",
            "\n",
            "--- Subgroup Threshold Optimization for 'age_bin' Complete ---\n",
            "Inference complete. Found 2183 validation samples.\n",
            "Found unique subgroup values in 'device': ['AT-6     6', 'AT-6 C', 'AT-6 C 5.0', 'AT-6 C 5.3', 'AT-6 C 5.5', 'AT-6 C 5.6', 'AT-6 C 5.8', 'AT-60    3', 'CS-12', 'CS-12   E', 'CS100    3']\n",
            "Optimizing thresholds using 99 steps (step=0.010)...\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6     6 --\n",
            "  Optimizing using 222 samples.\n",
            "  CD             : Best Threshold = 0.620 (Subgroup Val F1 = 0.7748)\n",
            "  HYP            : Best Threshold = 0.300 (Subgroup Val F1 = 0.4615)\n",
            "  MI             : Best Threshold = 0.670 (Subgroup Val F1 = 0.8046)\n",
            "  NORM           : Best Threshold = 0.430 (Subgroup Val F1 = 0.8602)\n",
            "  STTC           : Best Threshold = 0.320 (Subgroup Val F1 = 0.8435)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C --\n",
            "  Optimizing using 119 samples.\n",
            "  CD             : Best Threshold = 0.280 (Subgroup Val F1 = 0.7250)\n",
            "  HYP            : Best Threshold = 0.220 (Subgroup Val F1 = 0.6471)\n",
            "  MI             : Best Threshold = 0.700 (Subgroup Val F1 = 0.8148)\n",
            "  NORM           : Best Threshold = 0.230 (Subgroup Val F1 = 0.7179)\n",
            "  STTC           : Best Threshold = 0.300 (Subgroup Val F1 = 0.8571)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.0 --\n",
            "  Optimizing using 14 samples.\n",
            "  CD             : Best Threshold = 0.380 (Subgroup Val F1 = 1.0000)\n",
            "  HYP            : Best Threshold = 0.210 (Subgroup Val F1 = 0.8889)\n",
            "  MI             : Best Threshold = 0.850 (Subgroup Val F1 = 0.8889)\n",
            "  NORM           : Best Threshold = 0.050 (Subgroup Val F1 = 0.9091)\n",
            "  STTC           : Best Threshold = 0.590 (Subgroup Val F1 = 1.0000)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.3 --\n",
            "  Optimizing using 10 samples.\n",
            "  CD             : Best Threshold = 0.350 (Subgroup Val F1 = 0.8571)\n",
            "  HYP            : Best Threshold = 0.160 (Subgroup Val F1 = 0.8000)\n",
            "  MI             : Best Threshold = 0.190 (Subgroup Val F1 = 1.0000)\n",
            "  NORM           : Best Threshold = 0.180 (Subgroup Val F1 = 0.8889)\n",
            "  STTC           : Best Threshold = 0.340 (Subgroup Val F1 = 1.0000)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.5 --\n",
            "  Optimizing using 397 samples.\n",
            "  CD             : Best Threshold = 0.370 (Subgroup Val F1 = 0.8440)\n",
            "  HYP            : Best Threshold = 0.150 (Subgroup Val F1 = 0.4688)\n",
            "  MI             : Best Threshold = 0.690 (Subgroup Val F1 = 0.7799)\n",
            "  NORM           : Best Threshold = 0.200 (Subgroup Val F1 = 0.8854)\n",
            "  STTC           : Best Threshold = 0.320 (Subgroup Val F1 = 0.7692)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.6 --\n",
            "  Optimizing using 3 samples.\n",
            "  CD             : No positive samples in subgroup. Using global threshold 0.430\n",
            "  HYP            : No positive samples in subgroup. Using global threshold 0.200\n",
            "  MI             : Best Threshold = 0.280 (Subgroup Val F1 = 1.0000)\n",
            "  NORM           : Best Threshold = 0.010 (Subgroup Val F1 = 1.0000)\n",
            "  STTC           : No positive samples in subgroup. Using global threshold 0.340\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.8 --\n",
            "  Optimizing using 75 samples.\n",
            "  CD             : Best Threshold = 0.260 (Subgroup Val F1 = 0.8696)\n",
            "  HYP            : Best Threshold = 0.110 (Subgroup Val F1 = 0.4878)\n",
            "  MI             : Best Threshold = 0.690 (Subgroup Val F1 = 0.8333)\n",
            "  NORM           : Best Threshold = 0.250 (Subgroup Val F1 = 0.8525)\n",
            "  STTC           : Best Threshold = 0.340 (Subgroup Val F1 = 0.7755)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-60    3 --\n",
            "  Optimizing using 182 samples.\n",
            "  CD             : Best Threshold = 0.580 (Subgroup Val F1 = 0.7838)\n",
            "  HYP            : Best Threshold = 0.430 (Subgroup Val F1 = 0.5161)\n",
            "  MI             : Best Threshold = 0.190 (Subgroup Val F1 = 0.7132)\n",
            "  NORM           : Best Threshold = 0.240 (Subgroup Val F1 = 0.8166)\n",
            "  STTC           : Best Threshold = 0.280 (Subgroup Val F1 = 0.7843)\n",
            "\n",
            "-- Optimizing for Subgroup: device = CS-12 --\n",
            "  Optimizing using 644 samples.\n",
            "  CD             : Best Threshold = 0.590 (Subgroup Val F1 = 0.6913)\n",
            "  HYP            : Best Threshold = 0.330 (Subgroup Val F1 = 0.4459)\n",
            "  MI             : Best Threshold = 0.400 (Subgroup Val F1 = 0.7484)\n",
            "  NORM           : Best Threshold = 0.220 (Subgroup Val F1 = 0.8090)\n",
            "  STTC           : Best Threshold = 0.420 (Subgroup Val F1 = 0.7317)\n",
            "\n",
            "-- Optimizing for Subgroup: device = CS-12   E --\n",
            "  Optimizing using 454 samples.\n",
            "  CD             : Best Threshold = 0.430 (Subgroup Val F1 = 0.7414)\n",
            "  HYP            : Best Threshold = 0.140 (Subgroup Val F1 = 0.3182)\n",
            "  MI             : Best Threshold = 0.430 (Subgroup Val F1 = 0.6154)\n",
            "  NORM           : Best Threshold = 0.450 (Subgroup Val F1 = 0.9102)\n",
            "  STTC           : Best Threshold = 0.220 (Subgroup Val F1 = 0.7156)\n",
            "\n",
            "-- Optimizing for Subgroup: device = CS100    3 --\n",
            "  Optimizing using 63 samples.\n",
            "  CD             : Best Threshold = 0.370 (Subgroup Val F1 = 0.6842)\n",
            "  HYP            : Best Threshold = 0.380 (Subgroup Val F1 = 0.8333)\n",
            "  MI             : Best Threshold = 0.690 (Subgroup Val F1 = 0.8986)\n",
            "  NORM           : Best Threshold = 0.150 (Subgroup Val F1 = 0.8947)\n",
            "  STTC           : Best Threshold = 0.510 (Subgroup Val F1 = 0.7660)\n",
            "\n",
            "--- Subgroup Threshold Optimization for 'device' Complete ---\n",
            "\n",
            "==================== Optimizing Subgroup Thresholds for SEED=1018 ====================\n",
            "Inference complete. Found 2183 validation samples.\n",
            "Found unique subgroup values in 'sex': ['0', '1']\n",
            "Optimizing thresholds using 99 steps (step=0.010)...\n",
            "\n",
            "-- Optimizing for Subgroup: sex = 0 --\n",
            "  Optimizing using 1133 samples.\n",
            "  CD             : Best Threshold = 0.250 (Subgroup Val F1 = 0.7612)\n",
            "  HYP            : Best Threshold = 0.190 (Subgroup Val F1 = 0.5156)\n",
            "  MI             : Best Threshold = 0.230 (Subgroup Val F1 = 0.7738)\n",
            "  NORM           : Best Threshold = 0.490 (Subgroup Val F1 = 0.8517)\n",
            "  STTC           : Best Threshold = 0.430 (Subgroup Val F1 = 0.7200)\n",
            "\n",
            "-- Optimizing for Subgroup: sex = 1 --\n",
            "  Optimizing using 1050 samples.\n",
            "  CD             : Best Threshold = 0.230 (Subgroup Val F1 = 0.7411)\n",
            "  HYP            : Best Threshold = 0.230 (Subgroup Val F1 = 0.4481)\n",
            "  MI             : Best Threshold = 0.160 (Subgroup Val F1 = 0.7122)\n",
            "  NORM           : Best Threshold = 0.540 (Subgroup Val F1 = 0.8600)\n",
            "  STTC           : Best Threshold = 0.350 (Subgroup Val F1 = 0.7778)\n",
            "\n",
            "--- Subgroup Threshold Optimization for 'sex' Complete ---\n",
            "Inference complete. Found 2183 validation samples.\n",
            "Found unique subgroup values in 'age_bin': ['0s', '10s', '20s', '30s', '40s', '50s', '60s', '70s', '80s', '90']\n",
            "Optimizing thresholds using 99 steps (step=0.010)...\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 0s --\n",
            "  Optimizing using 1 samples.\n",
            "  CD             : No positive samples in subgroup. Using global threshold 0.240\n",
            "  HYP            : No positive samples in subgroup. Using global threshold 0.190\n",
            "  MI             : No positive samples in subgroup. Using global threshold 0.210\n",
            "  NORM           : Best Threshold = 0.010 (Subgroup Val F1 = 1.0000)\n",
            "  STTC           : No positive samples in subgroup. Using global threshold 0.430\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 10s --\n",
            "  Optimizing using 47 samples.\n",
            "  CD             : Best Threshold = 0.200 (Subgroup Val F1 = 0.6667)\n",
            "  HYP            : Best Threshold = 0.030 (Subgroup Val F1 = 0.2667)\n",
            "  MI             : No positive samples in subgroup. Using global threshold 0.210\n",
            "  NORM           : Best Threshold = 0.030 (Subgroup Val F1 = 0.9425)\n",
            "  STTC           : Best Threshold = 0.050 (Subgroup Val F1 = 0.6667)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 20s --\n",
            "  Optimizing using 101 samples.\n",
            "  CD             : Best Threshold = 0.190 (Subgroup Val F1 = 0.6667)\n",
            "  HYP            : Best Threshold = 0.230 (Subgroup Val F1 = 0.3333)\n",
            "  MI             : Best Threshold = 0.120 (Subgroup Val F1 = 0.5000)\n",
            "  NORM           : Best Threshold = 0.210 (Subgroup Val F1 = 0.9302)\n",
            "  STTC           : Best Threshold = 0.430 (Subgroup Val F1 = 0.7778)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 30s --\n",
            "  Optimizing using 135 samples.\n",
            "  CD             : Best Threshold = 0.240 (Subgroup Val F1 = 0.9032)\n",
            "  HYP            : Best Threshold = 0.140 (Subgroup Val F1 = 0.5556)\n",
            "  MI             : Best Threshold = 0.160 (Subgroup Val F1 = 0.7273)\n",
            "  NORM           : Best Threshold = 0.470 (Subgroup Val F1 = 0.9279)\n",
            "  STTC           : Best Threshold = 0.440 (Subgroup Val F1 = 0.8421)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 40s --\n",
            "  Optimizing using 254 samples.\n",
            "  CD             : Best Threshold = 0.150 (Subgroup Val F1 = 0.7797)\n",
            "  HYP            : Best Threshold = 0.100 (Subgroup Val F1 = 0.5366)\n",
            "  MI             : Best Threshold = 0.210 (Subgroup Val F1 = 0.6897)\n",
            "  NORM           : Best Threshold = 0.590 (Subgroup Val F1 = 0.8995)\n",
            "  STTC           : Best Threshold = 0.380 (Subgroup Val F1 = 0.7458)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 50s --\n",
            "  Optimizing using 415 samples.\n",
            "  CD             : Best Threshold = 0.320 (Subgroup Val F1 = 0.6916)\n",
            "  HYP            : Best Threshold = 0.240 (Subgroup Val F1 = 0.4364)\n",
            "  MI             : Best Threshold = 0.300 (Subgroup Val F1 = 0.7273)\n",
            "  NORM           : Best Threshold = 0.520 (Subgroup Val F1 = 0.8658)\n",
            "  STTC           : Best Threshold = 0.280 (Subgroup Val F1 = 0.7778)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 60s --\n",
            "  Optimizing using 481 samples.\n",
            "  CD             : Best Threshold = 0.250 (Subgroup Val F1 = 0.7215)\n",
            "  HYP            : Best Threshold = 0.230 (Subgroup Val F1 = 0.5605)\n",
            "  MI             : Best Threshold = 0.170 (Subgroup Val F1 = 0.7748)\n",
            "  NORM           : Best Threshold = 0.500 (Subgroup Val F1 = 0.7807)\n",
            "  STTC           : Best Threshold = 0.350 (Subgroup Val F1 = 0.7591)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 70s --\n",
            "  Optimizing using 451 samples.\n",
            "  CD             : Best Threshold = 0.390 (Subgroup Val F1 = 0.8110)\n",
            "  HYP            : Best Threshold = 0.190 (Subgroup Val F1 = 0.4678)\n",
            "  MI             : Best Threshold = 0.220 (Subgroup Val F1 = 0.7530)\n",
            "  NORM           : Best Threshold = 0.540 (Subgroup Val F1 = 0.7915)\n",
            "  STTC           : Best Threshold = 0.550 (Subgroup Val F1 = 0.7560)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 80s --\n",
            "  Optimizing using 256 samples.\n",
            "  CD             : Best Threshold = 0.230 (Subgroup Val F1 = 0.7511)\n",
            "  HYP            : Best Threshold = 0.290 (Subgroup Val F1 = 0.5536)\n",
            "  MI             : Best Threshold = 0.290 (Subgroup Val F1 = 0.7964)\n",
            "  NORM           : Best Threshold = 0.610 (Subgroup Val F1 = 0.7391)\n",
            "  STTC           : Best Threshold = 0.430 (Subgroup Val F1 = 0.7783)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 90 --\n",
            "  Optimizing using 42 samples.\n",
            "  CD             : Best Threshold = 0.530 (Subgroup Val F1 = 0.8980)\n",
            "  HYP            : Best Threshold = 0.190 (Subgroup Val F1 = 0.4615)\n",
            "  MI             : Best Threshold = 0.330 (Subgroup Val F1 = 0.7273)\n",
            "  NORM           : Best Threshold = 0.740 (Subgroup Val F1 = 1.0000)\n",
            "  STTC           : Best Threshold = 0.540 (Subgroup Val F1 = 0.8276)\n",
            "\n",
            "--- Subgroup Threshold Optimization for 'age_bin' Complete ---\n",
            "Inference complete. Found 2183 validation samples.\n",
            "Found unique subgroup values in 'device': ['AT-6     6', 'AT-6 C', 'AT-6 C 5.0', 'AT-6 C 5.3', 'AT-6 C 5.5', 'AT-6 C 5.6', 'AT-6 C 5.8', 'AT-60    3', 'CS-12', 'CS-12   E', 'CS100    3']\n",
            "Optimizing thresholds using 99 steps (step=0.010)...\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6     6 --\n",
            "  Optimizing using 222 samples.\n",
            "  CD             : Best Threshold = 0.250 (Subgroup Val F1 = 0.7759)\n",
            "  HYP            : Best Threshold = 0.170 (Subgroup Val F1 = 0.4938)\n",
            "  MI             : Best Threshold = 0.360 (Subgroup Val F1 = 0.8043)\n",
            "  NORM           : Best Threshold = 0.540 (Subgroup Val F1 = 0.8526)\n",
            "  STTC           : Best Threshold = 0.270 (Subgroup Val F1 = 0.8366)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C --\n",
            "  Optimizing using 119 samples.\n",
            "  CD             : Best Threshold = 0.370 (Subgroup Val F1 = 0.7042)\n",
            "  HYP            : Best Threshold = 0.190 (Subgroup Val F1 = 0.6857)\n",
            "  MI             : Best Threshold = 0.450 (Subgroup Val F1 = 0.8372)\n",
            "  NORM           : Best Threshold = 0.720 (Subgroup Val F1 = 0.7586)\n",
            "  STTC           : Best Threshold = 0.380 (Subgroup Val F1 = 0.8431)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.0 --\n",
            "  Optimizing using 14 samples.\n",
            "  CD             : Best Threshold = 0.200 (Subgroup Val F1 = 1.0000)\n",
            "  HYP            : Best Threshold = 0.120 (Subgroup Val F1 = 0.8889)\n",
            "  MI             : Best Threshold = 0.140 (Subgroup Val F1 = 0.9091)\n",
            "  NORM           : Best Threshold = 0.220 (Subgroup Val F1 = 0.9091)\n",
            "  STTC           : Best Threshold = 0.590 (Subgroup Val F1 = 1.0000)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.3 --\n",
            "  Optimizing using 10 samples.\n",
            "  CD             : Best Threshold = 0.370 (Subgroup Val F1 = 0.8571)\n",
            "  HYP            : Best Threshold = 0.150 (Subgroup Val F1 = 0.8000)\n",
            "  MI             : Best Threshold = 0.070 (Subgroup Val F1 = 1.0000)\n",
            "  NORM           : Best Threshold = 0.370 (Subgroup Val F1 = 0.8889)\n",
            "  STTC           : Best Threshold = 0.270 (Subgroup Val F1 = 1.0000)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.5 --\n",
            "  Optimizing using 397 samples.\n",
            "  CD             : Best Threshold = 0.180 (Subgroup Val F1 = 0.8407)\n",
            "  HYP            : Best Threshold = 0.150 (Subgroup Val F1 = 0.4348)\n",
            "  MI             : Best Threshold = 0.210 (Subgroup Val F1 = 0.7568)\n",
            "  NORM           : Best Threshold = 0.550 (Subgroup Val F1 = 0.8835)\n",
            "  STTC           : Best Threshold = 0.430 (Subgroup Val F1 = 0.7586)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.6 --\n",
            "  Optimizing using 3 samples.\n",
            "  CD             : No positive samples in subgroup. Using global threshold 0.240\n",
            "  HYP            : No positive samples in subgroup. Using global threshold 0.190\n",
            "  MI             : Best Threshold = 0.170 (Subgroup Val F1 = 1.0000)\n",
            "  NORM           : Best Threshold = 0.010 (Subgroup Val F1 = 1.0000)\n",
            "  STTC           : No positive samples in subgroup. Using global threshold 0.430\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.8 --\n",
            "  Optimizing using 75 samples.\n",
            "  CD             : Best Threshold = 0.200 (Subgroup Val F1 = 0.8837)\n",
            "  HYP            : Best Threshold = 0.120 (Subgroup Val F1 = 0.5000)\n",
            "  MI             : Best Threshold = 0.520 (Subgroup Val F1 = 0.8485)\n",
            "  NORM           : Best Threshold = 0.560 (Subgroup Val F1 = 0.8571)\n",
            "  STTC           : Best Threshold = 0.410 (Subgroup Val F1 = 0.7451)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-60    3 --\n",
            "  Optimizing using 182 samples.\n",
            "  CD             : Best Threshold = 0.370 (Subgroup Val F1 = 0.7792)\n",
            "  HYP            : Best Threshold = 0.290 (Subgroup Val F1 = 0.4651)\n",
            "  MI             : Best Threshold = 0.090 (Subgroup Val F1 = 0.7179)\n",
            "  NORM           : Best Threshold = 0.510 (Subgroup Val F1 = 0.8024)\n",
            "  STTC           : Best Threshold = 0.470 (Subgroup Val F1 = 0.7742)\n",
            "\n",
            "-- Optimizing for Subgroup: device = CS-12 --\n",
            "  Optimizing using 644 samples.\n",
            "  CD             : Best Threshold = 0.270 (Subgroup Val F1 = 0.7052)\n",
            "  HYP            : Best Threshold = 0.240 (Subgroup Val F1 = 0.4494)\n",
            "  MI             : Best Threshold = 0.180 (Subgroup Val F1 = 0.7285)\n",
            "  NORM           : Best Threshold = 0.540 (Subgroup Val F1 = 0.8075)\n",
            "  STTC           : Best Threshold = 0.550 (Subgroup Val F1 = 0.7372)\n",
            "\n",
            "-- Optimizing for Subgroup: device = CS-12   E --\n",
            "  Optimizing using 454 samples.\n",
            "  CD             : Best Threshold = 0.460 (Subgroup Val F1 = 0.7475)\n",
            "  HYP            : Best Threshold = 0.130 (Subgroup Val F1 = 0.3415)\n",
            "  MI             : Best Threshold = 0.170 (Subgroup Val F1 = 0.6667)\n",
            "  NORM           : Best Threshold = 0.700 (Subgroup Val F1 = 0.9011)\n",
            "  STTC           : Best Threshold = 0.200 (Subgroup Val F1 = 0.7069)\n",
            "\n",
            "-- Optimizing for Subgroup: device = CS100    3 --\n",
            "  Optimizing using 63 samples.\n",
            "  CD             : Best Threshold = 0.370 (Subgroup Val F1 = 0.7429)\n",
            "  HYP            : Best Threshold = 0.200 (Subgroup Val F1 = 0.7586)\n",
            "  MI             : Best Threshold = 0.130 (Subgroup Val F1 = 0.9041)\n",
            "  NORM           : Best Threshold = 0.310 (Subgroup Val F1 = 0.9444)\n",
            "  STTC           : Best Threshold = 0.300 (Subgroup Val F1 = 0.7273)\n",
            "\n",
            "--- Subgroup Threshold Optimization for 'device' Complete ---\n",
            "\n",
            "==================== Optimizing Subgroup Thresholds for SEED=1016 ====================\n",
            "Inference complete. Found 2183 validation samples.\n",
            "Found unique subgroup values in 'sex': ['0', '1']\n",
            "Optimizing thresholds using 99 steps (step=0.010)...\n",
            "\n",
            "-- Optimizing for Subgroup: sex = 0 --\n",
            "  Optimizing using 1133 samples.\n",
            "  CD             : Best Threshold = 0.270 (Subgroup Val F1 = 0.7628)\n",
            "  HYP            : Best Threshold = 0.240 (Subgroup Val F1 = 0.5143)\n",
            "  MI             : Best Threshold = 0.450 (Subgroup Val F1 = 0.7890)\n",
            "  NORM           : Best Threshold = 0.420 (Subgroup Val F1 = 0.8495)\n",
            "  STTC           : Best Threshold = 0.440 (Subgroup Val F1 = 0.7156)\n",
            "\n",
            "-- Optimizing for Subgroup: sex = 1 --\n",
            "  Optimizing using 1050 samples.\n",
            "  CD             : Best Threshold = 0.240 (Subgroup Val F1 = 0.7611)\n",
            "  HYP            : Best Threshold = 0.280 (Subgroup Val F1 = 0.4790)\n",
            "  MI             : Best Threshold = 0.380 (Subgroup Val F1 = 0.7074)\n",
            "  NORM           : Best Threshold = 0.460 (Subgroup Val F1 = 0.8725)\n",
            "  STTC           : Best Threshold = 0.450 (Subgroup Val F1 = 0.7663)\n",
            "\n",
            "--- Subgroup Threshold Optimization for 'sex' Complete ---\n",
            "Inference complete. Found 2183 validation samples.\n",
            "Found unique subgroup values in 'age_bin': ['0s', '10s', '20s', '30s', '40s', '50s', '60s', '70s', '80s', '90']\n",
            "Optimizing thresholds using 99 steps (step=0.010)...\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 0s --\n",
            "  Optimizing using 1 samples.\n",
            "  CD             : No positive samples in subgroup. Using global threshold 0.250\n",
            "  HYP            : No positive samples in subgroup. Using global threshold 0.290\n",
            "  MI             : No positive samples in subgroup. Using global threshold 0.450\n",
            "  NORM           : Best Threshold = 0.010 (Subgroup Val F1 = 1.0000)\n",
            "  STTC           : No positive samples in subgroup. Using global threshold 0.440\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 10s --\n",
            "  Optimizing using 47 samples.\n",
            "  CD             : Best Threshold = 0.110 (Subgroup Val F1 = 0.6667)\n",
            "  HYP            : Best Threshold = 0.080 (Subgroup Val F1 = 0.3636)\n",
            "  MI             : No positive samples in subgroup. Using global threshold 0.450\n",
            "  NORM           : Best Threshold = 0.010 (Subgroup Val F1 = 0.9425)\n",
            "  STTC           : Best Threshold = 0.520 (Subgroup Val F1 = 0.8000)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 20s --\n",
            "  Optimizing using 101 samples.\n",
            "  CD             : Best Threshold = 0.120 (Subgroup Val F1 = 0.6429)\n",
            "  HYP            : Best Threshold = 0.290 (Subgroup Val F1 = 0.2857)\n",
            "  MI             : Best Threshold = 0.410 (Subgroup Val F1 = 0.6667)\n",
            "  NORM           : Best Threshold = 0.280 (Subgroup Val F1 = 0.9240)\n",
            "  STTC           : Best Threshold = 0.260 (Subgroup Val F1 = 0.6667)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 30s --\n",
            "  Optimizing using 135 samples.\n",
            "  CD             : Best Threshold = 0.220 (Subgroup Val F1 = 0.8824)\n",
            "  HYP            : Best Threshold = 0.190 (Subgroup Val F1 = 0.6250)\n",
            "  MI             : Best Threshold = 0.370 (Subgroup Val F1 = 0.6667)\n",
            "  NORM           : Best Threshold = 0.480 (Subgroup Val F1 = 0.9364)\n",
            "  STTC           : Best Threshold = 0.340 (Subgroup Val F1 = 0.7826)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 40s --\n",
            "  Optimizing using 254 samples.\n",
            "  CD             : Best Threshold = 0.210 (Subgroup Val F1 = 0.7500)\n",
            "  HYP            : Best Threshold = 0.090 (Subgroup Val F1 = 0.4211)\n",
            "  MI             : Best Threshold = 0.410 (Subgroup Val F1 = 0.6557)\n",
            "  NORM           : Best Threshold = 0.480 (Subgroup Val F1 = 0.9000)\n",
            "  STTC           : Best Threshold = 0.300 (Subgroup Val F1 = 0.7419)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 50s --\n",
            "  Optimizing using 415 samples.\n",
            "  CD             : Best Threshold = 0.390 (Subgroup Val F1 = 0.7010)\n",
            "  HYP            : Best Threshold = 0.230 (Subgroup Val F1 = 0.4722)\n",
            "  MI             : Best Threshold = 0.510 (Subgroup Val F1 = 0.7273)\n",
            "  NORM           : Best Threshold = 0.470 (Subgroup Val F1 = 0.8816)\n",
            "  STTC           : Best Threshold = 0.420 (Subgroup Val F1 = 0.7607)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 60s --\n",
            "  Optimizing using 481 samples.\n",
            "  CD             : Best Threshold = 0.240 (Subgroup Val F1 = 0.7389)\n",
            "  HYP            : Best Threshold = 0.350 (Subgroup Val F1 = 0.5735)\n",
            "  MI             : Best Threshold = 0.340 (Subgroup Val F1 = 0.7774)\n",
            "  NORM           : Best Threshold = 0.420 (Subgroup Val F1 = 0.8033)\n",
            "  STTC           : Best Threshold = 0.510 (Subgroup Val F1 = 0.7591)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 70s --\n",
            "  Optimizing using 451 samples.\n",
            "  CD             : Best Threshold = 0.200 (Subgroup Val F1 = 0.7987)\n",
            "  HYP            : Best Threshold = 0.280 (Subgroup Val F1 = 0.5063)\n",
            "  MI             : Best Threshold = 0.390 (Subgroup Val F1 = 0.7601)\n",
            "  NORM           : Best Threshold = 0.410 (Subgroup Val F1 = 0.7837)\n",
            "  STTC           : Best Threshold = 0.450 (Subgroup Val F1 = 0.7284)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 80s --\n",
            "  Optimizing using 256 samples.\n",
            "  CD             : Best Threshold = 0.410 (Subgroup Val F1 = 0.7784)\n",
            "  HYP            : Best Threshold = 0.400 (Subgroup Val F1 = 0.5376)\n",
            "  MI             : Best Threshold = 0.610 (Subgroup Val F1 = 0.8141)\n",
            "  NORM           : Best Threshold = 0.570 (Subgroup Val F1 = 0.7234)\n",
            "  STTC           : Best Threshold = 0.470 (Subgroup Val F1 = 0.7650)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 90 --\n",
            "  Optimizing using 42 samples.\n",
            "  CD             : Best Threshold = 0.160 (Subgroup Val F1 = 0.9259)\n",
            "  HYP            : Best Threshold = 0.250 (Subgroup Val F1 = 0.4444)\n",
            "  MI             : Best Threshold = 0.370 (Subgroup Val F1 = 0.7500)\n",
            "  NORM           : Best Threshold = 0.670 (Subgroup Val F1 = 1.0000)\n",
            "  STTC           : Best Threshold = 0.520 (Subgroup Val F1 = 0.8235)\n",
            "\n",
            "--- Subgroup Threshold Optimization for 'age_bin' Complete ---\n",
            "Inference complete. Found 2183 validation samples.\n",
            "Found unique subgroup values in 'device': ['AT-6     6', 'AT-6 C', 'AT-6 C 5.0', 'AT-6 C 5.3', 'AT-6 C 5.5', 'AT-6 C 5.6', 'AT-6 C 5.8', 'AT-60    3', 'CS-12', 'CS-12   E', 'CS100    3']\n",
            "Optimizing thresholds using 99 steps (step=0.010)...\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6     6 --\n",
            "  Optimizing using 222 samples.\n",
            "  CD             : Best Threshold = 0.320 (Subgroup Val F1 = 0.7788)\n",
            "  HYP            : Best Threshold = 0.240 (Subgroup Val F1 = 0.4878)\n",
            "  MI             : Best Threshold = 0.390 (Subgroup Val F1 = 0.7629)\n",
            "  NORM           : Best Threshold = 0.430 (Subgroup Val F1 = 0.8586)\n",
            "  STTC           : Best Threshold = 0.290 (Subgroup Val F1 = 0.8052)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C --\n",
            "  Optimizing using 119 samples.\n",
            "  CD             : Best Threshold = 0.190 (Subgroup Val F1 = 0.7273)\n",
            "  HYP            : Best Threshold = 0.270 (Subgroup Val F1 = 0.6866)\n",
            "  MI             : Best Threshold = 0.640 (Subgroup Val F1 = 0.8395)\n",
            "  NORM           : Best Threshold = 0.750 (Subgroup Val F1 = 0.7407)\n",
            "  STTC           : Best Threshold = 0.410 (Subgroup Val F1 = 0.8485)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.0 --\n",
            "  Optimizing using 14 samples.\n",
            "  CD             : Best Threshold = 0.180 (Subgroup Val F1 = 1.0000)\n",
            "  HYP            : Best Threshold = 0.120 (Subgroup Val F1 = 0.8333)\n",
            "  MI             : Best Threshold = 0.370 (Subgroup Val F1 = 0.9091)\n",
            "  NORM           : Best Threshold = 0.080 (Subgroup Val F1 = 0.9091)\n",
            "  STTC           : Best Threshold = 0.580 (Subgroup Val F1 = 1.0000)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.3 --\n",
            "  Optimizing using 10 samples.\n",
            "  CD             : Best Threshold = 0.270 (Subgroup Val F1 = 0.8571)\n",
            "  HYP            : Best Threshold = 0.090 (Subgroup Val F1 = 0.8000)\n",
            "  MI             : Best Threshold = 0.250 (Subgroup Val F1 = 1.0000)\n",
            "  NORM           : Best Threshold = 0.160 (Subgroup Val F1 = 0.8889)\n",
            "  STTC           : Best Threshold = 0.250 (Subgroup Val F1 = 1.0000)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.5 --\n",
            "  Optimizing using 397 samples.\n",
            "  CD             : Best Threshold = 0.280 (Subgroup Val F1 = 0.8517)\n",
            "  HYP            : Best Threshold = 0.200 (Subgroup Val F1 = 0.4959)\n",
            "  MI             : Best Threshold = 0.510 (Subgroup Val F1 = 0.7742)\n",
            "  NORM           : Best Threshold = 0.480 (Subgroup Val F1 = 0.8865)\n",
            "  STTC           : Best Threshold = 0.520 (Subgroup Val F1 = 0.7282)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.6 --\n",
            "  Optimizing using 3 samples.\n",
            "  CD             : No positive samples in subgroup. Using global threshold 0.250\n",
            "  HYP            : No positive samples in subgroup. Using global threshold 0.290\n",
            "  MI             : Best Threshold = 0.190 (Subgroup Val F1 = 1.0000)\n",
            "  NORM           : Best Threshold = 0.010 (Subgroup Val F1 = 1.0000)\n",
            "  STTC           : No positive samples in subgroup. Using global threshold 0.440\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.8 --\n",
            "  Optimizing using 75 samples.\n",
            "  CD             : Best Threshold = 0.150 (Subgroup Val F1 = 0.8444)\n",
            "  HYP            : Best Threshold = 0.220 (Subgroup Val F1 = 0.5161)\n",
            "  MI             : Best Threshold = 0.430 (Subgroup Val F1 = 0.8421)\n",
            "  NORM           : Best Threshold = 0.190 (Subgroup Val F1 = 0.8571)\n",
            "  STTC           : Best Threshold = 0.410 (Subgroup Val F1 = 0.7200)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-60    3 --\n",
            "  Optimizing using 182 samples.\n",
            "  CD             : Best Threshold = 0.250 (Subgroup Val F1 = 0.8052)\n",
            "  HYP            : Best Threshold = 0.380 (Subgroup Val F1 = 0.5000)\n",
            "  MI             : Best Threshold = 0.400 (Subgroup Val F1 = 0.7451)\n",
            "  NORM           : Best Threshold = 0.410 (Subgroup Val F1 = 0.8313)\n",
            "  STTC           : Best Threshold = 0.450 (Subgroup Val F1 = 0.7677)\n",
            "\n",
            "-- Optimizing for Subgroup: device = CS-12 --\n",
            "  Optimizing using 644 samples.\n",
            "  CD             : Best Threshold = 0.250 (Subgroup Val F1 = 0.7143)\n",
            "  HYP            : Best Threshold = 0.290 (Subgroup Val F1 = 0.4659)\n",
            "  MI             : Best Threshold = 0.430 (Subgroup Val F1 = 0.7282)\n",
            "  NORM           : Best Threshold = 0.470 (Subgroup Val F1 = 0.8102)\n",
            "  STTC           : Best Threshold = 0.590 (Subgroup Val F1 = 0.7239)\n",
            "\n",
            "-- Optimizing for Subgroup: device = CS-12   E --\n",
            "  Optimizing using 454 samples.\n",
            "  CD             : Best Threshold = 0.200 (Subgroup Val F1 = 0.7018)\n",
            "  HYP            : Best Threshold = 0.130 (Subgroup Val F1 = 0.3860)\n",
            "  MI             : Best Threshold = 0.410 (Subgroup Val F1 = 0.6579)\n",
            "  NORM           : Best Threshold = 0.640 (Subgroup Val F1 = 0.9108)\n",
            "  STTC           : Best Threshold = 0.170 (Subgroup Val F1 = 0.6891)\n",
            "\n",
            "-- Optimizing for Subgroup: device = CS100    3 --\n",
            "  Optimizing using 63 samples.\n",
            "  CD             : Best Threshold = 0.330 (Subgroup Val F1 = 0.7742)\n",
            "  HYP            : Best Threshold = 0.270 (Subgroup Val F1 = 0.7097)\n",
            "  MI             : Best Threshold = 0.510 (Subgroup Val F1 = 0.9429)\n",
            "  NORM           : Best Threshold = 0.180 (Subgroup Val F1 = 0.9189)\n",
            "  STTC           : Best Threshold = 0.480 (Subgroup Val F1 = 0.8085)\n",
            "\n",
            "--- Subgroup Threshold Optimization for 'device' Complete ---\n",
            "\n",
            "==================== Optimizing Subgroup Thresholds for SEED=391 ====================\n",
            "Inference complete. Found 2183 validation samples.\n",
            "Found unique subgroup values in 'sex': ['0', '1']\n",
            "Optimizing thresholds using 99 steps (step=0.010)...\n",
            "\n",
            "-- Optimizing for Subgroup: sex = 0 --\n",
            "  Optimizing using 1133 samples.\n",
            "  CD             : Best Threshold = 0.460 (Subgroup Val F1 = 0.7470)\n",
            "  HYP            : Best Threshold = 0.170 (Subgroup Val F1 = 0.5077)\n",
            "  MI             : Best Threshold = 0.380 (Subgroup Val F1 = 0.7719)\n",
            "  NORM           : Best Threshold = 0.520 (Subgroup Val F1 = 0.8524)\n",
            "  STTC           : Best Threshold = 0.380 (Subgroup Val F1 = 0.7309)\n",
            "\n",
            "-- Optimizing for Subgroup: sex = 1 --\n",
            "  Optimizing using 1050 samples.\n",
            "  CD             : Best Threshold = 0.410 (Subgroup Val F1 = 0.7621)\n",
            "  HYP            : Best Threshold = 0.270 (Subgroup Val F1 = 0.4553)\n",
            "  MI             : Best Threshold = 0.330 (Subgroup Val F1 = 0.6962)\n",
            "  NORM           : Best Threshold = 0.440 (Subgroup Val F1 = 0.8690)\n",
            "  STTC           : Best Threshold = 0.320 (Subgroup Val F1 = 0.7675)\n",
            "\n",
            "--- Subgroup Threshold Optimization for 'sex' Complete ---\n",
            "Inference complete. Found 2183 validation samples.\n",
            "Found unique subgroup values in 'age_bin': ['0s', '10s', '20s', '30s', '40s', '50s', '60s', '70s', '80s', '90']\n",
            "Optimizing thresholds using 99 steps (step=0.010)...\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 0s --\n",
            "  Optimizing using 1 samples.\n",
            "  CD             : No positive samples in subgroup. Using global threshold 0.420\n",
            "  HYP            : No positive samples in subgroup. Using global threshold 0.200\n",
            "  MI             : No positive samples in subgroup. Using global threshold 0.360\n",
            "  NORM           : Best Threshold = 0.010 (Subgroup Val F1 = 1.0000)\n",
            "  STTC           : No positive samples in subgroup. Using global threshold 0.400\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 10s --\n",
            "  Optimizing using 47 samples.\n",
            "  CD             : Best Threshold = 0.150 (Subgroup Val F1 = 0.6667)\n",
            "  HYP            : Best Threshold = 0.010 (Subgroup Val F1 = 0.1481)\n",
            "  MI             : No positive samples in subgroup. Using global threshold 0.360\n",
            "  NORM           : Best Threshold = 0.020 (Subgroup Val F1 = 0.9425)\n",
            "  STTC           : Best Threshold = 0.380 (Subgroup Val F1 = 1.0000)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 20s --\n",
            "  Optimizing using 101 samples.\n",
            "  CD             : Best Threshold = 0.300 (Subgroup Val F1 = 0.7000)\n",
            "  HYP            : Best Threshold = 0.070 (Subgroup Val F1 = 0.2500)\n",
            "  MI             : Best Threshold = 0.220 (Subgroup Val F1 = 0.4444)\n",
            "  NORM           : Best Threshold = 0.270 (Subgroup Val F1 = 0.9349)\n",
            "  STTC           : Best Threshold = 0.530 (Subgroup Val F1 = 0.6667)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 30s --\n",
            "  Optimizing using 135 samples.\n",
            "  CD             : Best Threshold = 0.270 (Subgroup Val F1 = 0.8333)\n",
            "  HYP            : Best Threshold = 0.080 (Subgroup Val F1 = 0.6364)\n",
            "  MI             : Best Threshold = 0.320 (Subgroup Val F1 = 0.7273)\n",
            "  NORM           : Best Threshold = 0.320 (Subgroup Val F1 = 0.9339)\n",
            "  STTC           : Best Threshold = 0.380 (Subgroup Val F1 = 0.8421)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 40s --\n",
            "  Optimizing using 254 samples.\n",
            "  CD             : Best Threshold = 0.160 (Subgroup Val F1 = 0.6857)\n",
            "  HYP            : Best Threshold = 0.090 (Subgroup Val F1 = 0.4167)\n",
            "  MI             : Best Threshold = 0.180 (Subgroup Val F1 = 0.6667)\n",
            "  NORM           : Best Threshold = 0.460 (Subgroup Val F1 = 0.9019)\n",
            "  STTC           : Best Threshold = 0.390 (Subgroup Val F1 = 0.7857)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 50s --\n",
            "  Optimizing using 415 samples.\n",
            "  CD             : Best Threshold = 0.400 (Subgroup Val F1 = 0.6667)\n",
            "  HYP            : Best Threshold = 0.180 (Subgroup Val F1 = 0.3944)\n",
            "  MI             : Best Threshold = 0.410 (Subgroup Val F1 = 0.7027)\n",
            "  NORM           : Best Threshold = 0.520 (Subgroup Val F1 = 0.8659)\n",
            "  STTC           : Best Threshold = 0.320 (Subgroup Val F1 = 0.7657)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 60s --\n",
            "  Optimizing using 481 samples.\n",
            "  CD             : Best Threshold = 0.450 (Subgroup Val F1 = 0.7358)\n",
            "  HYP            : Best Threshold = 0.200 (Subgroup Val F1 = 0.5385)\n",
            "  MI             : Best Threshold = 0.360 (Subgroup Val F1 = 0.7698)\n",
            "  NORM           : Best Threshold = 0.350 (Subgroup Val F1 = 0.7937)\n",
            "  STTC           : Best Threshold = 0.370 (Subgroup Val F1 = 0.7744)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 70s --\n",
            "  Optimizing using 451 samples.\n",
            "  CD             : Best Threshold = 0.370 (Subgroup Val F1 = 0.8000)\n",
            "  HYP            : Best Threshold = 0.210 (Subgroup Val F1 = 0.4886)\n",
            "  MI             : Best Threshold = 0.390 (Subgroup Val F1 = 0.7546)\n",
            "  NORM           : Best Threshold = 0.490 (Subgroup Val F1 = 0.8000)\n",
            "  STTC           : Best Threshold = 0.490 (Subgroup Val F1 = 0.7309)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 80s --\n",
            "  Optimizing using 256 samples.\n",
            "  CD             : Best Threshold = 0.480 (Subgroup Val F1 = 0.7876)\n",
            "  HYP            : Best Threshold = 0.380 (Subgroup Val F1 = 0.5294)\n",
            "  MI             : Best Threshold = 0.500 (Subgroup Val F1 = 0.7783)\n",
            "  NORM           : Best Threshold = 0.440 (Subgroup Val F1 = 0.7170)\n",
            "  STTC           : Best Threshold = 0.310 (Subgroup Val F1 = 0.7699)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 90 --\n",
            "  Optimizing using 42 samples.\n",
            "  CD             : Best Threshold = 0.460 (Subgroup Val F1 = 0.8980)\n",
            "  HYP            : Best Threshold = 0.120 (Subgroup Val F1 = 0.4000)\n",
            "  MI             : Best Threshold = 0.480 (Subgroup Val F1 = 0.7727)\n",
            "  NORM           : Best Threshold = 0.510 (Subgroup Val F1 = 1.0000)\n",
            "  STTC           : Best Threshold = 0.550 (Subgroup Val F1 = 0.8125)\n",
            "\n",
            "--- Subgroup Threshold Optimization for 'age_bin' Complete ---\n",
            "Inference complete. Found 2183 validation samples.\n",
            "Found unique subgroup values in 'device': ['AT-6     6', 'AT-6 C', 'AT-6 C 5.0', 'AT-6 C 5.3', 'AT-6 C 5.5', 'AT-6 C 5.6', 'AT-6 C 5.8', 'AT-60    3', 'CS-12', 'CS-12   E', 'CS100    3']\n",
            "Optimizing thresholds using 99 steps (step=0.010)...\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6     6 --\n",
            "  Optimizing using 222 samples.\n",
            "  CD             : Best Threshold = 0.470 (Subgroup Val F1 = 0.7928)\n",
            "  HYP            : Best Threshold = 0.200 (Subgroup Val F1 = 0.4598)\n",
            "  MI             : Best Threshold = 0.450 (Subgroup Val F1 = 0.7609)\n",
            "  NORM           : Best Threshold = 0.520 (Subgroup Val F1 = 0.8750)\n",
            "  STTC           : Best Threshold = 0.320 (Subgroup Val F1 = 0.8299)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C --\n",
            "  Optimizing using 119 samples.\n",
            "  CD             : Best Threshold = 0.180 (Subgroup Val F1 = 0.6957)\n",
            "  HYP            : Best Threshold = 0.510 (Subgroup Val F1 = 0.6383)\n",
            "  MI             : Best Threshold = 0.680 (Subgroup Val F1 = 0.8642)\n",
            "  NORM           : Best Threshold = 0.550 (Subgroup Val F1 = 0.7333)\n",
            "  STTC           : Best Threshold = 0.390 (Subgroup Val F1 = 0.8515)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.0 --\n",
            "  Optimizing using 14 samples.\n",
            "  CD             : Best Threshold = 0.200 (Subgroup Val F1 = 1.0000)\n",
            "  HYP            : Best Threshold = 0.180 (Subgroup Val F1 = 0.8889)\n",
            "  MI             : Best Threshold = 0.440 (Subgroup Val F1 = 0.9091)\n",
            "  NORM           : Best Threshold = 0.110 (Subgroup Val F1 = 0.9091)\n",
            "  STTC           : Best Threshold = 0.660 (Subgroup Val F1 = 1.0000)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.3 --\n",
            "  Optimizing using 10 samples.\n",
            "  CD             : Best Threshold = 0.540 (Subgroup Val F1 = 1.0000)\n",
            "  HYP            : Best Threshold = 0.140 (Subgroup Val F1 = 0.8000)\n",
            "  MI             : Best Threshold = 0.280 (Subgroup Val F1 = 1.0000)\n",
            "  NORM           : Best Threshold = 0.220 (Subgroup Val F1 = 0.8889)\n",
            "  STTC           : Best Threshold = 0.210 (Subgroup Val F1 = 1.0000)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.5 --\n",
            "  Optimizing using 397 samples.\n",
            "  CD             : Best Threshold = 0.370 (Subgroup Val F1 = 0.8488)\n",
            "  HYP            : Best Threshold = 0.240 (Subgroup Val F1 = 0.4571)\n",
            "  MI             : Best Threshold = 0.380 (Subgroup Val F1 = 0.7889)\n",
            "  NORM           : Best Threshold = 0.500 (Subgroup Val F1 = 0.8925)\n",
            "  STTC           : Best Threshold = 0.350 (Subgroup Val F1 = 0.7511)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.6 --\n",
            "  Optimizing using 3 samples.\n",
            "  CD             : No positive samples in subgroup. Using global threshold 0.420\n",
            "  HYP            : No positive samples in subgroup. Using global threshold 0.200\n",
            "  MI             : Best Threshold = 0.150 (Subgroup Val F1 = 1.0000)\n",
            "  NORM           : Best Threshold = 0.010 (Subgroup Val F1 = 1.0000)\n",
            "  STTC           : No positive samples in subgroup. Using global threshold 0.400\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.8 --\n",
            "  Optimizing using 75 samples.\n",
            "  CD             : Best Threshold = 0.180 (Subgroup Val F1 = 0.8696)\n",
            "  HYP            : Best Threshold = 0.180 (Subgroup Val F1 = 0.4865)\n",
            "  MI             : Best Threshold = 0.490 (Subgroup Val F1 = 0.8421)\n",
            "  NORM           : Best Threshold = 0.410 (Subgroup Val F1 = 0.8421)\n",
            "  STTC           : Best Threshold = 0.460 (Subgroup Val F1 = 0.7500)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-60    3 --\n",
            "  Optimizing using 182 samples.\n",
            "  CD             : Best Threshold = 0.540 (Subgroup Val F1 = 0.7576)\n",
            "  HYP            : Best Threshold = 0.400 (Subgroup Val F1 = 0.4571)\n",
            "  MI             : Best Threshold = 0.180 (Subgroup Val F1 = 0.7333)\n",
            "  NORM           : Best Threshold = 0.500 (Subgroup Val F1 = 0.8171)\n",
            "  STTC           : Best Threshold = 0.450 (Subgroup Val F1 = 0.7500)\n",
            "\n",
            "-- Optimizing for Subgroup: device = CS-12 --\n",
            "  Optimizing using 644 samples.\n",
            "  CD             : Best Threshold = 0.440 (Subgroup Val F1 = 0.7315)\n",
            "  HYP            : Best Threshold = 0.200 (Subgroup Val F1 = 0.4645)\n",
            "  MI             : Best Threshold = 0.240 (Subgroup Val F1 = 0.7289)\n",
            "  NORM           : Best Threshold = 0.450 (Subgroup Val F1 = 0.8178)\n",
            "  STTC           : Best Threshold = 0.470 (Subgroup Val F1 = 0.7236)\n",
            "\n",
            "-- Optimizing for Subgroup: device = CS-12   E --\n",
            "  Optimizing using 454 samples.\n",
            "  CD             : Best Threshold = 0.300 (Subgroup Val F1 = 0.7009)\n",
            "  HYP            : Best Threshold = 0.180 (Subgroup Val F1 = 0.3158)\n",
            "  MI             : Best Threshold = 0.180 (Subgroup Val F1 = 0.5714)\n",
            "  NORM           : Best Threshold = 0.580 (Subgroup Val F1 = 0.9042)\n",
            "  STTC           : Best Threshold = 0.250 (Subgroup Val F1 = 0.6990)\n",
            "\n",
            "-- Optimizing for Subgroup: device = CS100    3 --\n",
            "  Optimizing using 63 samples.\n",
            "  CD             : Best Threshold = 0.270 (Subgroup Val F1 = 0.7429)\n",
            "  HYP            : Best Threshold = 0.400 (Subgroup Val F1 = 0.7200)\n",
            "  MI             : Best Threshold = 0.300 (Subgroup Val F1 = 0.9296)\n",
            "  NORM           : Best Threshold = 0.220 (Subgroup Val F1 = 0.9189)\n",
            "  STTC           : Best Threshold = 0.400 (Subgroup Val F1 = 0.8000)\n",
            "\n",
            "--- Subgroup Threshold Optimization for 'device' Complete ---\n",
            "\n",
            "==================== Optimizing Subgroup Thresholds for SEED=976 ====================\n",
            "Inference complete. Found 2183 validation samples.\n",
            "Found unique subgroup values in 'sex': ['0', '1']\n",
            "Optimizing thresholds using 99 steps (step=0.010)...\n",
            "\n",
            "-- Optimizing for Subgroup: sex = 0 --\n",
            "  Optimizing using 1133 samples.\n",
            "  CD             : Best Threshold = 0.540 (Subgroup Val F1 = 0.7639)\n",
            "  HYP            : Best Threshold = 0.250 (Subgroup Val F1 = 0.5167)\n",
            "  MI             : Best Threshold = 0.240 (Subgroup Val F1 = 0.7692)\n",
            "  NORM           : Best Threshold = 0.450 (Subgroup Val F1 = 0.8511)\n",
            "  STTC           : Best Threshold = 0.340 (Subgroup Val F1 = 0.7333)\n",
            "\n",
            "-- Optimizing for Subgroup: sex = 1 --\n",
            "  Optimizing using 1050 samples.\n",
            "  CD             : Best Threshold = 0.340 (Subgroup Val F1 = 0.7543)\n",
            "  HYP            : Best Threshold = 0.210 (Subgroup Val F1 = 0.4610)\n",
            "  MI             : Best Threshold = 0.430 (Subgroup Val F1 = 0.7102)\n",
            "  NORM           : Best Threshold = 0.490 (Subgroup Val F1 = 0.8640)\n",
            "  STTC           : Best Threshold = 0.330 (Subgroup Val F1 = 0.7919)\n",
            "\n",
            "--- Subgroup Threshold Optimization for 'sex' Complete ---\n",
            "Inference complete. Found 2183 validation samples.\n",
            "Found unique subgroup values in 'age_bin': ['0s', '10s', '20s', '30s', '40s', '50s', '60s', '70s', '80s', '90']\n",
            "Optimizing thresholds using 99 steps (step=0.010)...\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 0s --\n",
            "  Optimizing using 1 samples.\n",
            "  CD             : No positive samples in subgroup. Using global threshold 0.530\n",
            "  HYP            : No positive samples in subgroup. Using global threshold 0.260\n",
            "  MI             : No positive samples in subgroup. Using global threshold 0.440\n",
            "  NORM           : Best Threshold = 0.010 (Subgroup Val F1 = 1.0000)\n",
            "  STTC           : No positive samples in subgroup. Using global threshold 0.340\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 10s --\n",
            "  Optimizing using 47 samples.\n",
            "  CD             : Best Threshold = 0.180 (Subgroup Val F1 = 0.6667)\n",
            "  HYP            : Best Threshold = 0.040 (Subgroup Val F1 = 0.2667)\n",
            "  MI             : No positive samples in subgroup. Using global threshold 0.440\n",
            "  NORM           : Best Threshold = 0.430 (Subgroup Val F1 = 0.9535)\n",
            "  STTC           : Best Threshold = 0.090 (Subgroup Val F1 = 0.6667)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 20s --\n",
            "  Optimizing using 101 samples.\n",
            "  CD             : Best Threshold = 0.530 (Subgroup Val F1 = 0.7000)\n",
            "  HYP            : Best Threshold = 0.100 (Subgroup Val F1 = 0.3077)\n",
            "  MI             : Best Threshold = 0.570 (Subgroup Val F1 = 0.4000)\n",
            "  NORM           : Best Threshold = 0.300 (Subgroup Val F1 = 0.9357)\n",
            "  STTC           : Best Threshold = 0.300 (Subgroup Val F1 = 0.7500)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 30s --\n",
            "  Optimizing using 135 samples.\n",
            "  CD             : Best Threshold = 0.300 (Subgroup Val F1 = 0.9412)\n",
            "  HYP            : Best Threshold = 0.100 (Subgroup Val F1 = 0.6364)\n",
            "  MI             : Best Threshold = 0.390 (Subgroup Val F1 = 0.7273)\n",
            "  NORM           : Best Threshold = 0.490 (Subgroup Val F1 = 0.9238)\n",
            "  STTC           : Best Threshold = 0.340 (Subgroup Val F1 = 0.9000)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 40s --\n",
            "  Optimizing using 254 samples.\n",
            "  CD             : Best Threshold = 0.180 (Subgroup Val F1 = 0.6970)\n",
            "  HYP            : Best Threshold = 0.100 (Subgroup Val F1 = 0.4583)\n",
            "  MI             : Best Threshold = 0.170 (Subgroup Val F1 = 0.6500)\n",
            "  NORM           : Best Threshold = 0.650 (Subgroup Val F1 = 0.9032)\n",
            "  STTC           : Best Threshold = 0.180 (Subgroup Val F1 = 0.7692)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 50s --\n",
            "  Optimizing using 415 samples.\n",
            "  CD             : Best Threshold = 0.540 (Subgroup Val F1 = 0.7400)\n",
            "  HYP            : Best Threshold = 0.250 (Subgroup Val F1 = 0.4444)\n",
            "  MI             : Best Threshold = 0.320 (Subgroup Val F1 = 0.6822)\n",
            "  NORM           : Best Threshold = 0.450 (Subgroup Val F1 = 0.8759)\n",
            "  STTC           : Best Threshold = 0.280 (Subgroup Val F1 = 0.7816)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 60s --\n",
            "  Optimizing using 481 samples.\n",
            "  CD             : Best Threshold = 0.360 (Subgroup Val F1 = 0.7343)\n",
            "  HYP            : Best Threshold = 0.250 (Subgroup Val F1 = 0.5732)\n",
            "  MI             : Best Threshold = 0.280 (Subgroup Val F1 = 0.7818)\n",
            "  NORM           : Best Threshold = 0.530 (Subgroup Val F1 = 0.7921)\n",
            "  STTC           : Best Threshold = 0.320 (Subgroup Val F1 = 0.7774)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 70s --\n",
            "  Optimizing using 451 samples.\n",
            "  CD             : Best Threshold = 0.310 (Subgroup Val F1 = 0.8065)\n",
            "  HYP            : Best Threshold = 0.260 (Subgroup Val F1 = 0.4744)\n",
            "  MI             : Best Threshold = 0.370 (Subgroup Val F1 = 0.7836)\n",
            "  NORM           : Best Threshold = 0.390 (Subgroup Val F1 = 0.7840)\n",
            "  STTC           : Best Threshold = 0.360 (Subgroup Val F1 = 0.7419)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 80s --\n",
            "  Optimizing using 256 samples.\n",
            "  CD             : Best Threshold = 0.520 (Subgroup Val F1 = 0.7668)\n",
            "  HYP            : Best Threshold = 0.330 (Subgroup Val F1 = 0.5243)\n",
            "  MI             : Best Threshold = 0.520 (Subgroup Val F1 = 0.7713)\n",
            "  NORM           : Best Threshold = 0.620 (Subgroup Val F1 = 0.7273)\n",
            "  STTC           : Best Threshold = 0.360 (Subgroup Val F1 = 0.7748)\n",
            "\n",
            "-- Optimizing for Subgroup: age_bin = 90 --\n",
            "  Optimizing using 42 samples.\n",
            "  CD             : Best Threshold = 0.240 (Subgroup Val F1 = 0.9091)\n",
            "  HYP            : Best Threshold = 0.200 (Subgroup Val F1 = 0.6087)\n",
            "  MI             : Best Threshold = 0.440 (Subgroup Val F1 = 0.7727)\n",
            "  NORM           : Best Threshold = 0.620 (Subgroup Val F1 = 1.0000)\n",
            "  STTC           : Best Threshold = 0.520 (Subgroup Val F1 = 0.8571)\n",
            "\n",
            "--- Subgroup Threshold Optimization for 'age_bin' Complete ---\n",
            "Inference complete. Found 2183 validation samples.\n",
            "Found unique subgroup values in 'device': ['AT-6     6', 'AT-6 C', 'AT-6 C 5.0', 'AT-6 C 5.3', 'AT-6 C 5.5', 'AT-6 C 5.6', 'AT-6 C 5.8', 'AT-60    3', 'CS-12', 'CS-12   E', 'CS100    3']\n",
            "Optimizing thresholds using 99 steps (step=0.010)...\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6     6 --\n",
            "  Optimizing using 222 samples.\n",
            "  CD             : Best Threshold = 0.480 (Subgroup Val F1 = 0.7818)\n",
            "  HYP            : Best Threshold = 0.210 (Subgroup Val F1 = 0.4944)\n",
            "  MI             : Best Threshold = 0.450 (Subgroup Val F1 = 0.8041)\n",
            "  NORM           : Best Threshold = 0.390 (Subgroup Val F1 = 0.8500)\n",
            "  STTC           : Best Threshold = 0.270 (Subgroup Val F1 = 0.8252)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C --\n",
            "  Optimizing using 119 samples.\n",
            "  CD             : Best Threshold = 0.170 (Subgroup Val F1 = 0.7191)\n",
            "  HYP            : Best Threshold = 0.320 (Subgroup Val F1 = 0.6909)\n",
            "  MI             : Best Threshold = 0.440 (Subgroup Val F1 = 0.8211)\n",
            "  NORM           : Best Threshold = 0.710 (Subgroup Val F1 = 0.7692)\n",
            "  STTC           : Best Threshold = 0.330 (Subgroup Val F1 = 0.8515)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.0 --\n",
            "  Optimizing using 14 samples.\n",
            "  CD             : Best Threshold = 0.180 (Subgroup Val F1 = 1.0000)\n",
            "  HYP            : Best Threshold = 0.220 (Subgroup Val F1 = 0.8889)\n",
            "  MI             : Best Threshold = 0.450 (Subgroup Val F1 = 0.9091)\n",
            "  NORM           : Best Threshold = 0.170 (Subgroup Val F1 = 0.9091)\n",
            "  STTC           : Best Threshold = 0.610 (Subgroup Val F1 = 1.0000)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.3 --\n",
            "  Optimizing using 10 samples.\n",
            "  CD             : Best Threshold = 0.200 (Subgroup Val F1 = 0.8571)\n",
            "  HYP            : Best Threshold = 0.110 (Subgroup Val F1 = 0.8000)\n",
            "  MI             : Best Threshold = 0.210 (Subgroup Val F1 = 1.0000)\n",
            "  NORM           : Best Threshold = 0.290 (Subgroup Val F1 = 0.8889)\n",
            "  STTC           : Best Threshold = 0.180 (Subgroup Val F1 = 1.0000)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.5 --\n",
            "  Optimizing using 397 samples.\n",
            "  CD             : Best Threshold = 0.340 (Subgroup Val F1 = 0.8440)\n",
            "  HYP            : Best Threshold = 0.230 (Subgroup Val F1 = 0.4954)\n",
            "  MI             : Best Threshold = 0.370 (Subgroup Val F1 = 0.7676)\n",
            "  NORM           : Best Threshold = 0.490 (Subgroup Val F1 = 0.8853)\n",
            "  STTC           : Best Threshold = 0.350 (Subgroup Val F1 = 0.7751)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.6 --\n",
            "  Optimizing using 3 samples.\n",
            "  CD             : No positive samples in subgroup. Using global threshold 0.530\n",
            "  HYP            : No positive samples in subgroup. Using global threshold 0.260\n",
            "  MI             : Best Threshold = 0.230 (Subgroup Val F1 = 1.0000)\n",
            "  NORM           : Best Threshold = 0.010 (Subgroup Val F1 = 1.0000)\n",
            "  STTC           : No positive samples in subgroup. Using global threshold 0.340\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-6 C 5.8 --\n",
            "  Optimizing using 75 samples.\n",
            "  CD             : Best Threshold = 0.240 (Subgroup Val F1 = 0.8837)\n",
            "  HYP            : Best Threshold = 0.250 (Subgroup Val F1 = 0.5714)\n",
            "  MI             : Best Threshold = 0.580 (Subgroup Val F1 = 0.8421)\n",
            "  NORM           : Best Threshold = 0.420 (Subgroup Val F1 = 0.8276)\n",
            "  STTC           : Best Threshold = 0.430 (Subgroup Val F1 = 0.7391)\n",
            "\n",
            "-- Optimizing for Subgroup: device = AT-60    3 --\n",
            "  Optimizing using 182 samples.\n",
            "  CD             : Best Threshold = 0.400 (Subgroup Val F1 = 0.7895)\n",
            "  HYP            : Best Threshold = 0.320 (Subgroup Val F1 = 0.4615)\n",
            "  MI             : Best Threshold = 0.210 (Subgroup Val F1 = 0.7227)\n",
            "  NORM           : Best Threshold = 0.250 (Subgroup Val F1 = 0.8156)\n",
            "  STTC           : Best Threshold = 0.300 (Subgroup Val F1 = 0.7723)\n",
            "\n",
            "-- Optimizing for Subgroup: device = CS-12 --\n",
            "  Optimizing using 644 samples.\n",
            "  CD             : Best Threshold = 0.530 (Subgroup Val F1 = 0.7162)\n",
            "  HYP            : Best Threshold = 0.260 (Subgroup Val F1 = 0.4419)\n",
            "  MI             : Best Threshold = 0.240 (Subgroup Val F1 = 0.7415)\n",
            "  NORM           : Best Threshold = 0.530 (Subgroup Val F1 = 0.8137)\n",
            "  STTC           : Best Threshold = 0.360 (Subgroup Val F1 = 0.7342)\n",
            "\n",
            "-- Optimizing for Subgroup: device = CS-12   E --\n",
            "  Optimizing using 454 samples.\n",
            "  CD             : Best Threshold = 0.540 (Subgroup Val F1 = 0.7423)\n",
            "  HYP            : Best Threshold = 0.100 (Subgroup Val F1 = 0.3284)\n",
            "  MI             : Best Threshold = 0.190 (Subgroup Val F1 = 0.5657)\n",
            "  NORM           : Best Threshold = 0.620 (Subgroup Val F1 = 0.9083)\n",
            "  STTC           : Best Threshold = 0.270 (Subgroup Val F1 = 0.7273)\n",
            "\n",
            "-- Optimizing for Subgroup: device = CS100    3 --\n",
            "  Optimizing using 63 samples.\n",
            "  CD             : Best Threshold = 0.440 (Subgroup Val F1 = 0.8125)\n",
            "  HYP            : Best Threshold = 0.400 (Subgroup Val F1 = 0.8182)\n",
            "  MI             : Best Threshold = 0.300 (Subgroup Val F1 = 0.9315)\n",
            "  NORM           : Best Threshold = 0.300 (Subgroup Val F1 = 0.9444)\n",
            "  STTC           : Best Threshold = 0.330 (Subgroup Val F1 = 0.8364)\n",
            "\n",
            "--- Subgroup Threshold Optimization for 'device' Complete ---\n",
            "\n",
            "Saving computed subgroup thresholds per seed to: optimization_results/optimized_subgroup_thresholds_per_seed_DA_False.pkl\n",
            "Optimized subgroup thresholds per seed saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# ===== START OF EVALUATION AND AGGREGATION CODE ===============================\n",
        "# ==============================================================================\n",
        "# --- Configuration for Evaluation ---\n",
        "MODEL_SAVE_DIRECTORY = 'saved_models' # Directory where models are saved\n",
        "NUM_EPOCHS = 30 # Number of epochs models were trained for (used in filename)\n",
        "RESULTS_DIR = 'evaluation_results' # Directory to save results files\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "# --- Validate Test Data (Ensure variables from loading step exist) ---\n",
        "if 'test_df' not in locals() or test_df is None: print(\"Error: 'test_df' not available.\"); exit()\n",
        "if 'mlb' not in locals() or mlb is None: print(\"Error: 'mlb' not available.\"); exit()\n",
        "if 'test_loader' not in locals() or test_loader is None: print(\"Error: 'test_loader' not available.\"); exit()\n",
        "\n",
        "required_cols = ['sex', 'age_bin', 'device']\n",
        "if not all(col in test_df.columns for col in required_cols):\n",
        "    print(f\"Error: test_df missing columns: {required_cols}\"); exit()\n",
        "# Ensure consistent data types (strings recommended for categorical keys)\n",
        "test_df['age_bin'] = test_df['age_bin'].astype(str)\n",
        "test_df['device'] = test_df['device'].astype(str)\n",
        "test_df['sex'] = test_df['sex'].astype(str) # Use '0', '1'\n",
        "\n",
        "target_classes = list(mlb.classes_)\n",
        "num_classes = len(target_classes)\n",
        "print(f\"Number of classes for evaluation: {num_classes}\")\n",
        "print(f\"Target classes: {target_classes}\")\n",
        "\n",
        "EXPERIMENTAL_CONDITIONS = {\n",
        "    # Condition Name: { Parameters }\n",
        "    'Optimized_Global': { # Experiment 1\n",
        "        'DA_flag': False,\n",
        "        'threshold_mode': 'global_optimized',\n",
        "        'subgroup_focus': None # Not applicable, uses global array\n",
        "    },\n",
        "    'Optimized_Subgroup_Combined': { # Experiment 2 (Sex + Age + Device)\n",
        "        'DA_flag': False,\n",
        "        'threshold_mode': 'subgroup',\n",
        "        'subgroup_focus': 'combined' # Special keyword for combined effect\n",
        "    },\n",
        "    'Optimized_Subgroup_Sex': { # Experiment 3 (Sex Only)\n",
        "        'DA_flag': False,\n",
        "        'threshold_mode': 'subgroup',\n",
        "        'subgroup_focus': 'sex' # Focus only on sex thresholds\n",
        "    },\n",
        "    'Optimized_Subgroup_Age': { # Experiment 4 (Age Only)\n",
        "        'DA_flag': False,\n",
        "        'threshold_mode': 'subgroup',\n",
        "        'subgroup_focus': 'age_bin' # Focus only on age thresholds\n",
        "    },\n",
        "    'Optimized_Subgroup_Device': { # Experiment 5 (Device Only)\n",
        "        'DA_flag': False,\n",
        "        'threshold_mode': 'subgroup',\n",
        "        'subgroup_focus': 'device' # Focus only on device thresholds\n",
        "    },\n",
        "}\n",
        "\n",
        "# --- Flexible Detailed Evaluation Function ---\n",
        "def evaluate_model_detailed(model_path, test_loader, test_df, mlb, device, thresholds_arg):\n",
        "    \"\"\"\n",
        "    Evaluates model with detailed subgroup analysis. Handles global (float/array)\n",
        "    or subgroup-specific (dict) thresholds passed via thresholds_arg.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Starting Detailed Evaluation for Model: {os.path.basename(model_path)} ---\")\n",
        "    # Basic Validation\n",
        "    if not os.path.exists(model_path): print(f\"Error: Model not found: {model_path}\"); return None\n",
        "    if len(test_loader.dataset) != len(test_df): print(\"Error: Mismatch test_loader/test_df\"); return None\n",
        "\n",
        "    target_classes_eval = list(mlb.classes_)\n",
        "    num_classes_eval = len(target_classes_eval)\n",
        "    class_to_index = {cls_name: idx for idx, cls_name in enumerate(target_classes_eval)}\n",
        "\n",
        "    # Load Model\n",
        "    try:\n",
        "        model = ECGCNN(num_classes=num_classes_eval)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "        print(\"Model loaded successfully.\")\n",
        "    except Exception as e: print(f\"Error loading model: {e}\"); return None\n",
        "\n",
        "    # Run Inference\n",
        "    all_probs_list, all_labels_list = [], []\n",
        "    print(\"Running inference...\")\n",
        "    with torch.no_grad():\n",
        "        for signals, labels in test_loader:\n",
        "            signals = signals.to(device); outputs = model(signals); probs = torch.sigmoid(outputs)\n",
        "            all_probs_list.append(probs.cpu().numpy()); all_labels_list.append(labels.cpu().numpy())\n",
        "    all_probs = np.concatenate(all_probs_list, axis=0)\n",
        "    all_labels = np.concatenate(all_labels_list, axis=0).astype(int)\n",
        "    print(\"Inference complete. Calculating metrics...\")\n",
        "\n",
        "    # --- Determine Thresholding Mode and Set Fallback ---\n",
        "    thresholds_dict = None # Will hold the dict if mode is subgroup\n",
        "    if isinstance(thresholds_arg, dict):\n",
        "        print(\"Using Subgroup-Specific Threshold Dictionary.\")\n",
        "        threshold_mode = 'subgroup'\n",
        "        thresholds_dict = thresholds_arg\n",
        "        if 'all' not in thresholds_dict: print(\"Error: Threshold dict must contain 'all' key.\"); return None\n",
        "        fallback_thresholds = thresholds_dict['all']\n",
        "        if not isinstance(fallback_thresholds, np.ndarray) or fallback_thresholds.shape != (num_classes_eval,): print(f\"Error: thresholds_dict['all'] invalid.\"); return None\n",
        "    elif isinstance(thresholds_arg, (np.ndarray, list)):\n",
        "         print(\"Using Global Per-Class Threshold Array.\")\n",
        "         threshold_mode = 'global_array'\n",
        "         fallback_thresholds = np.array(thresholds_arg)\n",
        "         if fallback_thresholds.shape != (num_classes_eval,): print(f\"Error: Global threshold array shape invalid.\"); return None\n",
        "    elif isinstance(thresholds_arg, (float, int)):\n",
        "         print(f\"Using Single Global Threshold Value: {thresholds_arg}\")\n",
        "         threshold_mode = 'global_single'\n",
        "         fallback_thresholds = np.array([float(thresholds_arg)] * num_classes_eval)\n",
        "    else:\n",
        "         print(\"Error: Invalid thresholds argument type.\"); return None\n",
        "\n",
        "    # Prepare Results Structure\n",
        "    results = {'all': {}, 'sex': {}, 'age_bin': {}, 'device': {}, 'diagnostic_class': {}, 'overall_metrics': {}}\n",
        "\n",
        "    # Calculate 'all' metrics using fallback/global thresholds\n",
        "    print(\"\\n--- Overall Metrics (All Samples) ---\")\n",
        "    all_preds_overall = (all_probs >= fallback_thresholds).astype(int)\n",
        "    results['all'] = calculate_subgroup_metrics(all_labels, all_preds_overall, target_classes_eval)\n",
        "    for metric, value in results['all'].items():\n",
        "         if not isinstance(value, dict): print(f\"  {metric}: {value:.4f}\" if isinstance(value, float) else f\"  {metric}: {value}\")\n",
        "\n",
        "    # Calculate Metrics for Subgroups\n",
        "    subgroup_types = ['sex', 'age_bin', 'device', 'diagnostic_class']\n",
        "    for sg_type in subgroup_types:\n",
        "        print(f\"\\n--- Metrics by Subgroup Type: {sg_type.upper()} ---\")\n",
        "        unique_values = target_classes_eval if sg_type == 'diagnostic_class' else test_df[sg_type].unique()\n",
        "\n",
        "        for value in unique_values:\n",
        "            value_str = str(value); print(f\" -- Subgroup: {value_str} --\")\n",
        "            # Create mask\n",
        "            if sg_type == 'diagnostic_class':\n",
        "                 class_index = class_to_index.get(value);\n",
        "                 if class_index is None: continue\n",
        "                 mask = (all_labels[:, class_index] == 1)\n",
        "            else: mask = (test_df[sg_type].values == value_str)\n",
        "\n",
        "            if np.sum(mask) == 0:\n",
        "                 print(\"   (N=0) Skipping.\"); results[sg_type][value_str] = calculate_subgroup_metrics(np.array([]), np.array([]), target_classes_eval); continue\n",
        "\n",
        "            group_labels_sub = all_labels[mask]\n",
        "            group_probs_sub = all_probs[mask]\n",
        "\n",
        "            # Determine and Apply Thresholds for THIS subgroup\n",
        "            applied_threshold_source = \"Fallback/Global\"\n",
        "            if threshold_mode == 'subgroup':\n",
        "                current_thresholds = thresholds_dict.get(sg_type, {}).get(value_str, fallback_thresholds)\n",
        "                if not isinstance(current_thresholds, np.ndarray) or current_thresholds.shape != (num_classes_eval,):\n",
        "                    print(f\"Warning: Invalid stored threshold for {sg_type}/{value_str}. Using fallback.\"); current_thresholds = fallback_thresholds\n",
        "                elif value_str in thresholds_dict.get(sg_type, {}): applied_threshold_source = \"Specific\" # Mark if specific threshold was found and used\n",
        "            else: current_thresholds = fallback_thresholds # Use global thresholds\n",
        "\n",
        "            group_preds_sub = (group_probs_sub >= current_thresholds).astype(int)\n",
        "\n",
        "            # Calculate metrics\n",
        "            subgroup_metrics = calculate_subgroup_metrics(group_labels_sub, group_preds_sub, target_classes_eval)\n",
        "            results[sg_type][value_str] = subgroup_metrics\n",
        "\n",
        "            # Print summary\n",
        "            print(f\"   (N={subgroup_metrics['num_samples']}) Applied thresholds: {applied_threshold_source}\")\n",
        "            if subgroup_metrics['num_samples'] > 0: print(f\"   Macro F1: {subgroup_metrics['f1_macro']:.4f}; Exact Match: {subgroup_metrics['exact_match_ratio']:.4f}\")\n",
        "\n",
        "    # Calculate Specific Cross-Group Metrics (Avg Male/Female)\n",
        "    male_key, female_key = '1', '0'\n",
        "    results['overall_metrics']['avg_macro_recall_male_female'] = np.nan\n",
        "    results['overall_metrics']['avg_macro_precision_male_female'] = np.nan\n",
        "    results['overall_metrics']['avg_macro_f1_male_female'] = np.nan\n",
        "    if male_key in results['sex'] and female_key in results['sex'] and results['sex'][male_key].get('num_samples', 0) > 0 and results['sex'][female_key].get('num_samples', 0) > 0:\n",
        "        male_metrics = results['sex'][male_key]; female_metrics = results['sex'][female_key]\n",
        "        if not np.isnan(male_metrics.get('recall_macro', np.nan)) and not np.isnan(female_metrics.get('recall_macro', np.nan)): results['overall_metrics']['avg_macro_recall_male_female'] = (male_metrics['recall_macro'] + female_metrics['recall_macro']) / 2\n",
        "        if not np.isnan(male_metrics.get('precision_macro', np.nan)) and not np.isnan(female_metrics.get('precision_macro', np.nan)): results['overall_metrics']['avg_macro_precision_male_female'] = (male_metrics['precision_macro'] + female_metrics['precision_macro']) / 2\n",
        "        if not np.isnan(male_metrics.get('f1_macro', np.nan)) and not np.isnan(female_metrics.get('f1_macro', np.nan)): results['overall_metrics']['avg_macro_f1_male_female'] = (male_metrics['f1_macro'] + female_metrics['f1_macro']) / 2\n",
        "        print(\"\\n--- Cross-Group Metrics ---\"); print(f\"  Avg Macro F1 (M/F): {results['overall_metrics']['avg_macro_f1_male_female']:.4f}\")\n",
        "    else: print(\"\\nWarning: Cannot calculate average male/female metrics.\")\n",
        "\n",
        "    print(\"\\n--- Detailed Evaluation Complete ---\")\n",
        "    return results\n",
        "\n",
        "\n",
        "# --- Main Evaluation Loop ---\n",
        "# Structure: {condition_name: {seed: evaluation_dict}}\n",
        "all_evaluation_results = {name: {} for name in EXPERIMENTAL_CONDITIONS.keys()}\n",
        "\n",
        "# Assuming `all_seeds` list is defined earlier and `optimized_thresholds_per_seed` is populated\n",
        "if 'all_seeds' not in locals(): print(\"Error: `all_seeds` not defined.\"); exit()\n",
        "if 'optimized_thresholds_per_seed' not in locals(): print(\"Error: `optimized_thresholds_per_seed` not defined.\"); exit()\n",
        "\n",
        "for condition_name, condition_params in EXPERIMENTAL_CONDITIONS.items():\n",
        "    print(f\"\\n{'='*20} Evaluating Condition: {condition_name} {'='*20}\")\n",
        "    current_da_flag = condition_params['DA_flag']\n",
        "    threshold_mode = condition_params['threshold_mode']\n",
        "    subgroup_focus = condition_params.get('subgroup_focus') # Get the focus for subgroup modes\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {DEVICE}, DA Flag: {current_da_flag}, Thresh Mode: {threshold_mode}, Focus: {subgroup_focus}\")\n",
        "\n",
        "    for current_seed in all_seeds:\n",
        "        print(f\"\\n-- Evaluating SEED={current_seed} --\")\n",
        "        base_name_prefix = f\"model_seed_{current_seed}{'_DA' if current_da_flag else ''}\"\n",
        "        final_model_filename = f\"final_{base_name_prefix}_epoch_{NUM_EPOCHS}.pth\"\n",
        "        model_path = os.path.join(MODEL_SAVE_DIRECTORY, final_model_filename)\n",
        "\n",
        "        if not os.path.exists(model_path):\n",
        "            print(f\"Warning: Model file not found: {model_path}. Skipping.\"); all_evaluation_results[condition_name][current_seed] = None; continue\n",
        "\n",
        "        # --- *** MODIFIED THRESHOLD FETCHING *** ---\n",
        "        current_thresholds_arg = None\n",
        "        try:\n",
        "            # --- Handle GLOBAL mode (Experiment 1) ---\n",
        "            if threshold_mode == 'global_optimized':\n",
        "                if current_seed in optimized_thresholds_per_seed:\n",
        "                    current_thresholds_arg = optimized_thresholds_per_seed[current_seed]\n",
        "                    print(f\"Using optimized global thresholds for seed {current_seed}.\")\n",
        "                    if not isinstance(current_thresholds_arg, np.ndarray) or current_thresholds_arg.shape[0] != num_classes:\n",
        "                         raise ValueError(\"Invalid global threshold array found.\")\n",
        "                else:\n",
        "                    raise KeyError(f\"Optimized global thresholds for seed {current_seed} not found!\")\n",
        "\n",
        "            # --- Handle SUBGROUP modes (Experiments 2, 3, 4, 5) ---\n",
        "            elif threshold_mode == 'subgroup':\n",
        "                if current_seed not in optimized_thresholds_per_seed or current_seed not in optimized_subgroup_thresholds_per_seed_result:\n",
        "                     raise KeyError(f\"Required optimized thresholds (global or subgroup) missing for seed {current_seed}\")\n",
        "\n",
        "                # Always get the optimized global thresholds for fallback\n",
        "                global_fallback = optimized_thresholds_per_seed[current_seed]\n",
        "                if not isinstance(global_fallback, np.ndarray) or global_fallback.shape[0] != num_classes:\n",
        "                     raise ValueError(\"Invalid global threshold array found for fallback.\")\n",
        "\n",
        "                # Get the full dictionary of all optimized subgroup thresholds for this seed\n",
        "                all_subgroup_thresholds_this_seed = optimized_subgroup_thresholds_per_seed_result[current_seed]\n",
        "\n",
        "                # Build the argument dictionary based on subgroup_focus\n",
        "                current_thresholds_arg = {'all': global_fallback} # Start with the fallback\n",
        "\n",
        "                if subgroup_focus == 'combined': # Experiment 2\n",
        "                    print(f\"Using COMBINED optimized subgroup thresholds (Sex+Age+Device) for seed {current_seed}.\")\n",
        "                    current_thresholds_arg['sex'] = all_subgroup_thresholds_this_seed.get('sex', {})\n",
        "                    current_thresholds_arg['age_bin'] = all_subgroup_thresholds_this_seed.get('age_bin', {})\n",
        "                    current_thresholds_arg['device'] = all_subgroup_thresholds_this_seed.get('device', {})\n",
        "                    # Add 'diagnostic_class' if optimized:\n",
        "                    # current_thresholds_arg['diagnostic_class'] = all_subgroup_thresholds_this_seed.get('diagnostic_class', {})\n",
        "\n",
        "                elif subgroup_focus == 'sex': # Experiment 3\n",
        "                    print(f\"Using SEX optimized subgroup thresholds ONLY for seed {current_seed}.\")\n",
        "                    current_thresholds_arg['sex'] = all_subgroup_thresholds_this_seed.get('sex', {})\n",
        "                    # Age/Device keys omitted -> evaluate_model_detailed will use 'all' fallback\n",
        "\n",
        "                elif subgroup_focus == 'age_bin': # Experiment 4\n",
        "                    print(f\"Using AGE optimized subgroup thresholds ONLY for seed {current_seed}.\")\n",
        "                    current_thresholds_arg['age_bin'] = all_subgroup_thresholds_this_seed.get('age_bin', {})\n",
        "                     # Sex/Device keys omitted -> evaluate_model_detailed will use 'all' fallback\n",
        "\n",
        "                elif subgroup_focus == 'device': # Experiment 5\n",
        "                    print(f\"Using DEVICE optimized subgroup thresholds ONLY for seed {current_seed}.\")\n",
        "                    current_thresholds_arg['device'] = all_subgroup_thresholds_this_seed.get('device', {})\n",
        "                     # Sex/Age keys omitted -> evaluate_model_detailed will use 'all' fallback\n",
        "\n",
        "                else:\n",
        "                    raise ValueError(f\"Invalid subgroup_focus '{subgroup_focus}' for condition '{condition_name}'\")\n",
        "\n",
        "            # --- Handle other modes if needed ---\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown threshold_mode '{threshold_mode}'.\")\n",
        "\n",
        "        except (KeyError, ValueError) as e:\n",
        "             print(f\"ERROR fetching/validating thresholds for seed {current_seed}, condition {condition_name}: {e}. Using default 0.5.\")\n",
        "             # For subgroup mode, create a minimal fallback dict\n",
        "             if threshold_mode == 'subgroup':\n",
        "                 current_thresholds_arg = {'all': np.full(num_classes, 0.5)}\n",
        "             else: # Global mode fallback\n",
        "                 current_thresholds_arg = np.full(num_classes, 0.5)\n",
        "\n",
        "        # Ensure thresholds_arg is assigned\n",
        "        if current_thresholds_arg is None:\n",
        "            print(f\"CRITICAL ERROR: Failed to determine thresholds_arg for seed {current_seed}, condition {condition_name}. Using fallback.\")\n",
        "            if threshold_mode == 'subgroup':\n",
        "                 current_thresholds_arg = {'all': np.full(num_classes, 0.5)}\n",
        "            else:\n",
        "                 current_thresholds_arg = np.full(num_classes, 0.5)\n",
        "        # --- *** END THRESHOLD FETCHING *** ---\n",
        "\n",
        "        # Call evaluation (No change needed here)\n",
        "        results_this_seed = evaluate_model_detailed(\n",
        "            model_path=model_path, test_loader=test_loader, test_df=test_df, mlb=mlb, device=DEVICE,\n",
        "            thresholds_arg=current_thresholds_arg # Pass the dynamically built thresholds dict/array\n",
        "        )\n",
        "\n",
        "        all_evaluation_results[condition_name][current_seed] = results_this_seed\n",
        "        if results_this_seed: print(f\"Evaluation complete for seed {current_seed}.\")\n",
        "        else: print(f\"Evaluation failed for seed {current_seed}.\")\n",
        "\n",
        "\n",
        "# --- Save Raw Evaluation Results ---\n",
        "results_save_filename = 'all_evaluation_results_raw.pkl'\n",
        "results_save_path = os.path.join(RESULTS_DIR, results_save_filename)\n",
        "print(f\"\\nSaving detailed raw evaluation results to: {results_save_path}\")\n",
        "try:\n",
        "    with open(results_save_path, 'wb') as f: pickle.dump(all_evaluation_results, f)\n",
        "    print(\"Raw results saved successfully.\")\n",
        "except Exception as e: print(f\"Error saving raw results: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "# --- Step 5: Aggregation and Reporting ---\n",
        "print(f\"\\n{'='*20} Aggregating Evaluation Results Across Seeds {'='*20}\")\n",
        "\n",
        "# Ensure the raw results dictionary from the evaluation loop is available\n",
        "if 'all_evaluation_results' not in locals() or not all_evaluation_results:\n",
        "    print(\"Error: 'all_evaluation_results' dictionary not found or is empty. Cannot aggregate.\")\n",
        "else:\n",
        "    print(\"Using existing 'all_evaluation_results' dictionary.\")\n",
        "\n",
        "\n",
        "# Structure for aggregated stats: {condition_name: {top_level_key: {subgroup_name_or_metric: {metric_or_stats_dict}}}}\n",
        "# Initialize the dictionary to store aggregated results\n",
        "aggregated_stats = {cond_name: {} for cond_name in all_evaluation_results.keys()}\n",
        "\n",
        "# Loop through each experimental condition IN THE RAW RESULTS\n",
        "for condition_name, seed_results_dict in all_evaluation_results.items():\n",
        "    print(f\"\\n--- Aggregating for Condition: {condition_name} ---\")\n",
        "\n",
        "    # Filter out seeds where evaluation might have failed (result is None)\n",
        "    valid_seed_results = [res for res in seed_results_dict.values() if isinstance(res, dict)]\n",
        "\n",
        "    if not valid_seed_results:\n",
        "        print(\"  No valid evaluation results found for this condition. Skipping aggregation.\")\n",
        "        aggregated_stats[condition_name] = {} # Store empty dict for this condition\n",
        "        continue # Skip to the next condition\n",
        "\n",
        "    print(f\"  Aggregating from {len(valid_seed_results)} valid run(s).\")\n",
        "    aggregated_stats[condition_name] = {} # Initialize condition entry\n",
        "\n",
        "    # Use the structure of the first valid result to find keys\n",
        "    first_result = valid_seed_results[0]\n",
        "    top_level_keys = list(first_result.keys()) # Should be ['all', 'sex', 'age_bin', ...]\n",
        "\n",
        "    for top_key in top_level_keys: # Iterate through 'all', 'sex', 'age_bin', etc.\n",
        "        print(f\"\\n    Processing Top Key: {top_key.upper()}\")\n",
        "        aggregated_stats[condition_name][top_key] = {} # Initialize entry for this top key\n",
        "\n",
        "        first_level_data = first_result.get(top_key) # e.g., data under 'sex' or 'all'\n",
        "\n",
        "        # Check if this level contains subgroups (like 'sex': {'0':{...}, '1':{...}})\n",
        "        # or direct metrics (like 'all': {'f1_macro':...})\n",
        "        # or overall cross-group metrics ('overall_metrics': {'avg_macro...': ...})\n",
        "        if not isinstance(first_level_data, dict):\n",
        "            print(f\"      Skipping {top_key}: Expected dict, found {type(first_level_data)}.\")\n",
        "            continue\n",
        "\n",
        "        second_level_keys = list(first_level_data.keys())\n",
        "        if not second_level_keys:\n",
        "            print(f\"      Skipping {top_key}: Contains no data.\")\n",
        "            continue\n",
        "\n",
        "        # Determine if the second level represents subgroups (like '0', '1' for sex)\n",
        "        # or metrics (like 'f1_macro' for 'all' or 'overall_metrics')\n",
        "        # A simple check: does the first item at the second level contain 'f1_macro'? (adjust if needed)\n",
        "        level_contains_subgroups = isinstance(first_level_data.get(second_level_keys[0]), dict) and \\\n",
        "                                   'f1_macro' in first_level_data.get(second_level_keys[0], {})\n",
        "\n",
        "        if level_contains_subgroups: # Processing subgroups like 'sex', 'age_bin', 'device'\n",
        "            subgroup_names = second_level_keys # e.g., '0', '1', or '50s', '60s', or device names\n",
        "            for sg_name in subgroup_names:\n",
        "                print(f\"      Subgroup: {sg_name}\")\n",
        "                aggregated_stats[condition_name][top_key][sg_name] = {} # Initialize entry\n",
        "\n",
        "                # Get the structure of metrics from the first result for this subgroup\n",
        "                first_subgroup_data = first_level_data.get(sg_name)\n",
        "                if not isinstance(first_subgroup_data, dict): continue # Skip if subgroup data invalid\n",
        "\n",
        "                metric_names = list(first_subgroup_data.keys()) # e.g., 'f1_macro', 'precision_per_class'\n",
        "\n",
        "                for metric in metric_names:\n",
        "                    # Check if the metric itself contains per-class breakdown\n",
        "                    is_per_class = isinstance(first_subgroup_data.get(metric), dict)\n",
        "\n",
        "                    if is_per_class: # Handle per-class metrics (e.g., 'f1_per_class')\n",
        "                        aggregated_stats[condition_name][top_key][sg_name][metric] = {}\n",
        "                        class_names = list(first_subgroup_data[metric].keys())\n",
        "                        for cls_name in class_names:\n",
        "                            # Collect values for this specific class across seeds\n",
        "                            values = [seed_res.get(top_key, {}).get(sg_name, {}).get(metric, {}).get(cls_name)\n",
        "                                      for seed_res in valid_seed_results]\n",
        "                            valid_values = [v for v in values if isinstance(v, (int, float)) and not np.isnan(v)]\n",
        "                            mean_val, std_val = (np.mean(valid_values), np.std(valid_values)) if valid_values else (np.nan, np.nan)\n",
        "                            aggregated_stats[condition_name][top_key][sg_name][metric][cls_name] = {'mean': mean_val, 'std': std_val}\n",
        "                    else: # Handle direct metrics (e.g., 'f1_macro', 'num_samples')\n",
        "                        # Collect values for this metric across seeds\n",
        "                        values = [seed_res.get(top_key, {}).get(sg_name, {}).get(metric)\n",
        "                                  for seed_res in valid_seed_results]\n",
        "                        valid_values = [v for v in values if isinstance(v, (int, float)) and not np.isnan(v)]\n",
        "                        mean_val, std_val = (np.mean(valid_values), np.std(valid_values)) if valid_values else (np.nan, np.nan)\n",
        "                        aggregated_stats[condition_name][top_key][sg_name][metric] = {'mean': mean_val, 'std': std_val}\n",
        "                        # Optional print for key metrics\n",
        "                        if metric in ['f1_macro', 'recall_macro', 'precision_macro', 'exact_match_ratio', 'mean_true_labels', 'num_samples']:\n",
        "                             print(f\"        {metric}: Mean={mean_val:.4f}, Std={std_val:.4f}\" if not isinstance(mean_val, (int)) and metric != 'num_samples' else f\"        {metric}: Mean={mean_val:.1f}, Std={std_val:.2f}\")\n",
        "\n",
        "        else: # Processing direct metrics under 'all' or 'overall_metrics'\n",
        "            metric_names = second_level_keys # e.g., 'f1_macro', 'avg_macro_f1_male_female'\n",
        "            print(f\"      Metrics for: {top_key.upper()}\")\n",
        "            for metric in metric_names:\n",
        "                # Check if metric contains per-class breakdown (relevant for 'all')\n",
        "                is_per_class = isinstance(first_level_data.get(metric), dict)\n",
        "\n",
        "                if is_per_class and top_key == 'all': # Handle per-class metrics under 'all'\n",
        "                    aggregated_stats[condition_name][top_key][metric] = {}\n",
        "                    class_names = list(first_level_data[metric].keys())\n",
        "                    for cls_name in class_names:\n",
        "                        values = [seed_res.get(top_key, {}).get(metric, {}).get(cls_name)\n",
        "                                  for seed_res in valid_seed_results]\n",
        "                        valid_values = [v for v in values if isinstance(v, (int, float)) and not np.isnan(v)]\n",
        "                        mean_val, std_val = (np.mean(valid_values), np.std(valid_values)) if valid_values else (np.nan, np.nan)\n",
        "                        aggregated_stats[condition_name][top_key][metric][cls_name] = {'mean': mean_val, 'std': std_val}\n",
        "                elif not is_per_class: # Handle direct metrics under 'all' or 'overall_metrics'\n",
        "                    values = [seed_res.get(top_key, {}).get(metric)\n",
        "                              for seed_res in valid_seed_results]\n",
        "                    valid_values = [v for v in values if isinstance(v, (int, float)) and not np.isnan(v)]\n",
        "                    mean_val, std_val = (np.mean(valid_values), np.std(valid_values)) if valid_values else (np.nan, np.nan)\n",
        "                    # **** THIS IS WHERE THE DATA FOR 'all' GETS STORED ****\n",
        "                    aggregated_stats[condition_name][top_key][metric] = {'mean': mean_val, 'std': std_val}\n",
        "                    # *******************************************************\n",
        "                    print(f\"        {metric}: Mean={mean_val:.4f}, Std={std_val:.4f}\" if metric != 'num_samples' else f\"        {metric}: Mean={mean_val:.1f}, Std={std_val:.2f}\")\n",
        "\n",
        "\n",
        "# --- Save Aggregated Stats ---\n",
        "agg_save_filename = 'aggregated_evaluation_stats.pkl'\n",
        "agg_save_path = os.path.join(RESULTS_DIR, agg_save_filename)\n",
        "print(f\"\\nSaving aggregated evaluation statistics to: {agg_save_path}\")\n",
        "try:\n",
        "    with open(agg_save_path, 'wb') as f:\n",
        "        pickle.dump(aggregated_stats, f)\n",
        "    print(\"Aggregated stats saved successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving aggregated stats: {e}\")\n",
        "\n",
        "print(\"\\n--- Aggregation Script Finished ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-yk65Kc_sIG",
        "outputId": "8dcd3b11-d581-43c0-8111-c75764cf86c7"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes for evaluation: 5\n",
            "Target classes: ['CD', 'HYP', 'MI', 'NORM', 'STTC']\n",
            "\n",
            "==================== Evaluating Condition: Optimized_Global ====================\n",
            "Using device: cuda, DA Flag: False, Thresh Mode: global_optimized, Focus: None\n",
            "\n",
            "-- Evaluating SEED=458 --\n",
            "Using optimized global thresholds for seed 458.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_458_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Global Per-Class Threshold Array.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5682\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.6741\n",
            "  recall_macro: 0.7455\n",
            "  f1_macro: 0.7062\n",
            "  precision_micro: 0.7109\n",
            "  recall_micro: 0.7855\n",
            "  f1_micro: 0.7463\n",
            "  precision_weighted: 0.7180\n",
            "  recall_weighted: 0.7855\n",
            "  f1_weighted: 0.7490\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7226; Exact Match: 0.5936\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6878; Exact Match: 0.5413\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6854; Exact Match: 0.6262\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6828; Exact Match: 0.7215\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6936; Exact Match: 0.5177\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.4292; Exact Match: 0.8193\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6271; Exact Match: 0.7516\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5331; Exact Match: 0.7872\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7029; Exact Match: 0.4801\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6232; Exact Match: 0.3954\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6298; Exact Match: 0.5294\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6122; Exact Match: 0.7140\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7695; Exact Match: 0.5400\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6512; Exact Match: 0.5036\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7333; Exact Match: 0.6094\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5836; Exact Match: 0.2857\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6382; Exact Match: 0.4658\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7312; Exact Match: 0.5542\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.4833; Exact Match: 0.4286\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7121; Exact Match: 0.5230\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7982; Exact Match: 0.4746\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.8000; Exact Match: 0.2857\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6544; Exact Match: 0.3952\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6106; Exact Match: 0.3168\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5484; Exact Match: 0.3800\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2756; Exact Match: 0.8193\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5978; Exact Match: 0.3800\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7052\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 458.\n",
            "\n",
            "-- Evaluating SEED=1018 --\n",
            "Using optimized global thresholds for seed 1018.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_1018_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Global Per-Class Threshold Array.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5578\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.6740\n",
            "  recall_macro: 0.7512\n",
            "  f1_macro: 0.7084\n",
            "  precision_micro: 0.7100\n",
            "  recall_micro: 0.7937\n",
            "  f1_micro: 0.7495\n",
            "  precision_weighted: 0.7181\n",
            "  recall_weighted: 0.7937\n",
            "  f1_weighted: 0.7526\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7194; Exact Match: 0.5751\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6951; Exact Match: 0.5394\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6882; Exact Match: 0.6337\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6785; Exact Match: 0.7089\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6990; Exact Match: 0.5073\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.4355; Exact Match: 0.8313\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6165; Exact Match: 0.7516\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.3165; Exact Match: 0.7872\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7077; Exact Match: 0.4513\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6355; Exact Match: 0.3889\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5944; Exact Match: 0.4118\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5815; Exact Match: 0.7185\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7301; Exact Match: 0.4400\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6545; Exact Match: 0.4879\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7466; Exact Match: 0.6042\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5486; Exact Match: 0.5000\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6974; Exact Match: 0.5068\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7182; Exact Match: 0.5208\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5778; Exact Match: 0.5714\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7187; Exact Match: 0.5057\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.8251; Exact Match: 0.5085\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.8167; Exact Match: 0.2857\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6533; Exact Match: 0.3528\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6208; Exact Match: 0.2710\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5509; Exact Match: 0.3564\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2855; Exact Match: 0.8442\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5861; Exact Match: 0.3417\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7073\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 1018.\n",
            "\n",
            "-- Evaluating SEED=1016 --\n",
            "Using optimized global thresholds for seed 1016.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_1016_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Global Per-Class Threshold Array.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5728\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.6902\n",
            "  recall_macro: 0.7238\n",
            "  f1_macro: 0.7055\n",
            "  precision_micro: 0.7294\n",
            "  recall_micro: 0.7754\n",
            "  f1_micro: 0.7517\n",
            "  precision_weighted: 0.7301\n",
            "  recall_weighted: 0.7754\n",
            "  f1_weighted: 0.7508\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7088; Exact Match: 0.5769\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6996; Exact Match: 0.5685\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6726; Exact Match: 0.6510\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6549; Exact Match: 0.7046\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6908; Exact Match: 0.5052\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.4593; Exact Match: 0.8434\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6023; Exact Match: 0.7451\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.3165; Exact Match: 0.7872\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7118; Exact Match: 0.5022\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6218; Exact Match: 0.3954\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6286; Exact Match: 0.5000\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5682; Exact Match: 0.7162\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7561; Exact Match: 0.5200\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6530; Exact Match: 0.5064\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7276; Exact Match: 0.6172\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6429; Exact Match: 0.5714\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6933; Exact Match: 0.5068\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7125; Exact Match: 0.5417\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5500; Exact Match: 0.4286\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7376; Exact Match: 0.5402\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7990; Exact Match: 0.4576\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7667; Exact Match: 0.2857\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6429; Exact Match: 0.3649\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5977; Exact Match: 0.2634\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5399; Exact Match: 0.3673\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2791; Exact Match: 0.8370\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5966; Exact Match: 0.3858\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7042\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 1016.\n",
            "\n",
            "-- Evaluating SEED=391 --\n",
            "Using optimized global thresholds for seed 391.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_391_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Global Per-Class Threshold Array.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5591\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.6778\n",
            "  recall_macro: 0.7382\n",
            "  f1_macro: 0.7020\n",
            "  precision_micro: 0.7083\n",
            "  recall_micro: 0.7801\n",
            "  f1_micro: 0.7425\n",
            "  precision_weighted: 0.7215\n",
            "  recall_weighted: 0.7801\n",
            "  f1_weighted: 0.7465\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7148; Exact Match: 0.5777\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6867; Exact Match: 0.5394\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6712; Exact Match: 0.6238\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6518; Exact Match: 0.6962\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6903; Exact Match: 0.5198\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.4368; Exact Match: 0.8434\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6258; Exact Match: 0.7516\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5165; Exact Match: 0.7872\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7016; Exact Match: 0.4690\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6330; Exact Match: 0.3660\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5950; Exact Match: 0.4706\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5781; Exact Match: 0.7231\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7262; Exact Match: 0.4500\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6552; Exact Match: 0.4922\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7279; Exact Match: 0.5781\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7088; Exact Match: 0.6429\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6702; Exact Match: 0.4658\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7233; Exact Match: 0.5542\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5500; Exact Match: 0.5714\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7011; Exact Match: 0.5172\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7828; Exact Match: 0.4576\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.8381; Exact Match: 0.4286\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6288; Exact Match: 0.3266\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6196; Exact Match: 0.3015\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5502; Exact Match: 0.3836\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2731; Exact Match: 0.8401\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5897; Exact Match: 0.3436\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7008\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 391.\n",
            "\n",
            "-- Evaluating SEED=976 --\n",
            "Using optimized global thresholds for seed 976.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_976_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Global Per-Class Threshold Array.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5869\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.7064\n",
            "  recall_macro: 0.7182\n",
            "  f1_macro: 0.7084\n",
            "  precision_micro: 0.7366\n",
            "  recall_micro: 0.7711\n",
            "  f1_micro: 0.7535\n",
            "  precision_weighted: 0.7400\n",
            "  recall_weighted: 0.7711\n",
            "  f1_weighted: 0.7510\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7214; Exact Match: 0.6087\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6919; Exact Match: 0.5638\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6856; Exact Match: 0.6510\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6547; Exact Match: 0.7426\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6840; Exact Match: 0.5405\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.4641; Exact Match: 0.8434\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6253; Exact Match: 0.7647\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2754; Exact Match: 0.7660\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7112; Exact Match: 0.4934\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6391; Exact Match: 0.4216\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6185; Exact Match: 0.4706\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5571; Exact Match: 0.7323\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7407; Exact Match: 0.5000\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6663; Exact Match: 0.5377\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7199; Exact Match: 0.5990\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6448; Exact Match: 0.4286\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6720; Exact Match: 0.4521\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7541; Exact Match: 0.5792\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5111; Exact Match: 0.7143\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7207; Exact Match: 0.5920\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7755; Exact Match: 0.4068\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7833; Exact Match: 0.2857\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6253; Exact Match: 0.3427\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6076; Exact Match: 0.2748\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5415; Exact Match: 0.3636\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2854; Exact Match: 0.8567\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5864; Exact Match: 0.3858\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7067\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 976.\n",
            "\n",
            "==================== Evaluating Condition: Optimized_Subgroup_Combined ====================\n",
            "Using device: cuda, DA Flag: False, Thresh Mode: subgroup, Focus: combined\n",
            "\n",
            "-- Evaluating SEED=458 --\n",
            "Using COMBINED optimized subgroup thresholds (Sex+Age+Device) for seed 458.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_458_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Subgroup-Specific Threshold Dictionary.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5682\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.6741\n",
            "  recall_macro: 0.7455\n",
            "  f1_macro: 0.7062\n",
            "  precision_micro: 0.7109\n",
            "  recall_micro: 0.7855\n",
            "  f1_micro: 0.7463\n",
            "  precision_weighted: 0.7180\n",
            "  recall_weighted: 0.7855\n",
            "  f1_weighted: 0.7490\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Specific\n",
            "   Macro F1: 0.7178; Exact Match: 0.5769\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Specific\n",
            "   Macro F1: 0.6913; Exact Match: 0.5694\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Specific\n",
            "   Macro F1: 0.6730; Exact Match: 0.6386\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Specific\n",
            "   Macro F1: 0.6649; Exact Match: 0.6287\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Specific\n",
            "   Macro F1: 0.6910; Exact Match: 0.5177\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Specific\n",
            "   Macro F1: 0.4180; Exact Match: 0.7470\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Specific\n",
            "   Macro F1: 0.6139; Exact Match: 0.7320\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Specific\n",
            "   Macro F1: 0.5288; Exact Match: 0.6170\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Specific\n",
            "   Macro F1: 0.6886; Exact Match: 0.4204\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Specific\n",
            "   Macro F1: 0.6235; Exact Match: 0.3987\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Specific\n",
            "   Macro F1: 0.6275; Exact Match: 0.5000\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Specific\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Specific\n",
            "   Macro F1: 0.6338; Exact Match: 0.7094\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Specific\n",
            "   Macro F1: 0.7534; Exact Match: 0.5100\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Specific\n",
            "   Macro F1: 0.6470; Exact Match: 0.5064\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Specific\n",
            "   Macro F1: 0.7253; Exact Match: 0.5573\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Specific\n",
            "   Macro F1: 0.5076; Exact Match: 0.2857\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Specific\n",
            "   Macro F1: 0.6602; Exact Match: 0.4521\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Specific\n",
            "   Macro F1: 0.6872; Exact Match: 0.5417\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Specific\n",
            "   Macro F1: 0.4788; Exact Match: 0.4286\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Specific\n",
            "   Macro F1: 0.6894; Exact Match: 0.4770\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Specific\n",
            "   Macro F1: 0.7911; Exact Match: 0.4576\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Specific\n",
            "   Macro F1: 0.7333; Exact Match: 0.1429\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6544; Exact Match: 0.3952\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6106; Exact Match: 0.3168\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5484; Exact Match: 0.3800\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2756; Exact Match: 0.8193\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5978; Exact Match: 0.3800\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7046\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 458.\n",
            "\n",
            "-- Evaluating SEED=1018 --\n",
            "Using COMBINED optimized subgroup thresholds (Sex+Age+Device) for seed 1018.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_1018_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Subgroup-Specific Threshold Dictionary.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5578\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.6740\n",
            "  recall_macro: 0.7512\n",
            "  f1_macro: 0.7084\n",
            "  precision_micro: 0.7100\n",
            "  recall_micro: 0.7937\n",
            "  f1_micro: 0.7495\n",
            "  precision_weighted: 0.7181\n",
            "  recall_weighted: 0.7937\n",
            "  f1_weighted: 0.7526\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Specific\n",
            "   Macro F1: 0.7166; Exact Match: 0.5707\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Specific\n",
            "   Macro F1: 0.7002; Exact Match: 0.5450\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Specific\n",
            "   Macro F1: 0.6531; Exact Match: 0.6089\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Specific\n",
            "   Macro F1: 0.6618; Exact Match: 0.6498\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Specific\n",
            "   Macro F1: 0.6971; Exact Match: 0.5073\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Specific\n",
            "   Macro F1: 0.4539; Exact Match: 0.8434\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Specific\n",
            "   Macro F1: 0.6222; Exact Match: 0.7451\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Specific\n",
            "   Macro F1: 0.3122; Exact Match: 0.6596\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Specific\n",
            "   Macro F1: 0.7051; Exact Match: 0.4712\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Specific\n",
            "   Macro F1: 0.6438; Exact Match: 0.4281\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Specific\n",
            "   Macro F1: 0.5950; Exact Match: 0.4412\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Specific\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Specific\n",
            "   Macro F1: 0.5817; Exact Match: 0.7002\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Specific\n",
            "   Macro F1: 0.7543; Exact Match: 0.5000\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Specific\n",
            "   Macro F1: 0.6560; Exact Match: 0.5164\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Specific\n",
            "   Macro F1: 0.7372; Exact Match: 0.5625\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Specific\n",
            "   Macro F1: 0.5281; Exact Match: 0.4286\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Specific\n",
            "   Macro F1: 0.6666; Exact Match: 0.5342\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Specific\n",
            "   Macro F1: 0.7157; Exact Match: 0.5208\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Specific\n",
            "   Macro F1: 0.5455; Exact Match: 0.5714\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Specific\n",
            "   Macro F1: 0.7147; Exact Match: 0.5172\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Specific\n",
            "   Macro F1: 0.8007; Exact Match: 0.4407\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Specific\n",
            "   Macro F1: 0.7500; Exact Match: 0.1429\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6533; Exact Match: 0.3528\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6208; Exact Match: 0.2710\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5509; Exact Match: 0.3564\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2855; Exact Match: 0.8442\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5861; Exact Match: 0.3417\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7084\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 1018.\n",
            "\n",
            "-- Evaluating SEED=1016 --\n",
            "Using COMBINED optimized subgroup thresholds (Sex+Age+Device) for seed 1016.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_1016_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Subgroup-Specific Threshold Dictionary.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5728\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.6902\n",
            "  recall_macro: 0.7238\n",
            "  f1_macro: 0.7055\n",
            "  precision_micro: 0.7294\n",
            "  recall_micro: 0.7754\n",
            "  f1_micro: 0.7517\n",
            "  precision_weighted: 0.7301\n",
            "  recall_weighted: 0.7754\n",
            "  f1_weighted: 0.7508\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Specific\n",
            "   Macro F1: 0.7134; Exact Match: 0.5654\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Specific\n",
            "   Macro F1: 0.6977; Exact Match: 0.5582\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Specific\n",
            "   Macro F1: 0.6631; Exact Match: 0.6386\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Specific\n",
            "   Macro F1: 0.6434; Exact Match: 0.6160\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Specific\n",
            "   Macro F1: 0.6857; Exact Match: 0.5114\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Specific\n",
            "   Macro F1: 0.4448; Exact Match: 0.7831\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Specific\n",
            "   Macro F1: 0.6053; Exact Match: 0.7190\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Specific\n",
            "   Macro F1: 0.3122; Exact Match: 0.7660\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Specific\n",
            "   Macro F1: 0.7157; Exact Match: 0.4823\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Specific\n",
            "   Macro F1: 0.6113; Exact Match: 0.3954\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Specific\n",
            "   Macro F1: 0.5911; Exact Match: 0.4706\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Specific\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Specific\n",
            "   Macro F1: 0.5857; Exact Match: 0.6819\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Specific\n",
            "   Macro F1: 0.7708; Exact Match: 0.5500\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Specific\n",
            "   Macro F1: 0.6517; Exact Match: 0.5249\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Specific\n",
            "   Macro F1: 0.7271; Exact Match: 0.5755\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Specific\n",
            "   Macro F1: 0.5603; Exact Match: 0.3571\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Specific\n",
            "   Macro F1: 0.6956; Exact Match: 0.4795\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Specific\n",
            "   Macro F1: 0.7177; Exact Match: 0.5208\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Specific\n",
            "   Macro F1: 0.5600; Exact Match: 0.4286\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Specific\n",
            "   Macro F1: 0.7480; Exact Match: 0.5862\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Specific\n",
            "   Macro F1: 0.7908; Exact Match: 0.4237\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Specific\n",
            "   Macro F1: 0.8014; Exact Match: 0.2857\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6429; Exact Match: 0.3649\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5977; Exact Match: 0.2634\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5399; Exact Match: 0.3673\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2791; Exact Match: 0.8370\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5966; Exact Match: 0.3858\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7055\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 1016.\n",
            "\n",
            "-- Evaluating SEED=391 --\n",
            "Using COMBINED optimized subgroup thresholds (Sex+Age+Device) for seed 391.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_391_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Subgroup-Specific Threshold Dictionary.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5591\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.6778\n",
            "  recall_macro: 0.7382\n",
            "  f1_macro: 0.7020\n",
            "  precision_micro: 0.7083\n",
            "  recall_micro: 0.7801\n",
            "  f1_micro: 0.7425\n",
            "  precision_weighted: 0.7215\n",
            "  recall_weighted: 0.7801\n",
            "  f1_weighted: 0.7465\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Specific\n",
            "   Macro F1: 0.7120; Exact Match: 0.5680\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Specific\n",
            "   Macro F1: 0.6933; Exact Match: 0.5488\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Specific\n",
            "   Macro F1: 0.6736; Exact Match: 0.6114\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Specific\n",
            "   Macro F1: 0.6621; Exact Match: 0.6160\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Specific\n",
            "   Macro F1: 0.6921; Exact Match: 0.5114\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Specific\n",
            "   Macro F1: 0.4288; Exact Match: 0.7831\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Specific\n",
            "   Macro F1: 0.6369; Exact Match: 0.7190\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Specific\n",
            "   Macro F1: 0.5312; Exact Match: 0.4894\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Specific\n",
            "   Macro F1: 0.7032; Exact Match: 0.4801\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Specific\n",
            "   Macro F1: 0.6348; Exact Match: 0.4118\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Specific\n",
            "   Macro F1: 0.5571; Exact Match: 0.3529\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Specific\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Specific\n",
            "   Macro F1: 0.6344; Exact Match: 0.7140\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Specific\n",
            "   Macro F1: 0.7300; Exact Match: 0.4600\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Specific\n",
            "   Macro F1: 0.6584; Exact Match: 0.4893\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Specific\n",
            "   Macro F1: 0.7369; Exact Match: 0.5964\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Specific\n",
            "   Macro F1: 0.5079; Exact Match: 0.3571\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Specific\n",
            "   Macro F1: 0.6671; Exact Match: 0.4795\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Specific\n",
            "   Macro F1: 0.7158; Exact Match: 0.5375\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Specific\n",
            "   Macro F1: 0.5600; Exact Match: 0.4286\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Specific\n",
            "   Macro F1: 0.6997; Exact Match: 0.5230\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Specific\n",
            "   Macro F1: 0.7983; Exact Match: 0.4576\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Specific\n",
            "   Macro F1: 0.8214; Exact Match: 0.4286\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6288; Exact Match: 0.3266\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6196; Exact Match: 0.3015\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5502; Exact Match: 0.3836\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2731; Exact Match: 0.8401\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5897; Exact Match: 0.3436\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7026\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 391.\n",
            "\n",
            "-- Evaluating SEED=976 --\n",
            "Using COMBINED optimized subgroup thresholds (Sex+Age+Device) for seed 976.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_976_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Subgroup-Specific Threshold Dictionary.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5869\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.7064\n",
            "  recall_macro: 0.7182\n",
            "  f1_macro: 0.7084\n",
            "  precision_micro: 0.7366\n",
            "  recall_micro: 0.7711\n",
            "  f1_micro: 0.7535\n",
            "  precision_weighted: 0.7400\n",
            "  recall_weighted: 0.7711\n",
            "  f1_weighted: 0.7510\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Specific\n",
            "   Macro F1: 0.7213; Exact Match: 0.5830\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Specific\n",
            "   Macro F1: 0.6901; Exact Match: 0.5488\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Specific\n",
            "   Macro F1: 0.6821; Exact Match: 0.6337\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Specific\n",
            "   Macro F1: 0.6447; Exact Match: 0.5907\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Specific\n",
            "   Macro F1: 0.6912; Exact Match: 0.4969\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Specific\n",
            "   Macro F1: 0.5169; Exact Match: 0.8434\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Specific\n",
            "   Macro F1: 0.6145; Exact Match: 0.7124\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Specific\n",
            "   Macro F1: 0.3165; Exact Match: 0.7234\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Specific\n",
            "   Macro F1: 0.6980; Exact Match: 0.4712\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Specific\n",
            "   Macro F1: 0.6469; Exact Match: 0.4542\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Specific\n",
            "   Macro F1: 0.5898; Exact Match: 0.3824\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Specific\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Specific\n",
            "   Macro F1: 0.6096; Exact Match: 0.6773\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Specific\n",
            "   Macro F1: 0.7414; Exact Match: 0.4600\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Specific\n",
            "   Macro F1: 0.6712; Exact Match: 0.5263\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Specific\n",
            "   Macro F1: 0.7296; Exact Match: 0.5833\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Specific\n",
            "   Macro F1: 0.5378; Exact Match: 0.2857\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Specific\n",
            "   Macro F1: 0.6662; Exact Match: 0.5205\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Specific\n",
            "   Macro F1: 0.7457; Exact Match: 0.5542\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Specific\n",
            "   Macro F1: 0.4788; Exact Match: 0.4286\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Specific\n",
            "   Macro F1: 0.7229; Exact Match: 0.5057\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Specific\n",
            "   Macro F1: 0.7647; Exact Match: 0.3729\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Specific\n",
            "   Macro F1: 0.8014; Exact Match: 0.1429\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6253; Exact Match: 0.3427\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6076; Exact Match: 0.2748\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5415; Exact Match: 0.3636\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2854; Exact Match: 0.8567\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5864; Exact Match: 0.3858\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7057\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 976.\n",
            "\n",
            "==================== Evaluating Condition: Optimized_Subgroup_Sex ====================\n",
            "Using device: cuda, DA Flag: False, Thresh Mode: subgroup, Focus: sex\n",
            "\n",
            "-- Evaluating SEED=458 --\n",
            "Using SEX optimized subgroup thresholds ONLY for seed 458.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_458_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Subgroup-Specific Threshold Dictionary.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5682\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.6741\n",
            "  recall_macro: 0.7455\n",
            "  f1_macro: 0.7062\n",
            "  precision_micro: 0.7109\n",
            "  recall_micro: 0.7855\n",
            "  f1_micro: 0.7463\n",
            "  precision_weighted: 0.7180\n",
            "  recall_weighted: 0.7855\n",
            "  f1_weighted: 0.7490\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Specific\n",
            "   Macro F1: 0.7178; Exact Match: 0.5769\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Specific\n",
            "   Macro F1: 0.6913; Exact Match: 0.5694\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6854; Exact Match: 0.6262\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6828; Exact Match: 0.7215\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6936; Exact Match: 0.5177\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.4292; Exact Match: 0.8193\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6271; Exact Match: 0.7516\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5331; Exact Match: 0.7872\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7029; Exact Match: 0.4801\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6232; Exact Match: 0.3954\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6298; Exact Match: 0.5294\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6122; Exact Match: 0.7140\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7695; Exact Match: 0.5400\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6512; Exact Match: 0.5036\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7333; Exact Match: 0.6094\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5836; Exact Match: 0.2857\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6382; Exact Match: 0.4658\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7312; Exact Match: 0.5542\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.4833; Exact Match: 0.4286\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7121; Exact Match: 0.5230\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7982; Exact Match: 0.4746\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.8000; Exact Match: 0.2857\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6544; Exact Match: 0.3952\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6106; Exact Match: 0.3168\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5484; Exact Match: 0.3800\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2756; Exact Match: 0.8193\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5978; Exact Match: 0.3800\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7046\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 458.\n",
            "\n",
            "-- Evaluating SEED=1018 --\n",
            "Using SEX optimized subgroup thresholds ONLY for seed 1018.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_1018_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Subgroup-Specific Threshold Dictionary.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5578\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.6740\n",
            "  recall_macro: 0.7512\n",
            "  f1_macro: 0.7084\n",
            "  precision_micro: 0.7100\n",
            "  recall_micro: 0.7937\n",
            "  f1_micro: 0.7495\n",
            "  precision_weighted: 0.7181\n",
            "  recall_weighted: 0.7937\n",
            "  f1_weighted: 0.7526\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Specific\n",
            "   Macro F1: 0.7166; Exact Match: 0.5707\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Specific\n",
            "   Macro F1: 0.7002; Exact Match: 0.5450\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6882; Exact Match: 0.6337\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6785; Exact Match: 0.7089\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6990; Exact Match: 0.5073\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.4355; Exact Match: 0.8313\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6165; Exact Match: 0.7516\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.3165; Exact Match: 0.7872\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7077; Exact Match: 0.4513\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6355; Exact Match: 0.3889\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5944; Exact Match: 0.4118\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5815; Exact Match: 0.7185\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7301; Exact Match: 0.4400\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6545; Exact Match: 0.4879\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7466; Exact Match: 0.6042\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5486; Exact Match: 0.5000\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6974; Exact Match: 0.5068\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7182; Exact Match: 0.5208\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5778; Exact Match: 0.5714\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7187; Exact Match: 0.5057\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.8251; Exact Match: 0.5085\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.8167; Exact Match: 0.2857\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6533; Exact Match: 0.3528\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6208; Exact Match: 0.2710\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5509; Exact Match: 0.3564\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2855; Exact Match: 0.8442\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5861; Exact Match: 0.3417\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7084\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 1018.\n",
            "\n",
            "-- Evaluating SEED=1016 --\n",
            "Using SEX optimized subgroup thresholds ONLY for seed 1016.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_1016_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Subgroup-Specific Threshold Dictionary.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5728\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.6902\n",
            "  recall_macro: 0.7238\n",
            "  f1_macro: 0.7055\n",
            "  precision_micro: 0.7294\n",
            "  recall_micro: 0.7754\n",
            "  f1_micro: 0.7517\n",
            "  precision_weighted: 0.7301\n",
            "  recall_weighted: 0.7754\n",
            "  f1_weighted: 0.7508\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Specific\n",
            "   Macro F1: 0.7134; Exact Match: 0.5654\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Specific\n",
            "   Macro F1: 0.6977; Exact Match: 0.5582\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6726; Exact Match: 0.6510\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6549; Exact Match: 0.7046\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6908; Exact Match: 0.5052\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.4593; Exact Match: 0.8434\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6023; Exact Match: 0.7451\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.3165; Exact Match: 0.7872\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7118; Exact Match: 0.5022\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6218; Exact Match: 0.3954\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6286; Exact Match: 0.5000\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5682; Exact Match: 0.7162\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7561; Exact Match: 0.5200\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6530; Exact Match: 0.5064\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7276; Exact Match: 0.6172\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6429; Exact Match: 0.5714\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6933; Exact Match: 0.5068\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7125; Exact Match: 0.5417\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5500; Exact Match: 0.4286\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7376; Exact Match: 0.5402\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7990; Exact Match: 0.4576\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7667; Exact Match: 0.2857\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6429; Exact Match: 0.3649\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5977; Exact Match: 0.2634\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5399; Exact Match: 0.3673\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2791; Exact Match: 0.8370\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5966; Exact Match: 0.3858\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7055\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 1016.\n",
            "\n",
            "-- Evaluating SEED=391 --\n",
            "Using SEX optimized subgroup thresholds ONLY for seed 391.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_391_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Subgroup-Specific Threshold Dictionary.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5591\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.6778\n",
            "  recall_macro: 0.7382\n",
            "  f1_macro: 0.7020\n",
            "  precision_micro: 0.7083\n",
            "  recall_micro: 0.7801\n",
            "  f1_micro: 0.7425\n",
            "  precision_weighted: 0.7215\n",
            "  recall_weighted: 0.7801\n",
            "  f1_weighted: 0.7465\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Specific\n",
            "   Macro F1: 0.7120; Exact Match: 0.5680\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Specific\n",
            "   Macro F1: 0.6933; Exact Match: 0.5488\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6712; Exact Match: 0.6238\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6518; Exact Match: 0.6962\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6903; Exact Match: 0.5198\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.4368; Exact Match: 0.8434\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6258; Exact Match: 0.7516\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5165; Exact Match: 0.7872\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7016; Exact Match: 0.4690\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6330; Exact Match: 0.3660\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5950; Exact Match: 0.4706\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5781; Exact Match: 0.7231\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7262; Exact Match: 0.4500\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6552; Exact Match: 0.4922\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7279; Exact Match: 0.5781\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7088; Exact Match: 0.6429\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6702; Exact Match: 0.4658\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7233; Exact Match: 0.5542\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5500; Exact Match: 0.5714\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7011; Exact Match: 0.5172\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7828; Exact Match: 0.4576\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.8381; Exact Match: 0.4286\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6288; Exact Match: 0.3266\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6196; Exact Match: 0.3015\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5502; Exact Match: 0.3836\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2731; Exact Match: 0.8401\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5897; Exact Match: 0.3436\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7026\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 391.\n",
            "\n",
            "-- Evaluating SEED=976 --\n",
            "Using SEX optimized subgroup thresholds ONLY for seed 976.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_976_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Subgroup-Specific Threshold Dictionary.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5869\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.7064\n",
            "  recall_macro: 0.7182\n",
            "  f1_macro: 0.7084\n",
            "  precision_micro: 0.7366\n",
            "  recall_micro: 0.7711\n",
            "  f1_micro: 0.7535\n",
            "  precision_weighted: 0.7400\n",
            "  recall_weighted: 0.7711\n",
            "  f1_weighted: 0.7510\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Specific\n",
            "   Macro F1: 0.7213; Exact Match: 0.5830\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Specific\n",
            "   Macro F1: 0.6901; Exact Match: 0.5488\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6856; Exact Match: 0.6510\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6547; Exact Match: 0.7426\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6840; Exact Match: 0.5405\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.4641; Exact Match: 0.8434\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6253; Exact Match: 0.7647\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2754; Exact Match: 0.7660\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7112; Exact Match: 0.4934\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6391; Exact Match: 0.4216\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6185; Exact Match: 0.4706\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5571; Exact Match: 0.7323\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7407; Exact Match: 0.5000\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6663; Exact Match: 0.5377\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7199; Exact Match: 0.5990\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6448; Exact Match: 0.4286\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6720; Exact Match: 0.4521\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7541; Exact Match: 0.5792\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5111; Exact Match: 0.7143\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7207; Exact Match: 0.5920\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7755; Exact Match: 0.4068\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7833; Exact Match: 0.2857\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6253; Exact Match: 0.3427\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6076; Exact Match: 0.2748\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5415; Exact Match: 0.3636\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2854; Exact Match: 0.8567\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5864; Exact Match: 0.3858\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7057\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 976.\n",
            "\n",
            "==================== Evaluating Condition: Optimized_Subgroup_Age ====================\n",
            "Using device: cuda, DA Flag: False, Thresh Mode: subgroup, Focus: age_bin\n",
            "\n",
            "-- Evaluating SEED=458 --\n",
            "Using AGE optimized subgroup thresholds ONLY for seed 458.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_458_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Subgroup-Specific Threshold Dictionary.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5682\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.6741\n",
            "  recall_macro: 0.7455\n",
            "  f1_macro: 0.7062\n",
            "  precision_micro: 0.7109\n",
            "  recall_micro: 0.7855\n",
            "  f1_micro: 0.7463\n",
            "  precision_weighted: 0.7180\n",
            "  recall_weighted: 0.7855\n",
            "  f1_weighted: 0.7490\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7226; Exact Match: 0.5936\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6878; Exact Match: 0.5413\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Specific\n",
            "   Macro F1: 0.6730; Exact Match: 0.6386\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Specific\n",
            "   Macro F1: 0.6649; Exact Match: 0.6287\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Specific\n",
            "   Macro F1: 0.6910; Exact Match: 0.5177\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Specific\n",
            "   Macro F1: 0.4180; Exact Match: 0.7470\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Specific\n",
            "   Macro F1: 0.6139; Exact Match: 0.7320\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Specific\n",
            "   Macro F1: 0.5288; Exact Match: 0.6170\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Specific\n",
            "   Macro F1: 0.6886; Exact Match: 0.4204\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Specific\n",
            "   Macro F1: 0.6235; Exact Match: 0.3987\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Specific\n",
            "   Macro F1: 0.6275; Exact Match: 0.5000\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Specific\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6122; Exact Match: 0.7140\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7695; Exact Match: 0.5400\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6512; Exact Match: 0.5036\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7333; Exact Match: 0.6094\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5836; Exact Match: 0.2857\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6382; Exact Match: 0.4658\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7312; Exact Match: 0.5542\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.4833; Exact Match: 0.4286\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7121; Exact Match: 0.5230\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7982; Exact Match: 0.4746\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.8000; Exact Match: 0.2857\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6544; Exact Match: 0.3952\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6106; Exact Match: 0.3168\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5484; Exact Match: 0.3800\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2756; Exact Match: 0.8193\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5978; Exact Match: 0.3800\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7052\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 458.\n",
            "\n",
            "-- Evaluating SEED=1018 --\n",
            "Using AGE optimized subgroup thresholds ONLY for seed 1018.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_1018_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Subgroup-Specific Threshold Dictionary.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5578\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.6740\n",
            "  recall_macro: 0.7512\n",
            "  f1_macro: 0.7084\n",
            "  precision_micro: 0.7100\n",
            "  recall_micro: 0.7937\n",
            "  f1_micro: 0.7495\n",
            "  precision_weighted: 0.7181\n",
            "  recall_weighted: 0.7937\n",
            "  f1_weighted: 0.7526\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7194; Exact Match: 0.5751\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6951; Exact Match: 0.5394\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Specific\n",
            "   Macro F1: 0.6531; Exact Match: 0.6089\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Specific\n",
            "   Macro F1: 0.6618; Exact Match: 0.6498\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Specific\n",
            "   Macro F1: 0.6971; Exact Match: 0.5073\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Specific\n",
            "   Macro F1: 0.4539; Exact Match: 0.8434\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Specific\n",
            "   Macro F1: 0.6222; Exact Match: 0.7451\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Specific\n",
            "   Macro F1: 0.3122; Exact Match: 0.6596\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Specific\n",
            "   Macro F1: 0.7051; Exact Match: 0.4712\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Specific\n",
            "   Macro F1: 0.6438; Exact Match: 0.4281\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Specific\n",
            "   Macro F1: 0.5950; Exact Match: 0.4412\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Specific\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5815; Exact Match: 0.7185\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7301; Exact Match: 0.4400\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6545; Exact Match: 0.4879\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7466; Exact Match: 0.6042\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5486; Exact Match: 0.5000\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6974; Exact Match: 0.5068\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7182; Exact Match: 0.5208\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5778; Exact Match: 0.5714\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7187; Exact Match: 0.5057\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.8251; Exact Match: 0.5085\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.8167; Exact Match: 0.2857\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6533; Exact Match: 0.3528\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6208; Exact Match: 0.2710\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5509; Exact Match: 0.3564\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2855; Exact Match: 0.8442\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5861; Exact Match: 0.3417\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7073\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 1018.\n",
            "\n",
            "-- Evaluating SEED=1016 --\n",
            "Using AGE optimized subgroup thresholds ONLY for seed 1016.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_1016_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Subgroup-Specific Threshold Dictionary.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5728\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.6902\n",
            "  recall_macro: 0.7238\n",
            "  f1_macro: 0.7055\n",
            "  precision_micro: 0.7294\n",
            "  recall_micro: 0.7754\n",
            "  f1_micro: 0.7517\n",
            "  precision_weighted: 0.7301\n",
            "  recall_weighted: 0.7754\n",
            "  f1_weighted: 0.7508\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7088; Exact Match: 0.5769\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6996; Exact Match: 0.5685\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Specific\n",
            "   Macro F1: 0.6631; Exact Match: 0.6386\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Specific\n",
            "   Macro F1: 0.6434; Exact Match: 0.6160\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Specific\n",
            "   Macro F1: 0.6857; Exact Match: 0.5114\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Specific\n",
            "   Macro F1: 0.4448; Exact Match: 0.7831\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Specific\n",
            "   Macro F1: 0.6053; Exact Match: 0.7190\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Specific\n",
            "   Macro F1: 0.3122; Exact Match: 0.7660\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Specific\n",
            "   Macro F1: 0.7157; Exact Match: 0.4823\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Specific\n",
            "   Macro F1: 0.6113; Exact Match: 0.3954\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Specific\n",
            "   Macro F1: 0.5911; Exact Match: 0.4706\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Specific\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5682; Exact Match: 0.7162\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7561; Exact Match: 0.5200\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6530; Exact Match: 0.5064\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7276; Exact Match: 0.6172\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6429; Exact Match: 0.5714\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6933; Exact Match: 0.5068\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7125; Exact Match: 0.5417\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5500; Exact Match: 0.4286\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7376; Exact Match: 0.5402\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7990; Exact Match: 0.4576\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7667; Exact Match: 0.2857\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6429; Exact Match: 0.3649\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5977; Exact Match: 0.2634\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5399; Exact Match: 0.3673\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2791; Exact Match: 0.8370\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5966; Exact Match: 0.3858\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7042\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 1016.\n",
            "\n",
            "-- Evaluating SEED=391 --\n",
            "Using AGE optimized subgroup thresholds ONLY for seed 391.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_391_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Subgroup-Specific Threshold Dictionary.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5591\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.6778\n",
            "  recall_macro: 0.7382\n",
            "  f1_macro: 0.7020\n",
            "  precision_micro: 0.7083\n",
            "  recall_micro: 0.7801\n",
            "  f1_micro: 0.7425\n",
            "  precision_weighted: 0.7215\n",
            "  recall_weighted: 0.7801\n",
            "  f1_weighted: 0.7465\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7148; Exact Match: 0.5777\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6867; Exact Match: 0.5394\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Specific\n",
            "   Macro F1: 0.6736; Exact Match: 0.6114\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Specific\n",
            "   Macro F1: 0.6621; Exact Match: 0.6160\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Specific\n",
            "   Macro F1: 0.6921; Exact Match: 0.5114\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Specific\n",
            "   Macro F1: 0.4288; Exact Match: 0.7831\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Specific\n",
            "   Macro F1: 0.6369; Exact Match: 0.7190\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Specific\n",
            "   Macro F1: 0.5312; Exact Match: 0.4894\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Specific\n",
            "   Macro F1: 0.7032; Exact Match: 0.4801\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Specific\n",
            "   Macro F1: 0.6348; Exact Match: 0.4118\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Specific\n",
            "   Macro F1: 0.5571; Exact Match: 0.3529\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Specific\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5781; Exact Match: 0.7231\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7262; Exact Match: 0.4500\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6552; Exact Match: 0.4922\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7279; Exact Match: 0.5781\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7088; Exact Match: 0.6429\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6702; Exact Match: 0.4658\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7233; Exact Match: 0.5542\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5500; Exact Match: 0.5714\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7011; Exact Match: 0.5172\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7828; Exact Match: 0.4576\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.8381; Exact Match: 0.4286\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6288; Exact Match: 0.3266\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6196; Exact Match: 0.3015\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5502; Exact Match: 0.3836\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2731; Exact Match: 0.8401\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5897; Exact Match: 0.3436\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7008\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 391.\n",
            "\n",
            "-- Evaluating SEED=976 --\n",
            "Using AGE optimized subgroup thresholds ONLY for seed 976.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_976_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Subgroup-Specific Threshold Dictionary.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5869\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.7064\n",
            "  recall_macro: 0.7182\n",
            "  f1_macro: 0.7084\n",
            "  precision_micro: 0.7366\n",
            "  recall_micro: 0.7711\n",
            "  f1_micro: 0.7535\n",
            "  precision_weighted: 0.7400\n",
            "  recall_weighted: 0.7711\n",
            "  f1_weighted: 0.7510\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7214; Exact Match: 0.6087\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6919; Exact Match: 0.5638\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Specific\n",
            "   Macro F1: 0.6821; Exact Match: 0.6337\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Specific\n",
            "   Macro F1: 0.6447; Exact Match: 0.5907\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Specific\n",
            "   Macro F1: 0.6912; Exact Match: 0.4969\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Specific\n",
            "   Macro F1: 0.5169; Exact Match: 0.8434\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Specific\n",
            "   Macro F1: 0.6145; Exact Match: 0.7124\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Specific\n",
            "   Macro F1: 0.3165; Exact Match: 0.7234\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Specific\n",
            "   Macro F1: 0.6980; Exact Match: 0.4712\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Specific\n",
            "   Macro F1: 0.6469; Exact Match: 0.4542\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Specific\n",
            "   Macro F1: 0.5898; Exact Match: 0.3824\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Specific\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5571; Exact Match: 0.7323\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7407; Exact Match: 0.5000\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6663; Exact Match: 0.5377\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7199; Exact Match: 0.5990\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6448; Exact Match: 0.4286\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6720; Exact Match: 0.4521\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7541; Exact Match: 0.5792\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5111; Exact Match: 0.7143\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7207; Exact Match: 0.5920\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7755; Exact Match: 0.4068\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7833; Exact Match: 0.2857\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6253; Exact Match: 0.3427\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6076; Exact Match: 0.2748\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5415; Exact Match: 0.3636\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2854; Exact Match: 0.8567\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5864; Exact Match: 0.3858\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7067\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 976.\n",
            "\n",
            "==================== Evaluating Condition: Optimized_Subgroup_Device ====================\n",
            "Using device: cuda, DA Flag: False, Thresh Mode: subgroup, Focus: device\n",
            "\n",
            "-- Evaluating SEED=458 --\n",
            "Using DEVICE optimized subgroup thresholds ONLY for seed 458.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_458_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Subgroup-Specific Threshold Dictionary.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5682\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.6741\n",
            "  recall_macro: 0.7455\n",
            "  f1_macro: 0.7062\n",
            "  precision_micro: 0.7109\n",
            "  recall_micro: 0.7855\n",
            "  f1_micro: 0.7463\n",
            "  precision_weighted: 0.7180\n",
            "  recall_weighted: 0.7855\n",
            "  f1_weighted: 0.7490\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7226; Exact Match: 0.5936\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6878; Exact Match: 0.5413\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6854; Exact Match: 0.6262\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6828; Exact Match: 0.7215\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6936; Exact Match: 0.5177\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.4292; Exact Match: 0.8193\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6271; Exact Match: 0.7516\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5331; Exact Match: 0.7872\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7029; Exact Match: 0.4801\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6232; Exact Match: 0.3954\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6298; Exact Match: 0.5294\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Specific\n",
            "   Macro F1: 0.6338; Exact Match: 0.7094\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Specific\n",
            "   Macro F1: 0.7534; Exact Match: 0.5100\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Specific\n",
            "   Macro F1: 0.6470; Exact Match: 0.5064\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Specific\n",
            "   Macro F1: 0.7253; Exact Match: 0.5573\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Specific\n",
            "   Macro F1: 0.5076; Exact Match: 0.2857\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Specific\n",
            "   Macro F1: 0.6602; Exact Match: 0.4521\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Specific\n",
            "   Macro F1: 0.6872; Exact Match: 0.5417\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Specific\n",
            "   Macro F1: 0.4788; Exact Match: 0.4286\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Specific\n",
            "   Macro F1: 0.6894; Exact Match: 0.4770\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Specific\n",
            "   Macro F1: 0.7911; Exact Match: 0.4576\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Specific\n",
            "   Macro F1: 0.7333; Exact Match: 0.1429\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6544; Exact Match: 0.3952\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6106; Exact Match: 0.3168\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5484; Exact Match: 0.3800\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2756; Exact Match: 0.8193\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5978; Exact Match: 0.3800\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7052\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 458.\n",
            "\n",
            "-- Evaluating SEED=1018 --\n",
            "Using DEVICE optimized subgroup thresholds ONLY for seed 1018.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_1018_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Subgroup-Specific Threshold Dictionary.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5578\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.6740\n",
            "  recall_macro: 0.7512\n",
            "  f1_macro: 0.7084\n",
            "  precision_micro: 0.7100\n",
            "  recall_micro: 0.7937\n",
            "  f1_micro: 0.7495\n",
            "  precision_weighted: 0.7181\n",
            "  recall_weighted: 0.7937\n",
            "  f1_weighted: 0.7526\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7194; Exact Match: 0.5751\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6951; Exact Match: 0.5394\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6882; Exact Match: 0.6337\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6785; Exact Match: 0.7089\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6990; Exact Match: 0.5073\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.4355; Exact Match: 0.8313\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6165; Exact Match: 0.7516\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.3165; Exact Match: 0.7872\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7077; Exact Match: 0.4513\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6355; Exact Match: 0.3889\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5944; Exact Match: 0.4118\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Specific\n",
            "   Macro F1: 0.5817; Exact Match: 0.7002\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Specific\n",
            "   Macro F1: 0.7543; Exact Match: 0.5000\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Specific\n",
            "   Macro F1: 0.6560; Exact Match: 0.5164\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Specific\n",
            "   Macro F1: 0.7372; Exact Match: 0.5625\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Specific\n",
            "   Macro F1: 0.5281; Exact Match: 0.4286\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Specific\n",
            "   Macro F1: 0.6666; Exact Match: 0.5342\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Specific\n",
            "   Macro F1: 0.7157; Exact Match: 0.5208\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Specific\n",
            "   Macro F1: 0.5455; Exact Match: 0.5714\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Specific\n",
            "   Macro F1: 0.7147; Exact Match: 0.5172\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Specific\n",
            "   Macro F1: 0.8007; Exact Match: 0.4407\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Specific\n",
            "   Macro F1: 0.7500; Exact Match: 0.1429\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6533; Exact Match: 0.3528\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6208; Exact Match: 0.2710\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5509; Exact Match: 0.3564\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2855; Exact Match: 0.8442\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5861; Exact Match: 0.3417\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7073\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 1018.\n",
            "\n",
            "-- Evaluating SEED=1016 --\n",
            "Using DEVICE optimized subgroup thresholds ONLY for seed 1016.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_1016_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Subgroup-Specific Threshold Dictionary.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5728\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.6902\n",
            "  recall_macro: 0.7238\n",
            "  f1_macro: 0.7055\n",
            "  precision_micro: 0.7294\n",
            "  recall_micro: 0.7754\n",
            "  f1_micro: 0.7517\n",
            "  precision_weighted: 0.7301\n",
            "  recall_weighted: 0.7754\n",
            "  f1_weighted: 0.7508\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7088; Exact Match: 0.5769\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6996; Exact Match: 0.5685\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6726; Exact Match: 0.6510\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6549; Exact Match: 0.7046\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6908; Exact Match: 0.5052\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.4593; Exact Match: 0.8434\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6023; Exact Match: 0.7451\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.3165; Exact Match: 0.7872\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7118; Exact Match: 0.5022\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6218; Exact Match: 0.3954\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6286; Exact Match: 0.5000\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Specific\n",
            "   Macro F1: 0.5857; Exact Match: 0.6819\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Specific\n",
            "   Macro F1: 0.7708; Exact Match: 0.5500\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Specific\n",
            "   Macro F1: 0.6517; Exact Match: 0.5249\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Specific\n",
            "   Macro F1: 0.7271; Exact Match: 0.5755\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Specific\n",
            "   Macro F1: 0.5603; Exact Match: 0.3571\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Specific\n",
            "   Macro F1: 0.6956; Exact Match: 0.4795\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Specific\n",
            "   Macro F1: 0.7177; Exact Match: 0.5208\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Specific\n",
            "   Macro F1: 0.5600; Exact Match: 0.4286\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Specific\n",
            "   Macro F1: 0.7480; Exact Match: 0.5862\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Specific\n",
            "   Macro F1: 0.7908; Exact Match: 0.4237\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Specific\n",
            "   Macro F1: 0.8014; Exact Match: 0.2857\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6429; Exact Match: 0.3649\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5977; Exact Match: 0.2634\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5399; Exact Match: 0.3673\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2791; Exact Match: 0.8370\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5966; Exact Match: 0.3858\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7042\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 1016.\n",
            "\n",
            "-- Evaluating SEED=391 --\n",
            "Using DEVICE optimized subgroup thresholds ONLY for seed 391.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_391_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Subgroup-Specific Threshold Dictionary.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5591\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.6778\n",
            "  recall_macro: 0.7382\n",
            "  f1_macro: 0.7020\n",
            "  precision_micro: 0.7083\n",
            "  recall_micro: 0.7801\n",
            "  f1_micro: 0.7425\n",
            "  precision_weighted: 0.7215\n",
            "  recall_weighted: 0.7801\n",
            "  f1_weighted: 0.7465\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7148; Exact Match: 0.5777\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6867; Exact Match: 0.5394\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6712; Exact Match: 0.6238\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6518; Exact Match: 0.6962\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6903; Exact Match: 0.5198\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.4368; Exact Match: 0.8434\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6258; Exact Match: 0.7516\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5165; Exact Match: 0.7872\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7016; Exact Match: 0.4690\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6330; Exact Match: 0.3660\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5950; Exact Match: 0.4706\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Specific\n",
            "   Macro F1: 0.6344; Exact Match: 0.7140\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Specific\n",
            "   Macro F1: 0.7300; Exact Match: 0.4600\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Specific\n",
            "   Macro F1: 0.6584; Exact Match: 0.4893\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Specific\n",
            "   Macro F1: 0.7369; Exact Match: 0.5964\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Specific\n",
            "   Macro F1: 0.5079; Exact Match: 0.3571\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Specific\n",
            "   Macro F1: 0.6671; Exact Match: 0.4795\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Specific\n",
            "   Macro F1: 0.7158; Exact Match: 0.5375\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Specific\n",
            "   Macro F1: 0.5600; Exact Match: 0.4286\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Specific\n",
            "   Macro F1: 0.6997; Exact Match: 0.5230\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Specific\n",
            "   Macro F1: 0.7983; Exact Match: 0.4576\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Specific\n",
            "   Macro F1: 0.8214; Exact Match: 0.4286\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6288; Exact Match: 0.3266\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6196; Exact Match: 0.3015\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5502; Exact Match: 0.3836\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2731; Exact Match: 0.8401\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5897; Exact Match: 0.3436\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7008\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 391.\n",
            "\n",
            "-- Evaluating SEED=976 --\n",
            "Using DEVICE optimized subgroup thresholds ONLY for seed 976.\n",
            "\n",
            "--- Starting Detailed Evaluation for Model: final_model_seed_976_epoch_30.pth ---\n",
            "Model loaded successfully.\n",
            "Running inference...\n",
            "Inference complete. Calculating metrics...\n",
            "Using Subgroup-Specific Threshold Dictionary.\n",
            "\n",
            "--- Overall Metrics (All Samples) ---\n",
            "  num_samples: 2198\n",
            "  exact_match_ratio: 0.5869\n",
            "  mean_true_labels: 1.2702\n",
            "  precision_macro: 0.7064\n",
            "  recall_macro: 0.7182\n",
            "  f1_macro: 0.7084\n",
            "  precision_micro: 0.7366\n",
            "  recall_micro: 0.7711\n",
            "  f1_micro: 0.7535\n",
            "  precision_weighted: 0.7400\n",
            "  recall_weighted: 0.7711\n",
            "  f1_weighted: 0.7510\n",
            "\n",
            "--- Metrics by Subgroup Type: SEX ---\n",
            " -- Subgroup: 0 --\n",
            "   (N=1132) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7214; Exact Match: 0.6087\n",
            " -- Subgroup: 1 --\n",
            "   (N=1066) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6919; Exact Match: 0.5638\n",
            "\n",
            "--- Metrics by Subgroup Type: AGE_BIN ---\n",
            " -- Subgroup: 50s --\n",
            "   (N=404) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6856; Exact Match: 0.6510\n",
            " -- Subgroup: 40s --\n",
            "   (N=237) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6547; Exact Match: 0.7426\n",
            " -- Subgroup: 60s --\n",
            "   (N=481) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6840; Exact Match: 0.5405\n",
            " -- Subgroup: 20s --\n",
            "   (N=83) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.4641; Exact Match: 0.8434\n",
            " -- Subgroup: 30s --\n",
            "   (N=153) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6253; Exact Match: 0.7647\n",
            " -- Subgroup: 10s --\n",
            "   (N=47) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2754; Exact Match: 0.7660\n",
            " -- Subgroup: 70s --\n",
            "   (N=452) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.7112; Exact Match: 0.4934\n",
            " -- Subgroup: 80s --\n",
            "   (N=306) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6391; Exact Match: 0.4216\n",
            " -- Subgroup: 90 --\n",
            "   (N=34) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6185; Exact Match: 0.4706\n",
            " -- Subgroup: 0s --\n",
            "   (N=1) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.0000; Exact Match: 0.0000\n",
            "\n",
            "--- Metrics by Subgroup Type: DEVICE ---\n",
            " -- Subgroup: CS-12   E --\n",
            "   (N=437) Applied thresholds: Specific\n",
            "   Macro F1: 0.6096; Exact Match: 0.6773\n",
            " -- Subgroup: AT-6 C --\n",
            "   (N=100) Applied thresholds: Specific\n",
            "   Macro F1: 0.7414; Exact Match: 0.4600\n",
            " -- Subgroup: CS-12 --\n",
            "   (N=703) Applied thresholds: Specific\n",
            "   Macro F1: 0.6712; Exact Match: 0.5263\n",
            " -- Subgroup: AT-6 C 5.5 --\n",
            "   (N=384) Applied thresholds: Specific\n",
            "   Macro F1: 0.7296; Exact Match: 0.5833\n",
            " -- Subgroup: AT-6 C 5.0 --\n",
            "   (N=14) Applied thresholds: Specific\n",
            "   Macro F1: 0.5378; Exact Match: 0.2857\n",
            " -- Subgroup: AT-6 C 5.8 --\n",
            "   (N=73) Applied thresholds: Specific\n",
            "   Macro F1: 0.6662; Exact Match: 0.5205\n",
            " -- Subgroup: AT-6     6 --\n",
            "   (N=240) Applied thresholds: Specific\n",
            "   Macro F1: 0.7457; Exact Match: 0.5542\n",
            " -- Subgroup: AT-6 C 5.6 --\n",
            "   (N=7) Applied thresholds: Specific\n",
            "   Macro F1: 0.4788; Exact Match: 0.4286\n",
            " -- Subgroup: AT-60    3 --\n",
            "   (N=174) Applied thresholds: Specific\n",
            "   Macro F1: 0.7229; Exact Match: 0.5057\n",
            " -- Subgroup: CS100    3 --\n",
            "   (N=59) Applied thresholds: Specific\n",
            "   Macro F1: 0.7647; Exact Match: 0.3729\n",
            " -- Subgroup: AT-6 C 5.3 --\n",
            "   (N=7) Applied thresholds: Specific\n",
            "   Macro F1: 0.8014; Exact Match: 0.1429\n",
            "\n",
            "--- Metrics by Subgroup Type: DIAGNOSTIC_CLASS ---\n",
            " -- Subgroup: CD --\n",
            "   (N=496) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6253; Exact Match: 0.3427\n",
            " -- Subgroup: HYP --\n",
            "   (N=262) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.6076; Exact Match: 0.2748\n",
            " -- Subgroup: MI --\n",
            "   (N=550) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5415; Exact Match: 0.3636\n",
            " -- Subgroup: NORM --\n",
            "   (N=963) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.2854; Exact Match: 0.8567\n",
            " -- Subgroup: STTC --\n",
            "   (N=521) Applied thresholds: Fallback/Global\n",
            "   Macro F1: 0.5864; Exact Match: 0.3858\n",
            "\n",
            "--- Cross-Group Metrics ---\n",
            "  Avg Macro F1 (M/F): 0.7067\n",
            "\n",
            "--- Detailed Evaluation Complete ---\n",
            "Evaluation complete for seed 976.\n",
            "\n",
            "Saving detailed raw evaluation results to: evaluation_results/all_evaluation_results_raw.pkl\n",
            "Raw results saved successfully.\n",
            "\n",
            "==================== Aggregating Evaluation Results Across Seeds ====================\n",
            "Using existing 'all_evaluation_results' dictionary.\n",
            "\n",
            "--- Aggregating for Condition: Optimized_Global ---\n",
            "  Aggregating from 5 valid run(s).\n",
            "\n",
            "    Processing Top Key: ALL\n",
            "      Metrics for: ALL\n",
            "        num_samples: Mean=2198.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5690, Std=0.0106\n",
            "        mean_true_labels: Mean=1.2702, Std=0.0000\n",
            "        precision_macro: Mean=0.6845, Std=0.0125\n",
            "        recall_macro: Mean=0.7354, Std=0.0126\n",
            "        f1_macro: Mean=0.7061, Std=0.0023\n",
            "        precision_micro: Mean=0.7190, Std=0.0117\n",
            "        recall_micro: Mean=0.7812, Std=0.0079\n",
            "        f1_micro: Mean=0.7487, Std=0.0039\n",
            "        precision_weighted: Mean=0.7255, Std=0.0085\n",
            "        recall_weighted: Mean=0.7812, Std=0.0079\n",
            "        f1_weighted: Mean=0.7500, Std=0.0021\n",
            "\n",
            "    Processing Top Key: SEX\n",
            "      Subgroup: 0\n",
            "        num_samples: Mean=1132.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5864, Std=0.0130\n",
            "        mean_true_labels: Mean=1.2747, Std=0.0000\n",
            "        precision_macro: Mean=0.6965, Std=0.0113\n",
            "        recall_macro: Mean=0.7437, Std=0.0138\n",
            "        f1_macro: Mean=0.7174, Std=0.0050\n",
            "      Subgroup: 1\n",
            "        num_samples: Mean=1066.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5505, Std=0.0129\n",
            "        mean_true_labels: Mean=1.2655, Std=0.0000\n",
            "        precision_macro: Mean=0.6705, Std=0.0141\n",
            "        recall_macro: Mean=0.7255, Std=0.0131\n",
            "        f1_macro: Mean=0.6922, Std=0.0047\n",
            "\n",
            "    Processing Top Key: AGE_BIN\n",
            "      Subgroup: 50s\n",
            "        num_samples: Mean=404.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.6371, Std=0.0118\n",
            "        mean_true_labels: Mean=1.1906, Std=0.0000\n",
            "        precision_macro: Mean=0.6843, Std=0.0127\n",
            "        recall_macro: Mean=0.6845, Std=0.0095\n",
            "        f1_macro: Mean=0.6806, Std=0.0072\n",
            "      Subgroup: 40s\n",
            "        num_samples: Mean=237.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.7148, Std=0.0161\n",
            "        mean_true_labels: Mean=1.1181, Std=0.0000\n",
            "        precision_macro: Mean=0.6816, Std=0.0113\n",
            "        recall_macro: Mean=0.6606, Std=0.0205\n",
            "        f1_macro: Mean=0.6645, Std=0.0133\n",
            "      Subgroup: 60s\n",
            "        num_samples: Mean=481.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5181, Std=0.0126\n",
            "        mean_true_labels: Mean=1.2557, Std=0.0000\n",
            "        precision_macro: Mean=0.6643, Std=0.0081\n",
            "        recall_macro: Mean=0.7250, Std=0.0179\n",
            "        f1_macro: Mean=0.6915, Std=0.0049\n",
            "      Subgroup: 20s\n",
            "        num_samples: Mean=83.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.8361, Std=0.0096\n",
            "        mean_true_labels: Mean=1.0723, Std=0.0000\n",
            "        precision_macro: Mean=0.4769, Std=0.0176\n",
            "        recall_macro: Mean=0.4398, Std=0.0249\n",
            "        f1_macro: Mean=0.4450, Std=0.0140\n",
            "      Subgroup: 30s\n",
            "        num_samples: Mean=153.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.7529, Std=0.0064\n",
            "        mean_true_labels: Mean=1.1046, Std=0.0000\n",
            "        precision_macro: Mean=0.7061, Std=0.0627\n",
            "        recall_macro: Mean=0.5734, Std=0.0229\n",
            "        f1_macro: Mean=0.6194, Std=0.0093\n",
            "      Subgroup: 10s\n",
            "        num_samples: Mean=47.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.7830, Std=0.0085\n",
            "        mean_true_labels: Mean=1.0851, Std=0.0000\n",
            "        precision_macro: Mean=0.4489, Std=0.0980\n",
            "        recall_macro: Mean=0.3760, Std=0.1106\n",
            "        f1_macro: Mean=0.3916, Std=0.1099\n",
            "      Subgroup: 70s\n",
            "        num_samples: Mean=452.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4792, Std=0.0180\n",
            "        mean_true_labels: Mean=1.3761, Std=0.0000\n",
            "        precision_macro: Mean=0.6744, Std=0.0144\n",
            "        recall_macro: Mean=0.7548, Std=0.0110\n",
            "        f1_macro: Mean=0.7070, Std=0.0042\n",
            "      Subgroup: 80s\n",
            "        num_samples: Mean=306.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3935, Std=0.0177\n",
            "        mean_true_labels: Mean=1.4869, Std=0.0000\n",
            "        precision_macro: Mean=0.5838, Std=0.0176\n",
            "        recall_macro: Mean=0.7065, Std=0.0245\n",
            "        f1_macro: Mean=0.6305, Std=0.0068\n",
            "      Subgroup: 90\n",
            "        num_samples: Mean=34.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4765, Std=0.0390\n",
            "        mean_true_labels: Mean=1.6176, Std=0.0000\n",
            "        precision_macro: Mean=0.5583, Std=0.0273\n",
            "        recall_macro: Mean=0.7267, Std=0.0119\n",
            "        f1_macro: Mean=0.6133, Std=0.0156\n",
            "      Subgroup: 0s\n",
            "        num_samples: Mean=1.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.0000, Std=0.0000\n",
            "        mean_true_labels: Mean=1.0000, Std=0.0000\n",
            "        precision_macro: Mean=0.0000, Std=0.0000\n",
            "        recall_macro: Mean=0.0000, Std=0.0000\n",
            "        f1_macro: Mean=0.0000, Std=0.0000\n",
            "\n",
            "    Processing Top Key: DEVICE\n",
            "      Subgroup: CS-12   E\n",
            "        num_samples: Mean=437.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.7208, Std=0.0065\n",
            "        mean_true_labels: Mean=1.0824, Std=0.0000\n",
            "        precision_macro: Mean=0.6708, Std=0.0211\n",
            "        recall_macro: Mean=0.5419, Std=0.0253\n",
            "        f1_macro: Mean=0.5794, Std=0.0184\n",
            "      Subgroup: AT-6 C\n",
            "        num_samples: Mean=100.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4900, Std=0.0390\n",
            "        mean_true_labels: Mean=1.5200, Std=0.0000\n",
            "        precision_macro: Mean=0.6933, Std=0.0222\n",
            "        recall_macro: Mean=0.8121, Std=0.0121\n",
            "        f1_macro: Mean=0.7445, Std=0.0162\n",
            "      Subgroup: CS-12\n",
            "        num_samples: Mean=703.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5055, Std=0.0175\n",
            "        mean_true_labels: Mean=1.2617, Std=0.0000\n",
            "        precision_macro: Mean=0.6316, Std=0.0145\n",
            "        recall_macro: Mean=0.6959, Std=0.0086\n",
            "        f1_macro: Mean=0.6560, Std=0.0053\n",
            "      Subgroup: AT-6 C 5.5\n",
            "        num_samples: Mean=384.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.6016, Std=0.0132\n",
            "        mean_true_labels: Mean=1.2891, Std=0.0000\n",
            "        precision_macro: Mean=0.7103, Std=0.0093\n",
            "        recall_macro: Mean=0.7567, Std=0.0216\n",
            "        f1_macro: Mean=0.7311, Std=0.0089\n",
            "      Subgroup: AT-6 C 5.0\n",
            "        num_samples: Mean=14.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4857, Std=0.1229\n",
            "        mean_true_labels: Mean=1.0714, Std=0.0000\n",
            "        precision_macro: Mean=0.5447, Std=0.0721\n",
            "        recall_macro: Mean=0.8040, Std=0.0332\n",
            "        f1_macro: Mean=0.6257, Std=0.0553\n",
            "      Subgroup: AT-6 C 5.8\n",
            "        num_samples: Mean=73.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4795, Std=0.0229\n",
            "        mean_true_labels: Mean=1.3014, Std=0.0000\n",
            "        precision_macro: Mean=0.6556, Std=0.0261\n",
            "        recall_macro: Mean=0.7022, Std=0.0215\n",
            "        f1_macro: Mean=0.6742, Std=0.0211\n",
            "      Subgroup: AT-6     6\n",
            "        num_samples: Mean=240.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5500, Std=0.0190\n",
            "        mean_true_labels: Mean=1.3333, Std=0.0000\n",
            "        precision_macro: Mean=0.6986, Std=0.0212\n",
            "        recall_macro: Mean=0.7651, Std=0.0194\n",
            "        f1_macro: Mean=0.7279, Std=0.0145\n",
            "      Subgroup: AT-6 C 5.6\n",
            "        num_samples: Mean=7.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5429, Std=0.1069\n",
            "        mean_true_labels: Mean=1.0000, Std=0.0000\n",
            "        precision_macro: Mean=0.5140, Std=0.0484\n",
            "        recall_macro: Mean=0.5700, Std=0.0245\n",
            "        f1_macro: Mean=0.5344, Std=0.0332\n",
            "      Subgroup: AT-60    3\n",
            "        num_samples: Mean=174.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5356, Std=0.0303\n",
            "        mean_true_labels: Mean=1.2989, Std=0.0000\n",
            "        precision_macro: Mean=0.6687, Std=0.0234\n",
            "        recall_macro: Mean=0.7862, Std=0.0235\n",
            "        f1_macro: Mean=0.7180, Std=0.0119\n",
            "      Subgroup: CS100    3\n",
            "        num_samples: Mean=59.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4610, Std=0.0329\n",
            "        mean_true_labels: Mean=1.8475, Std=0.0000\n",
            "        precision_macro: Mean=0.8055, Std=0.0053\n",
            "        recall_macro: Mean=0.7988, Std=0.0274\n",
            "        f1_macro: Mean=0.7961, Std=0.0170\n",
            "      Subgroup: AT-6 C 5.3\n",
            "        num_samples: Mean=7.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3143, Std=0.0571\n",
            "        mean_true_labels: Mean=1.8571, Std=0.0000\n",
            "        precision_macro: Mean=0.7947, Std=0.0176\n",
            "        recall_macro: Mean=0.9100, Std=0.0200\n",
            "        f1_macro: Mean=0.8010, Std=0.0250\n",
            "\n",
            "    Processing Top Key: DIAGNOSTIC_CLASS\n",
            "      Subgroup: CD\n",
            "        num_samples: Mean=496.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3565, Std=0.0231\n",
            "        mean_true_labels: Mean=1.8004, Std=0.0000\n",
            "        precision_macro: Mean=0.6128, Std=0.0096\n",
            "        recall_macro: Mean=0.7287, Std=0.0160\n",
            "        f1_macro: Mean=0.6409, Std=0.0121\n",
            "      Subgroup: HYP\n",
            "        num_samples: Mean=262.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.2855, Std=0.0203\n",
            "        mean_true_labels: Mean=2.1870, Std=0.0000\n",
            "        precision_macro: Mean=0.6529, Std=0.0074\n",
            "        recall_macro: Mean=0.7645, Std=0.0392\n",
            "        f1_macro: Mean=0.6113, Std=0.0085\n",
            "      Subgroup: MI\n",
            "        num_samples: Mean=550.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3702, Std=0.0102\n",
            "        mean_true_labels: Mean=1.7145, Std=0.0000\n",
            "        precision_macro: Mean=0.5407, Std=0.0109\n",
            "        recall_macro: Mean=0.5798, Std=0.0232\n",
            "        f1_macro: Mean=0.5462, Std=0.0046\n",
            "      Subgroup: NORM\n",
            "        num_samples: Mean=963.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.8395, Std=0.0121\n",
            "        mean_true_labels: Mean=1.0550, Std=0.0000\n",
            "        precision_macro: Mean=0.2892, Std=0.0105\n",
            "        recall_macro: Mean=0.2731, Std=0.0097\n",
            "        f1_macro: Mean=0.2797, Std=0.0050\n",
            "      Subgroup: STTC\n",
            "        num_samples: Mean=521.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3674, Std=0.0203\n",
            "        mean_true_labels: Mean=1.7639, Std=0.0000\n",
            "        precision_macro: Mean=0.5720, Std=0.0128\n",
            "        recall_macro: Mean=0.7302, Std=0.0087\n",
            "        f1_macro: Mean=0.5913, Std=0.0050\n",
            "\n",
            "    Processing Top Key: OVERALL_METRICS\n",
            "      Metrics for: OVERALL_METRICS\n",
            "        avg_macro_recall_male_female: Mean=0.7346, Std=0.0126\n",
            "        avg_macro_precision_male_female: Mean=0.6835, Std=0.0122\n",
            "        avg_macro_f1_male_female: Mean=0.7048, Std=0.0023\n",
            "\n",
            "--- Aggregating for Condition: Optimized_Subgroup_Combined ---\n",
            "  Aggregating from 5 valid run(s).\n",
            "\n",
            "    Processing Top Key: ALL\n",
            "      Metrics for: ALL\n",
            "        num_samples: Mean=2198.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5690, Std=0.0106\n",
            "        mean_true_labels: Mean=1.2702, Std=0.0000\n",
            "        precision_macro: Mean=0.6845, Std=0.0125\n",
            "        recall_macro: Mean=0.7354, Std=0.0126\n",
            "        f1_macro: Mean=0.7061, Std=0.0023\n",
            "        precision_micro: Mean=0.7190, Std=0.0117\n",
            "        recall_micro: Mean=0.7812, Std=0.0079\n",
            "        f1_micro: Mean=0.7487, Std=0.0039\n",
            "        precision_weighted: Mean=0.7255, Std=0.0085\n",
            "        recall_weighted: Mean=0.7812, Std=0.0079\n",
            "        f1_weighted: Mean=0.7500, Std=0.0021\n",
            "\n",
            "    Processing Top Key: SEX\n",
            "      Subgroup: 0\n",
            "        num_samples: Mean=1132.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5728, Std=0.0064\n",
            "        mean_true_labels: Mean=1.2747, Std=0.0000\n",
            "        precision_macro: Mean=0.6909, Std=0.0067\n",
            "        recall_macro: Mean=0.7512, Std=0.0078\n",
            "        f1_macro: Mean=0.7162, Std=0.0033\n",
            "      Subgroup: 1\n",
            "        num_samples: Mean=1066.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5540, Std=0.0088\n",
            "        mean_true_labels: Mean=1.2655, Std=0.0000\n",
            "        precision_macro: Mean=0.6668, Std=0.0076\n",
            "        recall_macro: Mean=0.7301, Std=0.0147\n",
            "        f1_macro: Mean=0.6945, Std=0.0038\n",
            "\n",
            "    Processing Top Key: AGE_BIN\n",
            "      Subgroup: 50s\n",
            "        num_samples: Mean=404.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.6262, Std=0.0133\n",
            "        mean_true_labels: Mean=1.1906, Std=0.0000\n",
            "        precision_macro: Mean=0.6769, Std=0.0133\n",
            "        recall_macro: Mean=0.6759, Std=0.0168\n",
            "        f1_macro: Mean=0.6690, Std=0.0100\n",
            "      Subgroup: 40s\n",
            "        num_samples: Mean=237.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.6203, Std=0.0192\n",
            "        mean_true_labels: Mean=1.1181, Std=0.0000\n",
            "        precision_macro: Mean=0.6064, Std=0.0255\n",
            "        recall_macro: Mean=0.7525, Std=0.0253\n",
            "        f1_macro: Mean=0.6554, Std=0.0093\n",
            "      Subgroup: 60s\n",
            "        num_samples: Mean=481.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5089, Std=0.0069\n",
            "        mean_true_labels: Mean=1.2557, Std=0.0000\n",
            "        precision_macro: Mean=0.6569, Std=0.0057\n",
            "        recall_macro: Mean=0.7342, Std=0.0121\n",
            "        f1_macro: Mean=0.6914, Std=0.0036\n",
            "      Subgroup: 20s\n",
            "        num_samples: Mean=83.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.8000, Std=0.0378\n",
            "        mean_true_labels: Mean=1.0723, Std=0.0000\n",
            "        precision_macro: Mean=0.4585, Std=0.0527\n",
            "        recall_macro: Mean=0.4874, Std=0.0609\n",
            "        f1_macro: Mean=0.4525, Std=0.0345\n",
            "      Subgroup: 30s\n",
            "        num_samples: Mean=153.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.7255, Std=0.0117\n",
            "        mean_true_labels: Mean=1.1046, Std=0.0000\n",
            "        precision_macro: Mean=0.6133, Std=0.0222\n",
            "        recall_macro: Mean=0.6611, Std=0.0216\n",
            "        f1_macro: Mean=0.6186, Std=0.0106\n",
            "      Subgroup: 10s\n",
            "        num_samples: Mean=47.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.6511, Std=0.0957\n",
            "        mean_true_labels: Mean=1.0851, Std=0.0000\n",
            "        precision_macro: Mean=0.4451, Std=0.0993\n",
            "        recall_macro: Mean=0.4240, Std=0.1622\n",
            "        f1_macro: Mean=0.4002, Std=0.1060\n",
            "      Subgroup: 70s\n",
            "        num_samples: Mean=452.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4650, Std=0.0228\n",
            "        mean_true_labels: Mean=1.3761, Std=0.0000\n",
            "        precision_macro: Mean=0.6648, Std=0.0202\n",
            "        recall_macro: Mean=0.7580, Std=0.0146\n",
            "        f1_macro: Mean=0.7021, Std=0.0089\n",
            "      Subgroup: 80s\n",
            "        num_samples: Mean=306.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4176, Std=0.0216\n",
            "        mean_true_labels: Mean=1.4869, Std=0.0000\n",
            "        precision_macro: Mean=0.6320, Std=0.0161\n",
            "        recall_macro: Mean=0.6505, Std=0.0292\n",
            "        f1_macro: Mean=0.6321, Std=0.0132\n",
            "      Subgroup: 90\n",
            "        num_samples: Mean=34.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4294, Std=0.0546\n",
            "        mean_true_labels: Mean=1.6176, Std=0.0000\n",
            "        precision_macro: Mean=0.5532, Std=0.0246\n",
            "        recall_macro: Mean=0.7059, Std=0.0202\n",
            "        f1_macro: Mean=0.5921, Std=0.0223\n",
            "      Subgroup: 0s\n",
            "        num_samples: Mean=1.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.0000, Std=0.0000\n",
            "        mean_true_labels: Mean=1.0000, Std=0.0000\n",
            "        precision_macro: Mean=0.0000, Std=0.0000\n",
            "        recall_macro: Mean=0.0000, Std=0.0000\n",
            "        f1_macro: Mean=0.0000, Std=0.0000\n",
            "\n",
            "    Processing Top Key: DEVICE\n",
            "      Subgroup: CS-12   E\n",
            "        num_samples: Mean=437.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.6966, Std=0.0146\n",
            "        mean_true_labels: Mean=1.0824, Std=0.0000\n",
            "        precision_macro: Mean=0.6297, Std=0.0238\n",
            "        recall_macro: Mean=0.6291, Std=0.0288\n",
            "        f1_macro: Mean=0.6090, Std=0.0226\n",
            "      Subgroup: AT-6 C\n",
            "        num_samples: Mean=100.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4960, Std=0.0338\n",
            "        mean_true_labels: Mean=1.5200, Std=0.0000\n",
            "        precision_macro: Mean=0.7166, Std=0.0261\n",
            "        recall_macro: Mean=0.8102, Std=0.0270\n",
            "        f1_macro: Mean=0.7500, Std=0.0137\n",
            "      Subgroup: CS-12\n",
            "        num_samples: Mean=703.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5127, Std=0.0137\n",
            "        mean_true_labels: Mean=1.2617, Std=0.0000\n",
            "        precision_macro: Mean=0.6392, Std=0.0095\n",
            "        recall_macro: Mean=0.6888, Std=0.0172\n",
            "        f1_macro: Mean=0.6569, Std=0.0081\n",
            "      Subgroup: AT-6 C 5.5\n",
            "        num_samples: Mean=384.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5750, Std=0.0141\n",
            "        mean_true_labels: Mean=1.2891, Std=0.0000\n",
            "        precision_macro: Mean=0.6984, Std=0.0118\n",
            "        recall_macro: Mean=0.7739, Std=0.0167\n",
            "        f1_macro: Mean=0.7312, Std=0.0050\n",
            "      Subgroup: AT-6 C 5.0\n",
            "        num_samples: Mean=14.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3429, Std=0.0535\n",
            "        mean_true_labels: Mean=1.0714, Std=0.0000\n",
            "        precision_macro: Mean=0.4730, Std=0.0216\n",
            "        recall_macro: Mean=0.7660, Std=0.0561\n",
            "        f1_macro: Mean=0.5283, Std=0.0198\n",
            "      Subgroup: AT-6 C 5.8\n",
            "        num_samples: Mean=73.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4932, Std=0.0300\n",
            "        mean_true_labels: Mean=1.3014, Std=0.0000\n",
            "        precision_macro: Mean=0.6579, Std=0.0308\n",
            "        recall_macro: Mean=0.7160, Std=0.0347\n",
            "        f1_macro: Mean=0.6712, Std=0.0125\n",
            "      Subgroup: AT-6     6\n",
            "        num_samples: Mean=240.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5350, Std=0.0128\n",
            "        mean_true_labels: Mean=1.3333, Std=0.0000\n",
            "        precision_macro: Mean=0.6980, Std=0.0183\n",
            "        recall_macro: Mean=0.7486, Std=0.0481\n",
            "        f1_macro: Mean=0.7164, Std=0.0185\n",
            "      Subgroup: AT-6 C 5.6\n",
            "        num_samples: Mean=7.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4571, Std=0.0571\n",
            "        mean_true_labels: Mean=1.0000, Std=0.0000\n",
            "        precision_macro: Mean=0.4819, Std=0.0556\n",
            "        recall_macro: Mean=0.6000, Std=0.0000\n",
            "        f1_macro: Mean=0.5246, Std=0.0378\n",
            "      Subgroup: AT-60    3\n",
            "        num_samples: Mean=174.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5218, Std=0.0359\n",
            "        mean_true_labels: Mean=1.2989, Std=0.0000\n",
            "        precision_macro: Mean=0.6744, Std=0.0214\n",
            "        recall_macro: Mean=0.7763, Std=0.0292\n",
            "        f1_macro: Mean=0.7149, Std=0.0202\n",
            "      Subgroup: CS100    3\n",
            "        num_samples: Mean=59.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4305, Std=0.0314\n",
            "        mean_true_labels: Mean=1.8475, Std=0.0000\n",
            "        precision_macro: Mean=0.7842, Std=0.0134\n",
            "        recall_macro: Mean=0.8086, Std=0.0236\n",
            "        f1_macro: Mean=0.7891, Std=0.0128\n",
            "      Subgroup: AT-6 C 5.3\n",
            "        num_samples: Mean=7.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.2286, Std=0.1143\n",
            "        mean_true_labels: Mean=1.8571, Std=0.0000\n",
            "        precision_macro: Mean=0.7653, Std=0.0153\n",
            "        recall_macro: Mean=0.9300, Std=0.0245\n",
            "        f1_macro: Mean=0.7815, Std=0.0338\n",
            "\n",
            "    Processing Top Key: DIAGNOSTIC_CLASS\n",
            "      Subgroup: CD\n",
            "        num_samples: Mean=496.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3565, Std=0.0231\n",
            "        mean_true_labels: Mean=1.8004, Std=0.0000\n",
            "        precision_macro: Mean=0.6128, Std=0.0096\n",
            "        recall_macro: Mean=0.7287, Std=0.0160\n",
            "        f1_macro: Mean=0.6409, Std=0.0121\n",
            "      Subgroup: HYP\n",
            "        num_samples: Mean=262.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.2855, Std=0.0203\n",
            "        mean_true_labels: Mean=2.1870, Std=0.0000\n",
            "        precision_macro: Mean=0.6529, Std=0.0074\n",
            "        recall_macro: Mean=0.7645, Std=0.0392\n",
            "        f1_macro: Mean=0.6113, Std=0.0085\n",
            "      Subgroup: MI\n",
            "        num_samples: Mean=550.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3702, Std=0.0102\n",
            "        mean_true_labels: Mean=1.7145, Std=0.0000\n",
            "        precision_macro: Mean=0.5407, Std=0.0109\n",
            "        recall_macro: Mean=0.5798, Std=0.0232\n",
            "        f1_macro: Mean=0.5462, Std=0.0046\n",
            "      Subgroup: NORM\n",
            "        num_samples: Mean=963.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.8395, Std=0.0121\n",
            "        mean_true_labels: Mean=1.0550, Std=0.0000\n",
            "        precision_macro: Mean=0.2892, Std=0.0105\n",
            "        recall_macro: Mean=0.2731, Std=0.0097\n",
            "        f1_macro: Mean=0.2797, Std=0.0050\n",
            "      Subgroup: STTC\n",
            "        num_samples: Mean=521.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3674, Std=0.0203\n",
            "        mean_true_labels: Mean=1.7639, Std=0.0000\n",
            "        precision_macro: Mean=0.5720, Std=0.0128\n",
            "        recall_macro: Mean=0.7302, Std=0.0087\n",
            "        f1_macro: Mean=0.5913, Std=0.0050\n",
            "\n",
            "    Processing Top Key: OVERALL_METRICS\n",
            "      Metrics for: OVERALL_METRICS\n",
            "        avg_macro_recall_male_female: Mean=0.7407, Std=0.0064\n",
            "        avg_macro_precision_male_female: Mean=0.6789, Std=0.0046\n",
            "        avg_macro_f1_male_female: Mean=0.7054, Std=0.0019\n",
            "\n",
            "--- Aggregating for Condition: Optimized_Subgroup_Sex ---\n",
            "  Aggregating from 5 valid run(s).\n",
            "\n",
            "    Processing Top Key: ALL\n",
            "      Metrics for: ALL\n",
            "        num_samples: Mean=2198.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5690, Std=0.0106\n",
            "        mean_true_labels: Mean=1.2702, Std=0.0000\n",
            "        precision_macro: Mean=0.6845, Std=0.0125\n",
            "        recall_macro: Mean=0.7354, Std=0.0126\n",
            "        f1_macro: Mean=0.7061, Std=0.0023\n",
            "        precision_micro: Mean=0.7190, Std=0.0117\n",
            "        recall_micro: Mean=0.7812, Std=0.0079\n",
            "        f1_micro: Mean=0.7487, Std=0.0039\n",
            "        precision_weighted: Mean=0.7255, Std=0.0085\n",
            "        recall_weighted: Mean=0.7812, Std=0.0079\n",
            "        f1_weighted: Mean=0.7500, Std=0.0021\n",
            "\n",
            "    Processing Top Key: SEX\n",
            "      Subgroup: 0\n",
            "        num_samples: Mean=1132.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5728, Std=0.0064\n",
            "        mean_true_labels: Mean=1.2747, Std=0.0000\n",
            "        precision_macro: Mean=0.6909, Std=0.0067\n",
            "        recall_macro: Mean=0.7512, Std=0.0078\n",
            "        f1_macro: Mean=0.7162, Std=0.0033\n",
            "      Subgroup: 1\n",
            "        num_samples: Mean=1066.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5540, Std=0.0088\n",
            "        mean_true_labels: Mean=1.2655, Std=0.0000\n",
            "        precision_macro: Mean=0.6668, Std=0.0076\n",
            "        recall_macro: Mean=0.7301, Std=0.0147\n",
            "        f1_macro: Mean=0.6945, Std=0.0038\n",
            "\n",
            "    Processing Top Key: AGE_BIN\n",
            "      Subgroup: 50s\n",
            "        num_samples: Mean=404.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.6371, Std=0.0118\n",
            "        mean_true_labels: Mean=1.1906, Std=0.0000\n",
            "        precision_macro: Mean=0.6843, Std=0.0127\n",
            "        recall_macro: Mean=0.6845, Std=0.0095\n",
            "        f1_macro: Mean=0.6806, Std=0.0072\n",
            "      Subgroup: 40s\n",
            "        num_samples: Mean=237.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.7148, Std=0.0161\n",
            "        mean_true_labels: Mean=1.1181, Std=0.0000\n",
            "        precision_macro: Mean=0.6816, Std=0.0113\n",
            "        recall_macro: Mean=0.6606, Std=0.0205\n",
            "        f1_macro: Mean=0.6645, Std=0.0133\n",
            "      Subgroup: 60s\n",
            "        num_samples: Mean=481.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5181, Std=0.0126\n",
            "        mean_true_labels: Mean=1.2557, Std=0.0000\n",
            "        precision_macro: Mean=0.6643, Std=0.0081\n",
            "        recall_macro: Mean=0.7250, Std=0.0179\n",
            "        f1_macro: Mean=0.6915, Std=0.0049\n",
            "      Subgroup: 20s\n",
            "        num_samples: Mean=83.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.8361, Std=0.0096\n",
            "        mean_true_labels: Mean=1.0723, Std=0.0000\n",
            "        precision_macro: Mean=0.4769, Std=0.0176\n",
            "        recall_macro: Mean=0.4398, Std=0.0249\n",
            "        f1_macro: Mean=0.4450, Std=0.0140\n",
            "      Subgroup: 30s\n",
            "        num_samples: Mean=153.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.7529, Std=0.0064\n",
            "        mean_true_labels: Mean=1.1046, Std=0.0000\n",
            "        precision_macro: Mean=0.7061, Std=0.0627\n",
            "        recall_macro: Mean=0.5734, Std=0.0229\n",
            "        f1_macro: Mean=0.6194, Std=0.0093\n",
            "      Subgroup: 10s\n",
            "        num_samples: Mean=47.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.7830, Std=0.0085\n",
            "        mean_true_labels: Mean=1.0851, Std=0.0000\n",
            "        precision_macro: Mean=0.4489, Std=0.0980\n",
            "        recall_macro: Mean=0.3760, Std=0.1106\n",
            "        f1_macro: Mean=0.3916, Std=0.1099\n",
            "      Subgroup: 70s\n",
            "        num_samples: Mean=452.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4792, Std=0.0180\n",
            "        mean_true_labels: Mean=1.3761, Std=0.0000\n",
            "        precision_macro: Mean=0.6744, Std=0.0144\n",
            "        recall_macro: Mean=0.7548, Std=0.0110\n",
            "        f1_macro: Mean=0.7070, Std=0.0042\n",
            "      Subgroup: 80s\n",
            "        num_samples: Mean=306.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3935, Std=0.0177\n",
            "        mean_true_labels: Mean=1.4869, Std=0.0000\n",
            "        precision_macro: Mean=0.5838, Std=0.0176\n",
            "        recall_macro: Mean=0.7065, Std=0.0245\n",
            "        f1_macro: Mean=0.6305, Std=0.0068\n",
            "      Subgroup: 90\n",
            "        num_samples: Mean=34.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4765, Std=0.0390\n",
            "        mean_true_labels: Mean=1.6176, Std=0.0000\n",
            "        precision_macro: Mean=0.5583, Std=0.0273\n",
            "        recall_macro: Mean=0.7267, Std=0.0119\n",
            "        f1_macro: Mean=0.6133, Std=0.0156\n",
            "      Subgroup: 0s\n",
            "        num_samples: Mean=1.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.0000, Std=0.0000\n",
            "        mean_true_labels: Mean=1.0000, Std=0.0000\n",
            "        precision_macro: Mean=0.0000, Std=0.0000\n",
            "        recall_macro: Mean=0.0000, Std=0.0000\n",
            "        f1_macro: Mean=0.0000, Std=0.0000\n",
            "\n",
            "    Processing Top Key: DEVICE\n",
            "      Subgroup: CS-12   E\n",
            "        num_samples: Mean=437.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.7208, Std=0.0065\n",
            "        mean_true_labels: Mean=1.0824, Std=0.0000\n",
            "        precision_macro: Mean=0.6708, Std=0.0211\n",
            "        recall_macro: Mean=0.5419, Std=0.0253\n",
            "        f1_macro: Mean=0.5794, Std=0.0184\n",
            "      Subgroup: AT-6 C\n",
            "        num_samples: Mean=100.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4900, Std=0.0390\n",
            "        mean_true_labels: Mean=1.5200, Std=0.0000\n",
            "        precision_macro: Mean=0.6933, Std=0.0222\n",
            "        recall_macro: Mean=0.8121, Std=0.0121\n",
            "        f1_macro: Mean=0.7445, Std=0.0162\n",
            "      Subgroup: CS-12\n",
            "        num_samples: Mean=703.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5055, Std=0.0175\n",
            "        mean_true_labels: Mean=1.2617, Std=0.0000\n",
            "        precision_macro: Mean=0.6316, Std=0.0145\n",
            "        recall_macro: Mean=0.6959, Std=0.0086\n",
            "        f1_macro: Mean=0.6560, Std=0.0053\n",
            "      Subgroup: AT-6 C 5.5\n",
            "        num_samples: Mean=384.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.6016, Std=0.0132\n",
            "        mean_true_labels: Mean=1.2891, Std=0.0000\n",
            "        precision_macro: Mean=0.7103, Std=0.0093\n",
            "        recall_macro: Mean=0.7567, Std=0.0216\n",
            "        f1_macro: Mean=0.7311, Std=0.0089\n",
            "      Subgroup: AT-6 C 5.0\n",
            "        num_samples: Mean=14.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4857, Std=0.1229\n",
            "        mean_true_labels: Mean=1.0714, Std=0.0000\n",
            "        precision_macro: Mean=0.5447, Std=0.0721\n",
            "        recall_macro: Mean=0.8040, Std=0.0332\n",
            "        f1_macro: Mean=0.6257, Std=0.0553\n",
            "      Subgroup: AT-6 C 5.8\n",
            "        num_samples: Mean=73.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4795, Std=0.0229\n",
            "        mean_true_labels: Mean=1.3014, Std=0.0000\n",
            "        precision_macro: Mean=0.6556, Std=0.0261\n",
            "        recall_macro: Mean=0.7022, Std=0.0215\n",
            "        f1_macro: Mean=0.6742, Std=0.0211\n",
            "      Subgroup: AT-6     6\n",
            "        num_samples: Mean=240.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5500, Std=0.0190\n",
            "        mean_true_labels: Mean=1.3333, Std=0.0000\n",
            "        precision_macro: Mean=0.6986, Std=0.0212\n",
            "        recall_macro: Mean=0.7651, Std=0.0194\n",
            "        f1_macro: Mean=0.7279, Std=0.0145\n",
            "      Subgroup: AT-6 C 5.6\n",
            "        num_samples: Mean=7.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5429, Std=0.1069\n",
            "        mean_true_labels: Mean=1.0000, Std=0.0000\n",
            "        precision_macro: Mean=0.5140, Std=0.0484\n",
            "        recall_macro: Mean=0.5700, Std=0.0245\n",
            "        f1_macro: Mean=0.5344, Std=0.0332\n",
            "      Subgroup: AT-60    3\n",
            "        num_samples: Mean=174.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5356, Std=0.0303\n",
            "        mean_true_labels: Mean=1.2989, Std=0.0000\n",
            "        precision_macro: Mean=0.6687, Std=0.0234\n",
            "        recall_macro: Mean=0.7862, Std=0.0235\n",
            "        f1_macro: Mean=0.7180, Std=0.0119\n",
            "      Subgroup: CS100    3\n",
            "        num_samples: Mean=59.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4610, Std=0.0329\n",
            "        mean_true_labels: Mean=1.8475, Std=0.0000\n",
            "        precision_macro: Mean=0.8055, Std=0.0053\n",
            "        recall_macro: Mean=0.7988, Std=0.0274\n",
            "        f1_macro: Mean=0.7961, Std=0.0170\n",
            "      Subgroup: AT-6 C 5.3\n",
            "        num_samples: Mean=7.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3143, Std=0.0571\n",
            "        mean_true_labels: Mean=1.8571, Std=0.0000\n",
            "        precision_macro: Mean=0.7947, Std=0.0176\n",
            "        recall_macro: Mean=0.9100, Std=0.0200\n",
            "        f1_macro: Mean=0.8010, Std=0.0250\n",
            "\n",
            "    Processing Top Key: DIAGNOSTIC_CLASS\n",
            "      Subgroup: CD\n",
            "        num_samples: Mean=496.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3565, Std=0.0231\n",
            "        mean_true_labels: Mean=1.8004, Std=0.0000\n",
            "        precision_macro: Mean=0.6128, Std=0.0096\n",
            "        recall_macro: Mean=0.7287, Std=0.0160\n",
            "        f1_macro: Mean=0.6409, Std=0.0121\n",
            "      Subgroup: HYP\n",
            "        num_samples: Mean=262.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.2855, Std=0.0203\n",
            "        mean_true_labels: Mean=2.1870, Std=0.0000\n",
            "        precision_macro: Mean=0.6529, Std=0.0074\n",
            "        recall_macro: Mean=0.7645, Std=0.0392\n",
            "        f1_macro: Mean=0.6113, Std=0.0085\n",
            "      Subgroup: MI\n",
            "        num_samples: Mean=550.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3702, Std=0.0102\n",
            "        mean_true_labels: Mean=1.7145, Std=0.0000\n",
            "        precision_macro: Mean=0.5407, Std=0.0109\n",
            "        recall_macro: Mean=0.5798, Std=0.0232\n",
            "        f1_macro: Mean=0.5462, Std=0.0046\n",
            "      Subgroup: NORM\n",
            "        num_samples: Mean=963.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.8395, Std=0.0121\n",
            "        mean_true_labels: Mean=1.0550, Std=0.0000\n",
            "        precision_macro: Mean=0.2892, Std=0.0105\n",
            "        recall_macro: Mean=0.2731, Std=0.0097\n",
            "        f1_macro: Mean=0.2797, Std=0.0050\n",
            "      Subgroup: STTC\n",
            "        num_samples: Mean=521.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3674, Std=0.0203\n",
            "        mean_true_labels: Mean=1.7639, Std=0.0000\n",
            "        precision_macro: Mean=0.5720, Std=0.0128\n",
            "        recall_macro: Mean=0.7302, Std=0.0087\n",
            "        f1_macro: Mean=0.5913, Std=0.0050\n",
            "\n",
            "    Processing Top Key: OVERALL_METRICS\n",
            "      Metrics for: OVERALL_METRICS\n",
            "        avg_macro_recall_male_female: Mean=0.7407, Std=0.0064\n",
            "        avg_macro_precision_male_female: Mean=0.6789, Std=0.0046\n",
            "        avg_macro_f1_male_female: Mean=0.7054, Std=0.0019\n",
            "\n",
            "--- Aggregating for Condition: Optimized_Subgroup_Age ---\n",
            "  Aggregating from 5 valid run(s).\n",
            "\n",
            "    Processing Top Key: ALL\n",
            "      Metrics for: ALL\n",
            "        num_samples: Mean=2198.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5690, Std=0.0106\n",
            "        mean_true_labels: Mean=1.2702, Std=0.0000\n",
            "        precision_macro: Mean=0.6845, Std=0.0125\n",
            "        recall_macro: Mean=0.7354, Std=0.0126\n",
            "        f1_macro: Mean=0.7061, Std=0.0023\n",
            "        precision_micro: Mean=0.7190, Std=0.0117\n",
            "        recall_micro: Mean=0.7812, Std=0.0079\n",
            "        f1_micro: Mean=0.7487, Std=0.0039\n",
            "        precision_weighted: Mean=0.7255, Std=0.0085\n",
            "        recall_weighted: Mean=0.7812, Std=0.0079\n",
            "        f1_weighted: Mean=0.7500, Std=0.0021\n",
            "\n",
            "    Processing Top Key: SEX\n",
            "      Subgroup: 0\n",
            "        num_samples: Mean=1132.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5864, Std=0.0130\n",
            "        mean_true_labels: Mean=1.2747, Std=0.0000\n",
            "        precision_macro: Mean=0.6965, Std=0.0113\n",
            "        recall_macro: Mean=0.7437, Std=0.0138\n",
            "        f1_macro: Mean=0.7174, Std=0.0050\n",
            "      Subgroup: 1\n",
            "        num_samples: Mean=1066.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5505, Std=0.0129\n",
            "        mean_true_labels: Mean=1.2655, Std=0.0000\n",
            "        precision_macro: Mean=0.6705, Std=0.0141\n",
            "        recall_macro: Mean=0.7255, Std=0.0131\n",
            "        f1_macro: Mean=0.6922, Std=0.0047\n",
            "\n",
            "    Processing Top Key: AGE_BIN\n",
            "      Subgroup: 50s\n",
            "        num_samples: Mean=404.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.6262, Std=0.0133\n",
            "        mean_true_labels: Mean=1.1906, Std=0.0000\n",
            "        precision_macro: Mean=0.6769, Std=0.0133\n",
            "        recall_macro: Mean=0.6759, Std=0.0168\n",
            "        f1_macro: Mean=0.6690, Std=0.0100\n",
            "      Subgroup: 40s\n",
            "        num_samples: Mean=237.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.6203, Std=0.0192\n",
            "        mean_true_labels: Mean=1.1181, Std=0.0000\n",
            "        precision_macro: Mean=0.6064, Std=0.0255\n",
            "        recall_macro: Mean=0.7525, Std=0.0253\n",
            "        f1_macro: Mean=0.6554, Std=0.0093\n",
            "      Subgroup: 60s\n",
            "        num_samples: Mean=481.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5089, Std=0.0069\n",
            "        mean_true_labels: Mean=1.2557, Std=0.0000\n",
            "        precision_macro: Mean=0.6569, Std=0.0057\n",
            "        recall_macro: Mean=0.7342, Std=0.0121\n",
            "        f1_macro: Mean=0.6914, Std=0.0036\n",
            "      Subgroup: 20s\n",
            "        num_samples: Mean=83.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.8000, Std=0.0378\n",
            "        mean_true_labels: Mean=1.0723, Std=0.0000\n",
            "        precision_macro: Mean=0.4585, Std=0.0527\n",
            "        recall_macro: Mean=0.4874, Std=0.0609\n",
            "        f1_macro: Mean=0.4525, Std=0.0345\n",
            "      Subgroup: 30s\n",
            "        num_samples: Mean=153.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.7255, Std=0.0117\n",
            "        mean_true_labels: Mean=1.1046, Std=0.0000\n",
            "        precision_macro: Mean=0.6133, Std=0.0222\n",
            "        recall_macro: Mean=0.6611, Std=0.0216\n",
            "        f1_macro: Mean=0.6186, Std=0.0106\n",
            "      Subgroup: 10s\n",
            "        num_samples: Mean=47.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.6511, Std=0.0957\n",
            "        mean_true_labels: Mean=1.0851, Std=0.0000\n",
            "        precision_macro: Mean=0.4451, Std=0.0993\n",
            "        recall_macro: Mean=0.4240, Std=0.1622\n",
            "        f1_macro: Mean=0.4002, Std=0.1060\n",
            "      Subgroup: 70s\n",
            "        num_samples: Mean=452.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4650, Std=0.0228\n",
            "        mean_true_labels: Mean=1.3761, Std=0.0000\n",
            "        precision_macro: Mean=0.6648, Std=0.0202\n",
            "        recall_macro: Mean=0.7580, Std=0.0146\n",
            "        f1_macro: Mean=0.7021, Std=0.0089\n",
            "      Subgroup: 80s\n",
            "        num_samples: Mean=306.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4176, Std=0.0216\n",
            "        mean_true_labels: Mean=1.4869, Std=0.0000\n",
            "        precision_macro: Mean=0.6320, Std=0.0161\n",
            "        recall_macro: Mean=0.6505, Std=0.0292\n",
            "        f1_macro: Mean=0.6321, Std=0.0132\n",
            "      Subgroup: 90\n",
            "        num_samples: Mean=34.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4294, Std=0.0546\n",
            "        mean_true_labels: Mean=1.6176, Std=0.0000\n",
            "        precision_macro: Mean=0.5532, Std=0.0246\n",
            "        recall_macro: Mean=0.7059, Std=0.0202\n",
            "        f1_macro: Mean=0.5921, Std=0.0223\n",
            "      Subgroup: 0s\n",
            "        num_samples: Mean=1.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.0000, Std=0.0000\n",
            "        mean_true_labels: Mean=1.0000, Std=0.0000\n",
            "        precision_macro: Mean=0.0000, Std=0.0000\n",
            "        recall_macro: Mean=0.0000, Std=0.0000\n",
            "        f1_macro: Mean=0.0000, Std=0.0000\n",
            "\n",
            "    Processing Top Key: DEVICE\n",
            "      Subgroup: CS-12   E\n",
            "        num_samples: Mean=437.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.7208, Std=0.0065\n",
            "        mean_true_labels: Mean=1.0824, Std=0.0000\n",
            "        precision_macro: Mean=0.6708, Std=0.0211\n",
            "        recall_macro: Mean=0.5419, Std=0.0253\n",
            "        f1_macro: Mean=0.5794, Std=0.0184\n",
            "      Subgroup: AT-6 C\n",
            "        num_samples: Mean=100.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4900, Std=0.0390\n",
            "        mean_true_labels: Mean=1.5200, Std=0.0000\n",
            "        precision_macro: Mean=0.6933, Std=0.0222\n",
            "        recall_macro: Mean=0.8121, Std=0.0121\n",
            "        f1_macro: Mean=0.7445, Std=0.0162\n",
            "      Subgroup: CS-12\n",
            "        num_samples: Mean=703.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5055, Std=0.0175\n",
            "        mean_true_labels: Mean=1.2617, Std=0.0000\n",
            "        precision_macro: Mean=0.6316, Std=0.0145\n",
            "        recall_macro: Mean=0.6959, Std=0.0086\n",
            "        f1_macro: Mean=0.6560, Std=0.0053\n",
            "      Subgroup: AT-6 C 5.5\n",
            "        num_samples: Mean=384.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.6016, Std=0.0132\n",
            "        mean_true_labels: Mean=1.2891, Std=0.0000\n",
            "        precision_macro: Mean=0.7103, Std=0.0093\n",
            "        recall_macro: Mean=0.7567, Std=0.0216\n",
            "        f1_macro: Mean=0.7311, Std=0.0089\n",
            "      Subgroup: AT-6 C 5.0\n",
            "        num_samples: Mean=14.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4857, Std=0.1229\n",
            "        mean_true_labels: Mean=1.0714, Std=0.0000\n",
            "        precision_macro: Mean=0.5447, Std=0.0721\n",
            "        recall_macro: Mean=0.8040, Std=0.0332\n",
            "        f1_macro: Mean=0.6257, Std=0.0553\n",
            "      Subgroup: AT-6 C 5.8\n",
            "        num_samples: Mean=73.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4795, Std=0.0229\n",
            "        mean_true_labels: Mean=1.3014, Std=0.0000\n",
            "        precision_macro: Mean=0.6556, Std=0.0261\n",
            "        recall_macro: Mean=0.7022, Std=0.0215\n",
            "        f1_macro: Mean=0.6742, Std=0.0211\n",
            "      Subgroup: AT-6     6\n",
            "        num_samples: Mean=240.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5500, Std=0.0190\n",
            "        mean_true_labels: Mean=1.3333, Std=0.0000\n",
            "        precision_macro: Mean=0.6986, Std=0.0212\n",
            "        recall_macro: Mean=0.7651, Std=0.0194\n",
            "        f1_macro: Mean=0.7279, Std=0.0145\n",
            "      Subgroup: AT-6 C 5.6\n",
            "        num_samples: Mean=7.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5429, Std=0.1069\n",
            "        mean_true_labels: Mean=1.0000, Std=0.0000\n",
            "        precision_macro: Mean=0.5140, Std=0.0484\n",
            "        recall_macro: Mean=0.5700, Std=0.0245\n",
            "        f1_macro: Mean=0.5344, Std=0.0332\n",
            "      Subgroup: AT-60    3\n",
            "        num_samples: Mean=174.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5356, Std=0.0303\n",
            "        mean_true_labels: Mean=1.2989, Std=0.0000\n",
            "        precision_macro: Mean=0.6687, Std=0.0234\n",
            "        recall_macro: Mean=0.7862, Std=0.0235\n",
            "        f1_macro: Mean=0.7180, Std=0.0119\n",
            "      Subgroup: CS100    3\n",
            "        num_samples: Mean=59.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4610, Std=0.0329\n",
            "        mean_true_labels: Mean=1.8475, Std=0.0000\n",
            "        precision_macro: Mean=0.8055, Std=0.0053\n",
            "        recall_macro: Mean=0.7988, Std=0.0274\n",
            "        f1_macro: Mean=0.7961, Std=0.0170\n",
            "      Subgroup: AT-6 C 5.3\n",
            "        num_samples: Mean=7.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3143, Std=0.0571\n",
            "        mean_true_labels: Mean=1.8571, Std=0.0000\n",
            "        precision_macro: Mean=0.7947, Std=0.0176\n",
            "        recall_macro: Mean=0.9100, Std=0.0200\n",
            "        f1_macro: Mean=0.8010, Std=0.0250\n",
            "\n",
            "    Processing Top Key: DIAGNOSTIC_CLASS\n",
            "      Subgroup: CD\n",
            "        num_samples: Mean=496.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3565, Std=0.0231\n",
            "        mean_true_labels: Mean=1.8004, Std=0.0000\n",
            "        precision_macro: Mean=0.6128, Std=0.0096\n",
            "        recall_macro: Mean=0.7287, Std=0.0160\n",
            "        f1_macro: Mean=0.6409, Std=0.0121\n",
            "      Subgroup: HYP\n",
            "        num_samples: Mean=262.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.2855, Std=0.0203\n",
            "        mean_true_labels: Mean=2.1870, Std=0.0000\n",
            "        precision_macro: Mean=0.6529, Std=0.0074\n",
            "        recall_macro: Mean=0.7645, Std=0.0392\n",
            "        f1_macro: Mean=0.6113, Std=0.0085\n",
            "      Subgroup: MI\n",
            "        num_samples: Mean=550.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3702, Std=0.0102\n",
            "        mean_true_labels: Mean=1.7145, Std=0.0000\n",
            "        precision_macro: Mean=0.5407, Std=0.0109\n",
            "        recall_macro: Mean=0.5798, Std=0.0232\n",
            "        f1_macro: Mean=0.5462, Std=0.0046\n",
            "      Subgroup: NORM\n",
            "        num_samples: Mean=963.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.8395, Std=0.0121\n",
            "        mean_true_labels: Mean=1.0550, Std=0.0000\n",
            "        precision_macro: Mean=0.2892, Std=0.0105\n",
            "        recall_macro: Mean=0.2731, Std=0.0097\n",
            "        f1_macro: Mean=0.2797, Std=0.0050\n",
            "      Subgroup: STTC\n",
            "        num_samples: Mean=521.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3674, Std=0.0203\n",
            "        mean_true_labels: Mean=1.7639, Std=0.0000\n",
            "        precision_macro: Mean=0.5720, Std=0.0128\n",
            "        recall_macro: Mean=0.7302, Std=0.0087\n",
            "        f1_macro: Mean=0.5913, Std=0.0050\n",
            "\n",
            "    Processing Top Key: OVERALL_METRICS\n",
            "      Metrics for: OVERALL_METRICS\n",
            "        avg_macro_recall_male_female: Mean=0.7346, Std=0.0126\n",
            "        avg_macro_precision_male_female: Mean=0.6835, Std=0.0122\n",
            "        avg_macro_f1_male_female: Mean=0.7048, Std=0.0023\n",
            "\n",
            "--- Aggregating for Condition: Optimized_Subgroup_Device ---\n",
            "  Aggregating from 5 valid run(s).\n",
            "\n",
            "    Processing Top Key: ALL\n",
            "      Metrics for: ALL\n",
            "        num_samples: Mean=2198.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5690, Std=0.0106\n",
            "        mean_true_labels: Mean=1.2702, Std=0.0000\n",
            "        precision_macro: Mean=0.6845, Std=0.0125\n",
            "        recall_macro: Mean=0.7354, Std=0.0126\n",
            "        f1_macro: Mean=0.7061, Std=0.0023\n",
            "        precision_micro: Mean=0.7190, Std=0.0117\n",
            "        recall_micro: Mean=0.7812, Std=0.0079\n",
            "        f1_micro: Mean=0.7487, Std=0.0039\n",
            "        precision_weighted: Mean=0.7255, Std=0.0085\n",
            "        recall_weighted: Mean=0.7812, Std=0.0079\n",
            "        f1_weighted: Mean=0.7500, Std=0.0021\n",
            "\n",
            "    Processing Top Key: SEX\n",
            "      Subgroup: 0\n",
            "        num_samples: Mean=1132.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5864, Std=0.0130\n",
            "        mean_true_labels: Mean=1.2747, Std=0.0000\n",
            "        precision_macro: Mean=0.6965, Std=0.0113\n",
            "        recall_macro: Mean=0.7437, Std=0.0138\n",
            "        f1_macro: Mean=0.7174, Std=0.0050\n",
            "      Subgroup: 1\n",
            "        num_samples: Mean=1066.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5505, Std=0.0129\n",
            "        mean_true_labels: Mean=1.2655, Std=0.0000\n",
            "        precision_macro: Mean=0.6705, Std=0.0141\n",
            "        recall_macro: Mean=0.7255, Std=0.0131\n",
            "        f1_macro: Mean=0.6922, Std=0.0047\n",
            "\n",
            "    Processing Top Key: AGE_BIN\n",
            "      Subgroup: 50s\n",
            "        num_samples: Mean=404.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.6371, Std=0.0118\n",
            "        mean_true_labels: Mean=1.1906, Std=0.0000\n",
            "        precision_macro: Mean=0.6843, Std=0.0127\n",
            "        recall_macro: Mean=0.6845, Std=0.0095\n",
            "        f1_macro: Mean=0.6806, Std=0.0072\n",
            "      Subgroup: 40s\n",
            "        num_samples: Mean=237.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.7148, Std=0.0161\n",
            "        mean_true_labels: Mean=1.1181, Std=0.0000\n",
            "        precision_macro: Mean=0.6816, Std=0.0113\n",
            "        recall_macro: Mean=0.6606, Std=0.0205\n",
            "        f1_macro: Mean=0.6645, Std=0.0133\n",
            "      Subgroup: 60s\n",
            "        num_samples: Mean=481.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5181, Std=0.0126\n",
            "        mean_true_labels: Mean=1.2557, Std=0.0000\n",
            "        precision_macro: Mean=0.6643, Std=0.0081\n",
            "        recall_macro: Mean=0.7250, Std=0.0179\n",
            "        f1_macro: Mean=0.6915, Std=0.0049\n",
            "      Subgroup: 20s\n",
            "        num_samples: Mean=83.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.8361, Std=0.0096\n",
            "        mean_true_labels: Mean=1.0723, Std=0.0000\n",
            "        precision_macro: Mean=0.4769, Std=0.0176\n",
            "        recall_macro: Mean=0.4398, Std=0.0249\n",
            "        f1_macro: Mean=0.4450, Std=0.0140\n",
            "      Subgroup: 30s\n",
            "        num_samples: Mean=153.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.7529, Std=0.0064\n",
            "        mean_true_labels: Mean=1.1046, Std=0.0000\n",
            "        precision_macro: Mean=0.7061, Std=0.0627\n",
            "        recall_macro: Mean=0.5734, Std=0.0229\n",
            "        f1_macro: Mean=0.6194, Std=0.0093\n",
            "      Subgroup: 10s\n",
            "        num_samples: Mean=47.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.7830, Std=0.0085\n",
            "        mean_true_labels: Mean=1.0851, Std=0.0000\n",
            "        precision_macro: Mean=0.4489, Std=0.0980\n",
            "        recall_macro: Mean=0.3760, Std=0.1106\n",
            "        f1_macro: Mean=0.3916, Std=0.1099\n",
            "      Subgroup: 70s\n",
            "        num_samples: Mean=452.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4792, Std=0.0180\n",
            "        mean_true_labels: Mean=1.3761, Std=0.0000\n",
            "        precision_macro: Mean=0.6744, Std=0.0144\n",
            "        recall_macro: Mean=0.7548, Std=0.0110\n",
            "        f1_macro: Mean=0.7070, Std=0.0042\n",
            "      Subgroup: 80s\n",
            "        num_samples: Mean=306.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3935, Std=0.0177\n",
            "        mean_true_labels: Mean=1.4869, Std=0.0000\n",
            "        precision_macro: Mean=0.5838, Std=0.0176\n",
            "        recall_macro: Mean=0.7065, Std=0.0245\n",
            "        f1_macro: Mean=0.6305, Std=0.0068\n",
            "      Subgroup: 90\n",
            "        num_samples: Mean=34.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4765, Std=0.0390\n",
            "        mean_true_labels: Mean=1.6176, Std=0.0000\n",
            "        precision_macro: Mean=0.5583, Std=0.0273\n",
            "        recall_macro: Mean=0.7267, Std=0.0119\n",
            "        f1_macro: Mean=0.6133, Std=0.0156\n",
            "      Subgroup: 0s\n",
            "        num_samples: Mean=1.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.0000, Std=0.0000\n",
            "        mean_true_labels: Mean=1.0000, Std=0.0000\n",
            "        precision_macro: Mean=0.0000, Std=0.0000\n",
            "        recall_macro: Mean=0.0000, Std=0.0000\n",
            "        f1_macro: Mean=0.0000, Std=0.0000\n",
            "\n",
            "    Processing Top Key: DEVICE\n",
            "      Subgroup: CS-12   E\n",
            "        num_samples: Mean=437.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.6966, Std=0.0146\n",
            "        mean_true_labels: Mean=1.0824, Std=0.0000\n",
            "        precision_macro: Mean=0.6297, Std=0.0238\n",
            "        recall_macro: Mean=0.6291, Std=0.0288\n",
            "        f1_macro: Mean=0.6090, Std=0.0226\n",
            "      Subgroup: AT-6 C\n",
            "        num_samples: Mean=100.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4960, Std=0.0338\n",
            "        mean_true_labels: Mean=1.5200, Std=0.0000\n",
            "        precision_macro: Mean=0.7166, Std=0.0261\n",
            "        recall_macro: Mean=0.8102, Std=0.0270\n",
            "        f1_macro: Mean=0.7500, Std=0.0137\n",
            "      Subgroup: CS-12\n",
            "        num_samples: Mean=703.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5127, Std=0.0137\n",
            "        mean_true_labels: Mean=1.2617, Std=0.0000\n",
            "        precision_macro: Mean=0.6392, Std=0.0095\n",
            "        recall_macro: Mean=0.6888, Std=0.0172\n",
            "        f1_macro: Mean=0.6569, Std=0.0081\n",
            "      Subgroup: AT-6 C 5.5\n",
            "        num_samples: Mean=384.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5750, Std=0.0141\n",
            "        mean_true_labels: Mean=1.2891, Std=0.0000\n",
            "        precision_macro: Mean=0.6984, Std=0.0118\n",
            "        recall_macro: Mean=0.7739, Std=0.0167\n",
            "        f1_macro: Mean=0.7312, Std=0.0050\n",
            "      Subgroup: AT-6 C 5.0\n",
            "        num_samples: Mean=14.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3429, Std=0.0535\n",
            "        mean_true_labels: Mean=1.0714, Std=0.0000\n",
            "        precision_macro: Mean=0.4730, Std=0.0216\n",
            "        recall_macro: Mean=0.7660, Std=0.0561\n",
            "        f1_macro: Mean=0.5283, Std=0.0198\n",
            "      Subgroup: AT-6 C 5.8\n",
            "        num_samples: Mean=73.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4932, Std=0.0300\n",
            "        mean_true_labels: Mean=1.3014, Std=0.0000\n",
            "        precision_macro: Mean=0.6579, Std=0.0308\n",
            "        recall_macro: Mean=0.7160, Std=0.0347\n",
            "        f1_macro: Mean=0.6712, Std=0.0125\n",
            "      Subgroup: AT-6     6\n",
            "        num_samples: Mean=240.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5350, Std=0.0128\n",
            "        mean_true_labels: Mean=1.3333, Std=0.0000\n",
            "        precision_macro: Mean=0.6980, Std=0.0183\n",
            "        recall_macro: Mean=0.7486, Std=0.0481\n",
            "        f1_macro: Mean=0.7164, Std=0.0185\n",
            "      Subgroup: AT-6 C 5.6\n",
            "        num_samples: Mean=7.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4571, Std=0.0571\n",
            "        mean_true_labels: Mean=1.0000, Std=0.0000\n",
            "        precision_macro: Mean=0.4819, Std=0.0556\n",
            "        recall_macro: Mean=0.6000, Std=0.0000\n",
            "        f1_macro: Mean=0.5246, Std=0.0378\n",
            "      Subgroup: AT-60    3\n",
            "        num_samples: Mean=174.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.5218, Std=0.0359\n",
            "        mean_true_labels: Mean=1.2989, Std=0.0000\n",
            "        precision_macro: Mean=0.6744, Std=0.0214\n",
            "        recall_macro: Mean=0.7763, Std=0.0292\n",
            "        f1_macro: Mean=0.7149, Std=0.0202\n",
            "      Subgroup: CS100    3\n",
            "        num_samples: Mean=59.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.4305, Std=0.0314\n",
            "        mean_true_labels: Mean=1.8475, Std=0.0000\n",
            "        precision_macro: Mean=0.7842, Std=0.0134\n",
            "        recall_macro: Mean=0.8086, Std=0.0236\n",
            "        f1_macro: Mean=0.7891, Std=0.0128\n",
            "      Subgroup: AT-6 C 5.3\n",
            "        num_samples: Mean=7.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.2286, Std=0.1143\n",
            "        mean_true_labels: Mean=1.8571, Std=0.0000\n",
            "        precision_macro: Mean=0.7653, Std=0.0153\n",
            "        recall_macro: Mean=0.9300, Std=0.0245\n",
            "        f1_macro: Mean=0.7815, Std=0.0338\n",
            "\n",
            "    Processing Top Key: DIAGNOSTIC_CLASS\n",
            "      Subgroup: CD\n",
            "        num_samples: Mean=496.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3565, Std=0.0231\n",
            "        mean_true_labels: Mean=1.8004, Std=0.0000\n",
            "        precision_macro: Mean=0.6128, Std=0.0096\n",
            "        recall_macro: Mean=0.7287, Std=0.0160\n",
            "        f1_macro: Mean=0.6409, Std=0.0121\n",
            "      Subgroup: HYP\n",
            "        num_samples: Mean=262.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.2855, Std=0.0203\n",
            "        mean_true_labels: Mean=2.1870, Std=0.0000\n",
            "        precision_macro: Mean=0.6529, Std=0.0074\n",
            "        recall_macro: Mean=0.7645, Std=0.0392\n",
            "        f1_macro: Mean=0.6113, Std=0.0085\n",
            "      Subgroup: MI\n",
            "        num_samples: Mean=550.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3702, Std=0.0102\n",
            "        mean_true_labels: Mean=1.7145, Std=0.0000\n",
            "        precision_macro: Mean=0.5407, Std=0.0109\n",
            "        recall_macro: Mean=0.5798, Std=0.0232\n",
            "        f1_macro: Mean=0.5462, Std=0.0046\n",
            "      Subgroup: NORM\n",
            "        num_samples: Mean=963.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.8395, Std=0.0121\n",
            "        mean_true_labels: Mean=1.0550, Std=0.0000\n",
            "        precision_macro: Mean=0.2892, Std=0.0105\n",
            "        recall_macro: Mean=0.2731, Std=0.0097\n",
            "        f1_macro: Mean=0.2797, Std=0.0050\n",
            "      Subgroup: STTC\n",
            "        num_samples: Mean=521.0, Std=0.00\n",
            "        exact_match_ratio: Mean=0.3674, Std=0.0203\n",
            "        mean_true_labels: Mean=1.7639, Std=0.0000\n",
            "        precision_macro: Mean=0.5720, Std=0.0128\n",
            "        recall_macro: Mean=0.7302, Std=0.0087\n",
            "        f1_macro: Mean=0.5913, Std=0.0050\n",
            "\n",
            "    Processing Top Key: OVERALL_METRICS\n",
            "      Metrics for: OVERALL_METRICS\n",
            "        avg_macro_recall_male_female: Mean=0.7346, Std=0.0126\n",
            "        avg_macro_precision_male_female: Mean=0.6835, Std=0.0122\n",
            "        avg_macro_f1_male_female: Mean=0.7048, Std=0.0023\n",
            "\n",
            "Saving aggregated evaluation statistics to: evaluation_results/aggregated_evaluation_stats.pkl\n",
            "Aggregated stats saved successfully.\n",
            "\n",
            "--- Aggregation Script Finished ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate LaTex Table:"
      ],
      "metadata": {
        "id": "_aaVVAWOAb_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "# --- Optional Imports (Needed for PDF generation and Notebook display) ---\n",
        "try:\n",
        "    from pylatex import Document, Section, Subsection, Tabular, MultiColumn, Command\n",
        "    from pylatex.utils import NoEscape # To use LaTeX commands like \\pm\n",
        "    PYLATEX_AVAILABLE = True\n",
        "    print(\"pylatex library loaded successfully.\")\n",
        "except ImportError:\n",
        "    print(\"Warning: pylatex not found. PDF generation will be skipped.\")\n",
        "    PYLATEX_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    # Needed only if you want to display the PDF inside a Jupyter Notebook/Lab\n",
        "    from IPython.display import display, IFrame\n",
        "    IPYTHON_AVAILABLE = True\n",
        "except ImportError:\n",
        "    IPYTHON_AVAILABLE = False\n",
        "    print(\"Warning: IPython.display not found. PDF preview in notebook will be skipped.\")\n",
        "\n",
        "# --- Configuration Variables ---\n",
        "\n",
        "# Directory where results were saved and PDFs will be generated\n",
        "# Ensure this matches the directory used in your evaluation script\n",
        "RESULTS_DIR = 'evaluation_results'\n",
        "# Make sure the directory exists, create if not\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "# Full path to the file containing your aggregated statistics\n",
        "# Ensure this file exists and was generated by the previous aggregation step\n",
        "AGGREGATED_STATS_PATH = os.path.join(RESULTS_DIR, 'aggregated_evaluation_stats.pkl')\n",
        "\n",
        "# --- Helper Function Definitions ---\n",
        "\n",
        "def get_stat(agg_stats, condition, sg_type, sg_name, metric, stat_type, precision=3, default='N/A'):\n",
        "    \"\"\"\n",
        "    Retrieves an aggregated statistic (mean or std) from the nested dictionary.\n",
        "    Handles the 'all' case where metrics are stored directly under agg_stats[condition]['all'].\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Special handling for the 'all' group ('Total' row)\n",
        "        if sg_type == 'all':\n",
        "            # Access metrics directly under the 'all' key for the condition\n",
        "            value = agg_stats[condition]['all'][metric][stat_type]\n",
        "        else:\n",
        "            # Access metrics for specific subgroups\n",
        "            value = agg_stats[condition][sg_type][sg_name][metric][stat_type]\n",
        "\n",
        "        # Check for NaN and format\n",
        "        if isinstance(value, (int, float)) and np.isnan(value):\n",
        "            return default\n",
        "        if precision == 0:\n",
        "             if isinstance(value, (int, float)) and not np.isnan(value):\n",
        "                 return f\"{int(value)}\"\n",
        "             else:\n",
        "                 return default\n",
        "        else:\n",
        "             if isinstance(value, (int, float)):\n",
        "                return f\"{value:.{precision}f}\"\n",
        "             else:\n",
        "                 return default\n",
        "\n",
        "    except (KeyError, TypeError, IndexError):\n",
        "        # Return default if path doesn't exist (e.g., subgroup missing for a condition)\n",
        "        return default\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error in get_stat({condition}, {sg_type}, {sg_name}, {metric}, {stat_type}): {e}\")\n",
        "        return default\n",
        "\n",
        "def _format_metric_cell(mean_val, std_val, precision=3, default='N/A'):\n",
        "    \"\"\"Formats a table cell as 'mean ± std' handling N/A.\"\"\"\n",
        "    # Ensure mean/std are floats for isnan check, handle potential non-numeric types gracefully\n",
        "    try:\n",
        "        mean_val_f = float(mean_val) if mean_val is not None else np.nan\n",
        "    except (ValueError, TypeError):\n",
        "        mean_val_f = np.nan\n",
        "    try:\n",
        "        std_val_f = float(std_val) if std_val is not None else np.nan\n",
        "    except (ValueError, TypeError):\n",
        "        std_val_f = np.nan\n",
        "\n",
        "    # Format based on availability of valid mean and std\n",
        "    if not np.isnan(mean_val_f) and not np.isnan(std_val_f):\n",
        "        mean_str = f\"{mean_val_f:.{precision}f}\"\n",
        "        std_str = f\"{std_val_f:.{precision}f}\"\n",
        "        # Use NoEscape only if pylatex is available\n",
        "        if PYLATEX_AVAILABLE:\n",
        "             return NoEscape(f\"{mean_str} $\\\\pm$ {std_str}\")\n",
        "        else:\n",
        "             return f\"{mean_str} ± {std_str}\" # Fallback for non-latex output\n",
        "    elif not np.isnan(mean_val_f):\n",
        "         return f\"{mean_val_f:.{precision}f}\"\n",
        "    else:\n",
        "        return default\n",
        "\n",
        "\n",
        "# --- Helper Function to Format Mean ± Std  ---\n",
        "def _format_metric_cell(mean_val, std_val, precision=3, default='N/A'):\n",
        "    \"\"\"Formats a table cell as 'mean ± std' handling N/A.\"\"\"\n",
        "    if isinstance(mean_val, (int, float)) and not np.isnan(mean_val) and \\\n",
        "       isinstance(std_val, (int, float)) and not np.isnan(std_val):\n",
        "        mean_str = f\"{mean_val:.{precision}f}\"\n",
        "        std_str = f\"{std_val:.{precision}f}\"\n",
        "        return NoEscape(f\"{mean_str} $\\\\pm$ {std_str}\")\n",
        "    elif isinstance(mean_val, (int, float)) and not np.isnan(mean_val):\n",
        "         return f\"{mean_val:.{precision}f}\"\n",
        "    else:\n",
        "        return default\n",
        "\n",
        "\n",
        "\n",
        "# --- Placeholder Definitions (Customize these before running table generation) ---\n",
        "\n",
        "# **IMPORTANT**: You need to define which conditions and metrics to include for EACH table\n",
        "# Use the exact keys from your 'EXPERIMENTAL_CONDITIONS' dictionary defined earlier\n",
        "\n",
        "# Example for Sex Comparison Table\n",
        "CONDITIONS_TO_COMPARE_SEX = ['Optimized_Global', 'Optimized_Subgroup_Sex']\n",
        "METRICS_TO_INCLUDE_SEX = ['f1_macro', 'recall_macro', 'precision_macro', 'exact_match_ratio']\n",
        "OUTPUT_PDF_PATH_SEX = os.path.join(RESULTS_DIR, 'comparison_table_global_vs_sex.pdf')\n",
        "\n",
        "# Example for Age Comparison Table\n",
        "CONDITIONS_TO_COMPARE_AGE = ['Optimized_Global', 'Optimized_Subgroup_Age']\n",
        "METRICS_TO_INCLUDE_AGE = ['f1_macro', 'recall_macro', 'precision_macro', 'exact_match_ratio']\n",
        "OUTPUT_PDF_PATH_AGE = os.path.join(RESULTS_DIR, 'comparison_table_global_vs_age.pdf')\n",
        "\n",
        "# Example for Device Comparison Table\n",
        "CONDITIONS_TO_COMPARE_DEVICE = ['Optimized_Global', 'Optimized_Subgroup_Device']\n",
        "METRICS_TO_INCLUDE_DEVICE = ['f1_macro', 'recall_macro', 'precision_macro'] # Fewer metrics might be better\n",
        "OUTPUT_PDF_PATH_DEVICE = os.path.join(RESULTS_DIR, 'comparison_table_global_vs_device.pdf')\n",
        "# Optional: Specify which devices to show if you have many\n",
        "# DEVICES_TO_FILTER = ['AT-6 C 5.5', 'CS-12', 'CS-12   E'] # Example subset\n",
        "\n",
        "# You might also want to compare Global vs Combined (Exp 1 vs Exp 2)\n",
        "CONDITIONS_TO_COMPARE_COMBINED = ['Optimized_Global', 'Optimized_Subgroup_Combined']\n",
        "# You could reuse METRICS_TO_INCLUDE_SEX or define specific ones\n",
        "METRICS_TO_INCLUDE_COMBINED = ['f1_macro', 'recall_macro', 'precision_macro', 'exact_match_ratio', 'avg_macro_f1_male_female'] # Example including the avg M/F metric\n",
        "OUTPUT_PDF_PATH_COMBINED = os.path.join(RESULTS_DIR, 'comparison_table_global_vs_combined.pdf')\n",
        "# Note: You would likely use create_sex_comparison_table for this, as it shows M/F breakdown.\n",
        "\n",
        "print(f\"Results Directory: {RESULTS_DIR}\")\n",
        "print(f\"Aggregated Stats Path: {AGGREGATED_STATS_PATH}\")\n",
        "print(f\"PyLaTeX Available: {PYLATEX_AVAILABLE}\")\n",
        "print(f\"IPython Available: {IPYTHON_AVAILABLE}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5nhBdvtAekR",
        "outputId": "8f8eee3e-8164-48c9-c4a6-3010adc70c55"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pylatex library loaded successfully.\n",
            "Results Directory: evaluation_results\n",
            "Aggregated Stats Path: evaluation_results/aggregated_evaluation_stats.pkl\n",
            "PyLaTeX Available: True\n",
            "IPython Available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_sex_comparison_table(agg_stats, conditions, metrics, filename_base, metric_precision=3):\n",
        "    \"\"\"\n",
        "    Creates a LaTeX document with a comparison table (in landscape)\n",
        "    and generates a PDF.\n",
        "    The 'Total - Overall Metrics' row displays metrics calculated for the 'all' group.\n",
        "    \"\"\"\n",
        "    if not PYLATEX_AVAILABLE:\n",
        "        print(\"Skipping PDF generation as pylatex is not available.\")\n",
        "        return\n",
        "\n",
        "    # --- Input Validation ---\n",
        "    if not conditions: print(\"Error: No conditions provided.\"); return\n",
        "    if conditions[0] not in agg_stats: print(f\"Error: Condition '{conditions[0]}' not found in agg_stats.\"); return\n",
        "    if 'all' not in agg_stats[conditions[0]]: print(f\"Error: 'all' group data not found for condition '{conditions[0]}'.\"); return\n",
        "    if 'sex' not in agg_stats[conditions[0]]: print(f\"Error: 'sex' group data not found for condition '{conditions[0]}'.\"); return\n",
        "\n",
        "\n",
        "    num_conditions = len(conditions)\n",
        "    num_metrics = len(metrics)\n",
        "\n",
        "    # --- Document Setup ---\n",
        "    geometry_options = {\n",
        "        \"tmargin\": \"0.75in\", \"bmargin\": \"0.75in\",\n",
        "        \"lmargin\": \"1in\",   \"rmargin\": \"1in\",\n",
        "        \"includeheadfoot\": True,\n",
        "        \"landscape\": True\n",
        "    }\n",
        "    doc = Document(geometry_options=geometry_options)\n",
        "    doc.preamble.append(Command('usepackage', 'booktabs'))\n",
        "\n",
        "    doc.append(NoEscape(r'\\section*{Comparison of Metrics by Sex Subgroup}'))\n",
        "    doc.append(NoEscape(r'\\vspace{0.5em}'))\n",
        "\n",
        "    # --- Table Setup ---\n",
        "    col_format = 'r' * num_metrics # One data column per metric\n",
        "    table_format = 'l' + ('|' + col_format) * num_conditions\n",
        "    # Remove leading '|' if only one condition exists\n",
        "    if num_conditions > 0 and table_format.startswith('l|'):\n",
        "        table_format = 'l' + table_format[2:]\n",
        "\n",
        "    # Use smaller font for potentially wide table\n",
        "    doc.append(NoEscape(r'\\footnotesize')) # or \\scriptsize\n",
        "    table = Tabular(table_format, booktabs=True)\n",
        "\n",
        "    # --- Header Rows ---\n",
        "    header1 = [\"\"]\n",
        "    for i, cond_name in enumerate(conditions):\n",
        "        display_cond_name = cond_name.replace('_', ' ')\n",
        "        align_str = 'c|' if i < num_conditions - 1 else 'c' # Separator line logic\n",
        "        header1.append(MultiColumn(num_metrics, align=align_str, data=display_cond_name))\n",
        "    table.add_row(header1)\n",
        "    table.add_hline() # Add a horizontal line between header rows\n",
        "\n",
        "    header2 = [\"Subgroup (# Samples)\"] # Updated label\n",
        "    for _ in conditions:\n",
        "        display_metric_names = [m.replace('_', ' ').title() for m in metrics] # Format metric names\n",
        "        header2.extend(display_metric_names)\n",
        "    table.add_row(header2)\n",
        "    table.add_hline() # \\midrule equivalent\n",
        "\n",
        "    # --- Data Rows ---\n",
        "    subgroups_to_show = [\n",
        "        # sg_type, sg_name, display_label\n",
        "        ('all', 'all', 'Total - Overall Metrics'), # Use 'all' sg_type to trigger correct fetching\n",
        "        ('sex', '0', 'Female'),\n",
        "        ('sex', '1', 'Male')\n",
        "    ]\n",
        "\n",
        "    for item_index, item in enumerate(subgroups_to_show):\n",
        "        row_data = []\n",
        "        sg_type = item[0]\n",
        "        sg_name = item[1] # This will be 'all', '0', or '1'\n",
        "        row_label_base = item[2]\n",
        "\n",
        "        # Get sample count N from the specific group for the first condition\n",
        "        # For the 'Total' row, this correctly fetches N from the 'all' group.\n",
        "        n_samples_str = get_stat(agg_stats, conditions[0], sg_type, sg_name, 'num_samples', 'mean', precision=0)\n",
        "        row_label = f\"{row_label_base} \" + (f\"(N={n_samples_str})\" if n_samples_str != 'N/A' else \"(N=?)\")\n",
        "        row_data.append(row_label)\n",
        "\n",
        "        # Loop through conditions and metrics to fill the row\n",
        "        for cond_name in conditions:\n",
        "            for metric in metrics:\n",
        "                # --- MODIFIED LOGIC ---\n",
        "                # Fetch metrics based on whether it's the 'Total' row or a specific subgroup\n",
        "                # get_stat handles the sg_type='all' case internally now.\n",
        "                mean_str = get_stat(agg_stats, cond_name, sg_type, sg_name, metric, 'mean', precision=metric_precision)\n",
        "                std_str = get_stat(agg_stats, cond_name, sg_type, sg_name, metric, 'std', precision=metric_precision)\n",
        "                # --- END MODIFIED LOGIC ---\n",
        "\n",
        "                # Format the cell using the helper function\n",
        "                mean_val = float(mean_str) if mean_str != 'N/A' else np.nan\n",
        "                std_val = float(std_str) if std_str != 'N/A' else np.nan\n",
        "                cell_value = _format_metric_cell(mean_val, std_val, precision=metric_precision)\n",
        "\n",
        "                row_data.append(cell_value)\n",
        "\n",
        "        table.add_row(row_data)\n",
        "        # Optional: Add subtle lines between subgroup rows\n",
        "        if item_index < len(subgroups_to_show) - 1:\n",
        "             table.add_hline(start=2, end=len(row_data)) # Line only under data columns\n",
        "\n",
        "    # --- Add Table to Document ---\n",
        "    doc.append(table)\n",
        "    doc.append(NoEscape(r'\\normalsize')) # Revert font size\n",
        "    doc.append(NoEscape(r'\\vspace{1em}'))\n",
        "\n",
        "\n",
        "    # --- Generate PDF ---\n",
        "    try:\n",
        "        # Ensure filename_base doesn't have extension for generate_pdf\n",
        "        pdf_path_base = os.path.splitext(filename_base)[0]\n",
        "        doc.generate_pdf(pdf_path_base, clean_tex=False) # Set clean_tex=True to remove .tex files after\n",
        "        print(f\"PDF generated successfully: {pdf_path_base}.pdf\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating PDF '{filename_base}': {e}\")\n",
        "        print(\"Attempting to save the .tex file for inspection.\")\n",
        "        try:\n",
        "            tex_path = pdf_path_base + \".tex\"\n",
        "            doc.generate_tex(pdf_path_base)\n",
        "            print(f\"LaTeX source saved to: {tex_path}\")\n",
        "        except Exception as tex_e: print(f\"Could not save .tex file: {tex_e}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "8nZGPlgrApz9"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the exact names from your EXPERIMENTAL_CONDITIONS dictionary\n",
        "CONDITIONS_TO_COMPARE_SEX = ['Optimized_Global_Threshold', 'Optimized_Subgroup_Sex']\n",
        "CONDITIONS_TO_COMPARE_SEX = ['Optimized_Global', 'Optimized_Subgroup_Sex']\n",
        "\n",
        "# Define which metrics you want columns for\n",
        "METRICS_TO_INCLUDE_SEX = ['f1_macro', 'recall_macro', 'precision_macro', 'exact_match_ratio']\n",
        "\n",
        "# Define path to your saved aggregated stats\n",
        "# Make sure this path is correct and points to the .pkl file saved previously\n",
        "AGGREGATED_STATS_PATH = os.path.join(RESULTS_DIR, 'aggregated_evaluation_stats.pkl')\n",
        "OUTPUT_PDF_PATH_SEX = os.path.join(RESULTS_DIR, 'comparison_table_global_vs_sex.pdf')\n",
        "\n",
        "# --- Main Execution Logic (Modified for Sex Comparison) ---\n",
        "# 1. Load Aggregated Statistics\n",
        "print(f\"\\nLoading aggregated statistics from: {AGGREGATED_STATS_PATH}\")\n",
        "try:\n",
        "    with open(AGGREGATED_STATS_PATH, 'rb') as f:\n",
        "        aggregated_stats = pickle.load(f)\n",
        "    print(\"Aggregated stats loaded successfully.\")\n",
        "    # === ADD THIS LINE ===\n",
        "    print(\"Keys found in aggregated_stats:\", aggregated_stats.keys())\n",
        "    # ====================\n",
        "except FileNotFoundError: print(f\"Error: Aggregated stats file not found: {AGGREGATED_STATS_PATH}.\"); exit()\n",
        "except Exception as e: print(f\"Error loading aggregated stats file: {e}\"); exit()\n",
        "\n",
        "# 2. Validate Conditions\n",
        "valid_conditions = [cond for cond in CONDITIONS_TO_COMPARE_SEX if cond in aggregated_stats]\n",
        "if not valid_conditions:\n",
        "    print(f\"Error: None of the conditions {CONDITIONS_TO_COMPARE_SEX} found in stats.\"); exit()\n",
        "if len(valid_conditions) < len(CONDITIONS_TO_COMPARE_SEX):\n",
        "    print(f\"Warning: Only found conditions: {valid_conditions}\")\n",
        "\n",
        "# 3. Create and Generate Table PDF if pylatex is available\n",
        "if PYLATEX_AVAILABLE: # Check if pylatex was imported successfully earlier\n",
        "    print(f\"\\nGenerating Sex comparison table PDF ({OUTPUT_PDF_PATH_SEX})...\")\n",
        "    create_sex_comparison_table( # Use the existing function\n",
        "        agg_stats=aggregated_stats,\n",
        "        conditions=valid_conditions,\n",
        "        metrics=METRICS_TO_INCLUDE_SEX,\n",
        "        filename_base=OUTPUT_PDF_PATH_SEX,\n",
        "        metric_precision=3 # Or your desired precision\n",
        "    )\n",
        "    # Optional: Display in Notebook\n",
        "    # display(IFrame(f\"{OUTPUT_PDF_PATH_SEX}\", width=900, height=600))\n",
        "else:\n",
        "    print(\"\\nSkipping PDF generation because pylatex is not installed.\")\n",
        "\n",
        "print(\"\\nSex table generation process finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bVYLO-GAu3I",
        "outputId": "312fd70b-4080-4556-cc45-deb909c555d2"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading aggregated statistics from: evaluation_results/aggregated_evaluation_stats.pkl\n",
            "Aggregated stats loaded successfully.\n",
            "Keys found in aggregated_stats: dict_keys(['Optimized_Global', 'Optimized_Subgroup_Combined', 'Optimized_Subgroup_Sex', 'Optimized_Subgroup_Age', 'Optimized_Subgroup_Device'])\n",
            "\n",
            "Generating Sex comparison table PDF (evaluation_results/comparison_table_global_vs_sex.pdf)...\n",
            "Error generating PDF 'evaluation_results/comparison_table_global_vs_sex.pdf': No LaTex compiler was found\n",
            "Either specify a LaTex compiler or make sure you have latexmk or pdfLaTex installed.\n",
            "Attempting to save the .tex file for inspection.\n",
            "LaTeX source saved to: evaluation_results/comparison_table_global_vs_sex.tex\n",
            "\n",
            "Sex table generation process finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_age_comparison_table(agg_stats, conditions, metrics, filename_base, metric_precision=3):\n",
        "    \"\"\"\n",
        "    Creates a LaTeX document comparing metrics by Age Bin subgroups.\n",
        "    \"\"\"\n",
        "    if not PYLATEX_AVAILABLE:\n",
        "        print(\"Skipping PDF generation as pylatex is not available.\")\n",
        "        return\n",
        "\n",
        "    # --- Input Validation ---\n",
        "    if not conditions: print(\"Error: No conditions provided.\"); return\n",
        "    if conditions[0] not in agg_stats: print(f\"Error: Condition '{conditions[0]}' not found in agg_stats.\"); return\n",
        "    if 'all' not in agg_stats[conditions[0]]: print(f\"Error: 'all' group data not found for condition '{conditions[0]}'.\"); return\n",
        "    if 'age_bin' not in agg_stats[conditions[0]]: print(f\"Error: 'age_bin' group data not found for condition '{conditions[0]}'.\"); return\n",
        "\n",
        "    num_conditions = len(conditions)\n",
        "    num_metrics = len(metrics)\n",
        "\n",
        "    # --- Document Setup ---\n",
        "    geometry_options = {\n",
        "        \"tmargin\": \"0.75in\", \"bmargin\": \"0.75in\",\n",
        "        \"lmargin\": \"1in\",   \"rmargin\": \"1in\",\n",
        "        \"includeheadfoot\": True,\n",
        "        \"landscape\": True\n",
        "    }\n",
        "    doc = Document(geometry_options=geometry_options)\n",
        "    doc.preamble.append(Command('usepackage', 'booktabs'))\n",
        "\n",
        "    doc.append(NoEscape(r'\\section*{Comparison of Metrics by Age Bin Subgroup}')) # <-- Changed Title\n",
        "    doc.append(NoEscape(r'\\vspace{0.5em}'))\n",
        "\n",
        "    # --- Table Setup (same as before) ---\n",
        "    col_format = 'r' * num_metrics\n",
        "    table_format = 'l' + ('|' + col_format) * num_conditions\n",
        "    if num_conditions > 0 and table_format.startswith('l|'):\n",
        "        table_format = 'l' + table_format[2:]\n",
        "    doc.append(NoEscape(r'\\footnotesize'))\n",
        "    table = Tabular(table_format, booktabs=True)\n",
        "\n",
        "    # --- Header Rows (same as before) ---\n",
        "    header1 = [\"\"]\n",
        "    for i, cond_name in enumerate(conditions):\n",
        "        display_cond_name = cond_name.replace('_', ' ')\n",
        "        align_str = 'c|' if i < num_conditions - 1 else 'c'\n",
        "        header1.append(MultiColumn(num_metrics, align=align_str, data=display_cond_name))\n",
        "    table.add_row(header1)\n",
        "    table.add_hline()\n",
        "    header2 = [\"Subgroup (# Samples)\"]\n",
        "    for _ in conditions:\n",
        "        display_metric_names = [m.replace('_', ' ').title() for m in metrics]\n",
        "        header2.extend(display_metric_names)\n",
        "    table.add_row(header2)\n",
        "    table.add_hline()\n",
        "\n",
        "    # --- Data Rows ---\n",
        "    # Define which subgroups to show (Total + all found age bins)\n",
        "    subgroups_to_show = [('all', 'all', 'Total - Overall Metrics')] # Start with Total row\n",
        "    try:\n",
        "        # Get age bins dynamically from the first condition's stats\n",
        "        age_bins = sorted(agg_stats[conditions[0]]['age_bin'].keys())\n",
        "        # Add tuples for each age bin\n",
        "        subgroups_to_show.extend([('age_bin', bin_name, f\"Age Bin {bin_name}\") for bin_name in age_bins])\n",
        "    except KeyError:\n",
        "        print(f\"Warning: Could not dynamically determine age bins for condition '{conditions[0]}'. Age rows might be missing.\")\n",
        "\n",
        "    for item_index, item in enumerate(subgroups_to_show):\n",
        "        row_data = []\n",
        "        sg_type = item[0]\n",
        "        sg_name = item[1]\n",
        "        row_label_base = item[2]\n",
        "\n",
        "        # Get sample count N (same logic using get_stat)\n",
        "        n_samples_str = get_stat(agg_stats, conditions[0], sg_type, sg_name, 'num_samples', 'mean', precision=0)\n",
        "        row_label = f\"{row_label_base} \" + (f\"(N={n_samples_str})\" if n_samples_str != 'N/A' else \"(N=?)\")\n",
        "        row_data.append(row_label)\n",
        "\n",
        "        # Fill row data (same logic using get_stat)\n",
        "        for cond_name in conditions:\n",
        "            for metric in metrics:\n",
        "                mean_str = get_stat(agg_stats, cond_name, sg_type, sg_name, metric, 'mean', precision=metric_precision)\n",
        "                std_str = get_stat(agg_stats, cond_name, sg_type, sg_name, metric, 'std', precision=metric_precision)\n",
        "                mean_val = float(mean_str) if mean_str != 'N/A' else np.nan\n",
        "                std_val = float(std_str) if std_str != 'N/A' else np.nan\n",
        "                cell_value = _format_metric_cell(mean_val, std_val, precision=metric_precision)\n",
        "                row_data.append(cell_value)\n",
        "\n",
        "        table.add_row(row_data)\n",
        "        if item_index < len(subgroups_to_show) - 1:\n",
        "             table.add_hline(start=2, end=len(row_data))\n",
        "\n",
        "    # --- Add Table and Generate PDF (same as before) ---\n",
        "    doc.append(table)\n",
        "    doc.append(NoEscape(r'\\normalsize'))\n",
        "    doc.append(NoEscape(r'\\vspace{1em}'))\n",
        "    try:\n",
        "        pdf_path_base = os.path.splitext(filename_base)[0]\n",
        "        doc.generate_pdf(pdf_path_base, clean_tex=False)\n",
        "        print(f\"PDF generated successfully: {pdf_path_base}.pdf\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating PDF '{filename_base}': {e}\")\n",
        "        print(\"Attempting to save the .tex file for inspection.\")\n",
        "        try:\n",
        "            tex_path = pdf_path_base + \".tex\"\n",
        "            doc.generate_tex(pdf_path_base)\n",
        "            print(f\"LaTeX source saved to: {tex_path}\")\n",
        "        except Exception as tex_e: print(f\"Could not save .tex file: {tex_e}\")\n",
        "\n",
        "# --- Call the Age Comparison Function ---\n",
        "CONDITIONS_TO_COMPARE_AGE = ['Optimized_Global', 'Optimized_Subgroup_Age']\n",
        "METRICS_TO_INCLUDE_AGE = ['f1_macro', 'recall_macro', 'precision_macro', 'exact_match_ratio']\n",
        "OUTPUT_PDF_PATH_AGE = os.path.join(RESULTS_DIR, 'comparison_table_global_vs_age.pdf')\n",
        "\n",
        "if PYLATEX_AVAILABLE:\n",
        "    print(f\"\\nGenerating Age comparison table PDF ({OUTPUT_PDF_PATH_AGE})...\")\n",
        "    # Reload stats if necessary, or ensure 'aggregated_stats' is still available\n",
        "    # Load Aggregated Statistics (if not already loaded)\n",
        "    if 'aggregated_stats' not in locals():\n",
        "         print(f\"Reloading aggregated statistics from: {AGGREGATED_STATS_PATH}\")\n",
        "         # Add loading logic here again if needed\n",
        "         # ...\n",
        "\n",
        "    valid_conditions_age = [cond for cond in CONDITIONS_TO_COMPARE_AGE if cond in aggregated_stats]\n",
        "    if valid_conditions_age:\n",
        "        create_age_comparison_table( # Call the NEW function\n",
        "            agg_stats=aggregated_stats,\n",
        "            conditions=valid_conditions_age,\n",
        "            metrics=METRICS_TO_INCLUDE_AGE,\n",
        "            filename_base=OUTPUT_PDF_PATH_AGE,\n",
        "            metric_precision=3\n",
        "        )\n",
        "        # Optional: display(IFrame(f\"{OUTPUT_PDF_PATH_AGE}\", width=900, height=600))\n",
        "    else:\n",
        "         print(f\"Error: None of the conditions {CONDITIONS_TO_COMPARE_AGE} found in stats.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nSkipping Age PDF generation because pylatex is not installed.\")\n",
        "\n",
        "print(\"\\nAge table generation process finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb80YQYVA2Jz",
        "outputId": "50d768b8-6dda-4fa9-caaf-7bb9ffb39348"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating Age comparison table PDF (evaluation_results/comparison_table_global_vs_age.pdf)...\n",
            "Error generating PDF 'evaluation_results/comparison_table_global_vs_age.pdf': No LaTex compiler was found\n",
            "Either specify a LaTex compiler or make sure you have latexmk or pdfLaTex installed.\n",
            "Attempting to save the .tex file for inspection.\n",
            "LaTeX source saved to: evaluation_results/comparison_table_global_vs_age.tex\n",
            "\n",
            "Age table generation process finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_device_comparison_table(agg_stats, conditions, metrics, filename_base, metric_precision=3, devices_to_include=None):\n",
        "    \"\"\"\n",
        "    Creates a LaTeX document comparing metrics by Device subgroups.\n",
        "    Optionally filters devices to include.\n",
        "    \"\"\"\n",
        "    if not PYLATEX_AVAILABLE:\n",
        "        print(\"Skipping PDF generation as pylatex is not available.\")\n",
        "        return\n",
        "\n",
        "    # --- Input Validation ---\n",
        "    if not conditions: print(\"Error: No conditions provided.\"); return\n",
        "    if conditions[0] not in agg_stats: print(f\"Error: Condition '{conditions[0]}' not found in agg_stats.\"); return\n",
        "    if 'all' not in agg_stats[conditions[0]]: print(f\"Error: 'all' group data not found for condition '{conditions[0]}'.\"); return\n",
        "    if 'device' not in agg_stats[conditions[0]]: print(f\"Error: 'device' group data not found for condition '{conditions[0]}'.\"); return\n",
        "\n",
        "    num_conditions = len(conditions)\n",
        "    num_metrics = len(metrics)\n",
        "\n",
        "    # --- Document Setup (same)---\n",
        "    geometry_options = {\n",
        "        \"tmargin\": \"0.75in\", \"bmargin\": \"0.75in\",\n",
        "        \"lmargin\": \"0.75in\",   \"rmargin\": \"0.75in\", # Reduced side margins for potentially wide table\n",
        "        \"includeheadfoot\": True,\n",
        "        \"landscape\": True\n",
        "    }\n",
        "    doc = Document(geometry_options=geometry_options)\n",
        "    doc.preamble.append(Command('usepackage', 'booktabs'))\n",
        "    # Consider rotating long device names if needed (requires rotating package)\n",
        "    # doc.preamble.append(Command('usepackage', 'rotating'))\n",
        "\n",
        "    doc.append(NoEscape(r'\\section*{Comparison of Metrics by Device Subgroup}')) # <-- Changed Title\n",
        "    doc.append(NoEscape(r'\\vspace{0.5em}'))\n",
        "\n",
        "    # --- Table Setup (same) ---\n",
        "    col_format = 'r' * num_metrics\n",
        "    table_format = 'l' + ('|' + col_format) * num_conditions\n",
        "    if num_conditions > 0 and table_format.startswith('l|'):\n",
        "        table_format = 'l' + table_format[2:]\n",
        "    doc.append(NoEscape(r'\\tiny')) # Use even smaller font if many devices/metrics\n",
        "    table = Tabular(table_format, booktabs=True)\n",
        "\n",
        "    # --- Header Rows (same) ---\n",
        "    header1 = [\"\"]\n",
        "    for i, cond_name in enumerate(conditions):\n",
        "        display_cond_name = cond_name.replace('_', ' ')\n",
        "        align_str = 'c|' if i < num_conditions - 1 else 'c'\n",
        "        header1.append(MultiColumn(num_metrics, align=align_str, data=display_cond_name))\n",
        "    table.add_row(header1)\n",
        "    table.add_hline()\n",
        "    header2 = [\"Subgroup (# Samples)\"]\n",
        "    for _ in conditions:\n",
        "        display_metric_names = [m.replace('_', ' ').title() for m in metrics]\n",
        "        header2.extend(display_metric_names)\n",
        "    table.add_row(header2)\n",
        "    table.add_hline()\n",
        "\n",
        "    # --- Data Rows ---\n",
        "    subgroups_to_show = [('all', 'all', 'Total - Overall Metrics')]\n",
        "    try:\n",
        "        all_devices = sorted(agg_stats[conditions[0]]['device'].keys())\n",
        "        if devices_to_include: # Filter devices if a list is provided\n",
        "             devices_to_iterate = [d for d in all_devices if d in devices_to_include]\n",
        "             print(f\"Including devices: {devices_to_iterate}\")\n",
        "        else:\n",
        "             devices_to_iterate = all_devices # Include all devices\n",
        "             print(f\"Including all {len(devices_to_iterate)} devices.\")\n",
        "\n",
        "        subgroups_to_show.extend([('device', dev_name, f\"{dev_name}\") for dev_name in devices_to_iterate]) # Use device name as label\n",
        "    except KeyError:\n",
        "        print(f\"Warning: Could not dynamically determine devices for condition '{conditions[0]}'. Device rows might be missing.\")\n",
        "\n",
        "    for item_index, item in enumerate(subgroups_to_show):\n",
        "        row_data = []\n",
        "        sg_type = item[0]\n",
        "        sg_name = item[1]\n",
        "        row_label_base = item[2]\n",
        "\n",
        "        n_samples_str = get_stat(agg_stats, conditions[0], sg_type, sg_name, 'num_samples', 'mean', precision=0)\n",
        "        row_label = f\"{row_label_base} \" + (f\"(N={n_samples_str})\" if n_samples_str != 'N/A' else \"(N=?)\")\n",
        "        # Could use NoEscape + \\rotatebox{90}{...} for long device names if needed\n",
        "        row_data.append(row_label)\n",
        "\n",
        "        for cond_name in conditions:\n",
        "            for metric in metrics:\n",
        "                mean_str = get_stat(agg_stats, cond_name, sg_type, sg_name, metric, 'mean', precision=metric_precision)\n",
        "                std_str = get_stat(agg_stats, cond_name, sg_type, sg_name, metric, 'std', precision=metric_precision)\n",
        "                mean_val = float(mean_str) if mean_str != 'N/A' else np.nan\n",
        "                std_val = float(std_str) if std_str != 'N/A' else np.nan\n",
        "                cell_value = _format_metric_cell(mean_val, std_val, precision=metric_precision)\n",
        "                row_data.append(cell_value)\n",
        "\n",
        "        table.add_row(row_data)\n",
        "        if item_index < len(subgroups_to_show) - 1:\n",
        "             table.add_hline(start=2, end=len(row_data))\n",
        "\n",
        "    # --- Add Table and Generate PDF (same) ---\n",
        "    doc.append(table)\n",
        "    doc.append(NoEscape(r'\\normalsize'))\n",
        "    doc.append(NoEscape(r'\\vspace{1em}'))\n",
        "    try:\n",
        "        pdf_path_base = os.path.splitext(filename_base)[0]\n",
        "        doc.generate_pdf(pdf_path_base, clean_tex=False)\n",
        "        print(f\"PDF generated successfully: {pdf_path_base}.pdf\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating PDF '{filename_base}': {e}\")\n",
        "        print(\"Attempting to save the .tex file for inspection.\")\n",
        "        try:\n",
        "            tex_path = pdf_path_base + \".tex\"\n",
        "            doc.generate_tex(pdf_path_base)\n",
        "            print(f\"LaTeX source saved to: {tex_path}\")\n",
        "        except Exception as tex_e: print(f\"Could not save .tex file: {tex_e}\")\n",
        "\n",
        "\n",
        "# --- Call the Device Comparison Function ---\n",
        "CONDITIONS_TO_COMPARE_DEVICE = ['Optimized_Global', 'Optimized_Subgroup_Device']\n",
        "METRICS_TO_INCLUDE_DEVICE = ['f1_macro', 'recall_macro', 'precision_macro'] # Maybe fewer metrics if table is wide\n",
        "OUTPUT_PDF_PATH_DEVICE = os.path.join(RESULTS_DIR, 'comparison_table_global_vs_device.pdf')\n",
        "# Optional: Select only specific devices if the table becomes too large\n",
        "# DEVICES_TO_FILTER = ['AT-6 C 5.5', 'CS-12', 'CS-12   E'] # Example filter\n",
        "\n",
        "if PYLATEX_AVAILABLE:\n",
        "    print(f\"\\nGenerating Device comparison table PDF ({OUTPUT_PDF_PATH_DEVICE})...\")\n",
        "    # Reload stats if necessary\n",
        "    if 'aggregated_stats' not in locals():\n",
        "         print(f\"Reloading aggregated statistics from: {AGGREGATED_STATS_PATH}\")\n",
        "         # Add loading logic here again if needed\n",
        "         # ...\n",
        "\n",
        "    valid_conditions_device = [cond for cond in CONDITIONS_TO_COMPARE_DEVICE if cond in aggregated_stats]\n",
        "    if valid_conditions_device:\n",
        "        create_device_comparison_table( # Call the NEW function\n",
        "            agg_stats=aggregated_stats,\n",
        "            conditions=valid_conditions_device,\n",
        "            metrics=METRICS_TO_INCLUDE_DEVICE,\n",
        "            filename_base=OUTPUT_PDF_PATH_DEVICE,\n",
        "            metric_precision=3,\n",
        "            # devices_to_include=DEVICES_TO_FILTER # Uncomment to filter devices\n",
        "        )\n",
        "        # display(IFrame(f\"{OUTPUT_PDF_PATH_DEVICE}\", width=900, height=600))\n",
        "    else:\n",
        "         print(f\"Error: None of the conditions {CONDITIONS_TO_COMPARE_DEVICE} found in stats.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nSkipping Device PDF generation because pylatex is not installed.\")\n",
        "\n",
        "print(\"\\nDevice table generation process finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eu-jT_zXA-34",
        "outputId": "9d687e71-bcac-4f6b-9387-225b96bb5e3d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating Device comparison table PDF (evaluation_results/comparison_table_global_vs_device.pdf)...\n",
            "Including all 11 devices.\n",
            "Error generating PDF 'evaluation_results/comparison_table_global_vs_device.pdf': No LaTex compiler was found\n",
            "Either specify a LaTex compiler or make sure you have latexmk or pdfLaTex installed.\n",
            "Attempting to save the .tex file for inspection.\n",
            "LaTeX source saved to: evaluation_results/comparison_table_global_vs_device.tex\n",
            "\n",
            "Device table generation process finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_metric_class_summary_table(agg_stats, conditions, filename_base, metric_precision=3):\n",
        "    \"\"\"\n",
        "    Creates a LaTeX table showing key overall metrics and then per-class\n",
        "    F1, Precision, Recall across different conditions.\n",
        "    \"\"\"\n",
        "    if not PYLATEX_AVAILABLE: print(\"Skipping PDF: pylatex not available.\"); return\n",
        "\n",
        "    # --- Define Metrics to Display ---\n",
        "    overall_metrics_to_show = {\n",
        "        'f1_macro': 'Total - F1 Macro',\n",
        "        'precision_macro': 'Total - Precision Macro',\n",
        "        'recall_macro': 'Total - Recall Macro',\n",
        "        'exact_match_ratio': 'Total - Exact Match'\n",
        "    }\n",
        "    # Map display name to the per-class key in agg_stats\n",
        "    per_class_metrics_to_show = {\n",
        "        'F1': 'f1_per_class',\n",
        "        'Precision': 'precision_per_class',\n",
        "        'Recall': 'recall_per_class'\n",
        "    }\n",
        "\n",
        "    # --- Input Validation and Class Name Extraction ---\n",
        "    if not conditions: print(\"Error: No conditions provided.\"); return\n",
        "    first_cond = conditions[0]\n",
        "    if first_cond not in agg_stats: print(f\"Error: Cond '{first_cond}' not found.\"); return\n",
        "    if 'all' not in agg_stats[first_cond]: print(f\"Error: 'all' data missing for {first_cond}.\"); return\n",
        "\n",
        "    # Find the first valid per-class metric key to extract class names\n",
        "    first_per_class_key = None\n",
        "    for pc_key in per_class_metrics_to_show.values():\n",
        "        if pc_key in agg_stats[first_cond]['all']:\n",
        "            first_per_class_key = pc_key\n",
        "            break\n",
        "    if not first_per_class_key:\n",
        "         print(f\"Error: None of the per-class keys found in 'all' data: {list(per_class_metrics_to_show.values())}\"); return\n",
        "\n",
        "    try:\n",
        "        class_names = sorted(list(agg_stats[first_cond]['all'][first_per_class_key].keys()))\n",
        "        if not class_names: print(\"Warning: No class names found.\"); return\n",
        "    except Exception as e: print(f\"Error extracting class names: {e}\"); return\n",
        "\n",
        "    num_conditions = len(conditions)\n",
        "    num_data_cols_per_cond = 1 # Each condition is one column of 'mean ± std'\n",
        "\n",
        "    # --- Document Setup (Landscape) ---\n",
        "    geometry_options = {\"tmargin\": \"0.75in\", \"bmargin\": \"0.75in\", \"lmargin\": \"1in\", \"rmargin\": \"1in\", \"includeheadfoot\": True, \"landscape\": True}\n",
        "    doc = Document(geometry_options=geometry_options)\n",
        "    doc.preamble.append(Command('usepackage', 'booktabs'))\n",
        "    doc.append(NoEscape(r'\\section*{Metric Summary by Condition and Class}')) # Updated Title\n",
        "    doc.append(NoEscape(r'\\vspace{0.5em}'))\n",
        "\n",
        "    # --- Table Setup ---\n",
        "    col_format = 'r' * num_data_cols_per_cond\n",
        "    table_format = 'l' + ('|' + col_format) * num_conditions\n",
        "    if num_conditions > 0 and table_format.startswith('l|'): table_format = 'l' + table_format[2:]\n",
        "\n",
        "    doc.append(NoEscape(r'\\footnotesize'))\n",
        "    table = Tabular(table_format, booktabs=True)\n",
        "\n",
        "    # --- Header Row ---\n",
        "    header1 = [\"Metric / Class\"]\n",
        "    for i, cond_name in enumerate(conditions):\n",
        "        display_cond_name = cond_name.replace('_', ' ')\n",
        "        # Use align='c' - let table_format handle separators\n",
        "        header1.append(MultiColumn(num_data_cols_per_cond, align='c', data=display_cond_name))\n",
        "    table.add_row(header1)\n",
        "    table.add_hline() # \\midrule\n",
        "\n",
        "    # --- Overall Metric Rows ---\n",
        "    print(\"Fetching Overall Metrics...\")\n",
        "    for metric_key, display_label in overall_metrics_to_show.items():\n",
        "        row_data = [display_label]\n",
        "        for cond_name in conditions:\n",
        "            # Use get_stat for overall metrics (sg_type='all')\n",
        "            mean_str = get_stat(agg_stats, cond_name, 'all', 'all', metric_key, 'mean', precision=metric_precision)\n",
        "            std_str = get_stat(agg_stats, cond_name, 'all', 'all', metric_key, 'std', precision=metric_precision)\n",
        "            mean_val = float(mean_str) if mean_str != 'N/A' else np.nan\n",
        "            std_val = float(std_str) if std_str != 'N/A' else np.nan\n",
        "            cell_value = _format_metric_cell(mean_val, std_val, precision=metric_precision)\n",
        "            row_data.append(cell_value)\n",
        "        table.add_row(row_data)\n",
        "\n",
        "    # --- Separator Line ---\n",
        "    table.add_hline(start=1, end=1+num_conditions*num_data_cols_per_cond) # Full width line\n",
        "\n",
        "    # --- Per-Class Metric Rows ---\n",
        "    print(\"Fetching Per-Class Metrics...\")\n",
        "    for class_name in class_names:\n",
        "        print(f\"  Class: {class_name}\")\n",
        "        for metric_display_name, per_class_key in per_class_metrics_to_show.items():\n",
        "            row_label = f\"{class_name} - {metric_display_name}\"\n",
        "            row_data = [row_label]\n",
        "\n",
        "            for cond_name in conditions:\n",
        "                mean_val, std_val = np.nan, np.nan # Default\n",
        "                try:\n",
        "                    # Direct access for per-class data\n",
        "                    class_metric_dict = agg_stats[cond_name]['all'][per_class_key][class_name]\n",
        "                    mean_val = class_metric_dict.get('mean', np.nan)\n",
        "                    std_val = class_metric_dict.get('std', np.nan)\n",
        "                except (KeyError, TypeError):\n",
        "                     print(f\"Warn: Data missing for {cond_name}/all/{per_class_key}/{class_name}\")\n",
        "\n",
        "                cell_value = _format_metric_cell(mean_val, std_val, precision=metric_precision)\n",
        "                row_data.append(cell_value)\n",
        "            table.add_row(row_data)\n",
        "\n",
        "        # Add subtle line between classes if desired\n",
        "        if class_name != class_names[-1]: # Don't add after last class\n",
        "             table.add_hline(start=2, end=1+num_conditions*num_data_cols_per_cond) # Line only under data columns\n",
        "\n",
        "    # --- Add Table to Document ---\n",
        "    doc.append(table)\n",
        "    doc.append(NoEscape(r'\\normalsize'))\n",
        "    doc.append(NoEscape(r'\\vspace{1em}'))\n",
        "\n",
        "    # --- Generate PDF ---\n",
        "    try:\n",
        "        pdf_path_base = os.path.splitext(filename_base)[0]\n",
        "        doc.generate_pdf(pdf_path_base, clean_tex=False)\n",
        "        print(f\"PDF generated successfully: {pdf_path_base}.pdf\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating PDF: {e}\")\n",
        "        print(\"Attempting to save the .tex file for inspection.\")\n",
        "        try:\n",
        "            tex_path = pdf_path_base + \".tex\"; doc.generate_tex(pdf_path_base)\n",
        "            print(f\"LaTeX source saved to: {tex_path}\")\n",
        "        except Exception as tex_e: print(f\"Could not save .tex file: {tex_e}\")\n",
        "\n",
        "\n",
        "# Define paths, condition (singular), and metrics\n",
        "RESULTS_DIR = 'evaluation_results'\n",
        "AGGREGATED_STATS_FILENAME = 'aggregated_evaluation_stats.pkl'\n",
        "# Give a specific, descriptive name for this output PDF\n",
        "SUMMARY_TABLE_PDF_FILENAME = 'overall_metrics_table_global_thresh.pdf'\n",
        "\n",
        "AGGREGATED_STATS_PATH = os.path.join(RESULTS_DIR, AGGREGATED_STATS_FILENAME)\n",
        "SUMMARY_OUTPUT_PDF_PATH = os.path.join(RESULTS_DIR, SUMMARY_TABLE_PDF_FILENAME)\n",
        "\n",
        "# === KEY CHANGE: Specify ONLY the global threshold condition ===\n",
        "# Make sure 'Optimized_Global' is the exact key used in your aggregated_stats dictionary\n",
        "CONDITIONS_TO_COMPARE = ['Optimized_Global']\n",
        "# ===============================================================\n",
        "\n",
        "METRIC_PRECISION = 3 # Decimal places for formatting\n",
        "\n",
        "# 1. Load Aggregated Statistics (ensure this happens before this block)\n",
        "print(f\"\\nLoading aggregated statistics from: {AGGREGATED_STATS_PATH}\")\n",
        "if not os.path.exists(AGGREGATED_STATS_PATH):\n",
        "    print(f\"Error: Aggregated stats file not found: {AGGREGATED_STATS_PATH}.\")\n",
        "    # Decide how to handle: exit() or skip table generation\n",
        "    exit() # Example: exit if file not found\n",
        "try:\n",
        "    with open(AGGREGATED_STATS_PATH, 'rb') as f:\n",
        "        aggregated_stats = pickle.load(f)\n",
        "    print(\"Aggregated stats loaded successfully.\")\n",
        "    # Optional but recommended: Verify the specific condition exists\n",
        "    if CONDITIONS_TO_COMPARE[0] not in aggregated_stats:\n",
        "         print(f\"Error: Condition '{CONDITIONS_TO_COMPARE[0]}' not found in loaded stats.\")\n",
        "         print(f\"Available keys: {list(aggregated_stats.keys())}\")\n",
        "         exit() # Exit if the required condition is missing\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading aggregated stats file: {e}\")\n",
        "    exit()\n",
        "\n",
        "# 2. Validate Conditions (will just contain the single condition now)\n",
        "valid_conditions = [cond for cond in CONDITIONS_TO_COMPARE if cond in aggregated_stats]\n",
        "if not valid_conditions:\n",
        "    print(\"Error: The specified condition was not found in the loaded stats.\")\n",
        "    exit() # Exit if somehow the condition is invalid despite check above\n",
        "\n",
        "# 3. Create and Generate Metric x Class Summary Table PDF\n",
        "if PYLATEX_AVAILABLE: # Assumes PYLATEX_AVAILABLE was set earlier\n",
        "    print(f\"\\nGenerating Overall Metrics Table for '{CONDITIONS_TO_COMPARE[0]}' (landscape)...\")\n",
        "    create_metric_class_summary_table( # Call the existing function\n",
        "        agg_stats=aggregated_stats,\n",
        "        conditions=valid_conditions, # Pass the list containing only 'Optimized_Global'\n",
        "        filename_base=SUMMARY_OUTPUT_PDF_PATH, # Use the specific output path\n",
        "        metric_precision=METRIC_PRECISION\n",
        "    )\n",
        "    # Optional: Display in Jupyter\n",
        "    try:\n",
        "        # Ensure these were imported if using notebooks\n",
        "        from IPython.display import display, IFrame\n",
        "        if IPYTHON_AVAILABLE: # Check flag if you defined it\n",
        "            display(IFrame(f\"{SUMMARY_OUTPUT_PDF_PATH}\", width=900, height=600))\n",
        "    except ImportError:\n",
        "        pass # Ignore if IPython not available\n",
        "else:\n",
        "    print(\"\\nSkipping PDF generation because pylatex is not installed.\")\n",
        "\n",
        "print(f\"\\nOverall Metrics Table generation process finished ({SUMMARY_TABLE_PDF_FILENAME}).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "id": "Q1bV1_lJBJU8",
        "outputId": "ba74c681-63ce-43b9-f42f-a2b785c9b769"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading aggregated statistics from: evaluation_results/aggregated_evaluation_stats.pkl\n",
            "Aggregated stats loaded successfully.\n",
            "\n",
            "Generating Overall Metrics Table for 'Optimized_Global' (landscape)...\n",
            "Fetching Overall Metrics...\n",
            "Fetching Per-Class Metrics...\n",
            "  Class: CD\n",
            "  Class: HYP\n",
            "  Class: MI\n",
            "  Class: NORM\n",
            "  Class: STTC\n",
            "Error generating PDF: No LaTex compiler was found\n",
            "Either specify a LaTex compiler or make sure you have latexmk or pdfLaTex installed.\n",
            "Attempting to save the .tex file for inspection.\n",
            "LaTeX source saved to: evaluation_results/overall_metrics_table_global_thresh.tex\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x79f4f422a890>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"600\"\n",
              "            src=\"evaluation_results/overall_metrics_table_global_thresh.pdf\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Overall Metrics Table generation process finished (overall_metrics_table_global_thresh.pdf).\n"
          ]
        }
      ]
    }
  ]
}